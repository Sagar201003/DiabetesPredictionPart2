2023-06-04 20:37:46,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 20:37:46,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 20:37:46,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 20:37:46,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 20:37:48,358:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-04 20:38:10,974:INFO:PyCaret ClassificationExperiment
2023-06-04 20:38:10,974:INFO:Logging name: clf-default-name
2023-06-04 20:38:10,974:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-04 20:38:10,974:INFO:version 3.0.0
2023-06-04 20:38:10,975:INFO:Initializing setup()
2023-06-04 20:38:10,975:INFO:self.USI: 2203
2023-06-04 20:38:10,975:INFO:self._variable_keys: {'y_train', 'USI', 'pipeline', 'target_param', 'exp_id', 'y_test', '_available_plots', 'X_test', 'fold_groups_param', 'n_jobs_param', 'log_plots_param', 'fold_shuffle_param', 'seed', 'X_train', 'gpu_param', 'fix_imbalance', 'html_param', 'idx', 'fold_generator', 'logging_param', 'memory', 'gpu_n_jobs_param', 'y', 'data', '_ml_usecase', 'exp_name_log', 'X', 'is_multiclass'}
2023-06-04 20:38:10,975:INFO:Checking environment
2023-06-04 20:38:10,975:INFO:python_version: 3.11.3
2023-06-04 20:38:10,975:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2023-06-04 20:38:10,975:INFO:machine: AMD64
2023-06-04 20:38:11,007:INFO:platform: Windows-10-10.0.19045-SP0
2023-06-04 20:38:11,012:INFO:Memory: svmem(total=8384401408, available=876576768, percent=89.5, used=7507824640, free=876576768)
2023-06-04 20:38:11,013:INFO:Physical Core: 4
2023-06-04 20:38:11,013:INFO:Logical Core: 8
2023-06-04 20:38:11,013:INFO:Checking libraries
2023-06-04 20:38:11,013:INFO:System:
2023-06-04 20:38:11,013:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2023-06-04 20:38:11,013:INFO:executable: C:\Program Files\Python311\python.exe
2023-06-04 20:38:11,013:INFO:   machine: Windows-10-10.0.19045-SP0
2023-06-04 20:38:11,014:INFO:PyCaret required dependencies:
2023-06-04 20:38:11,014:INFO:                 pip: 22.3.1
2023-06-04 20:38:11,014:INFO:          setuptools: 65.5.0
2023-06-04 20:38:11,014:INFO:             pycaret: 3.0.0
2023-06-04 20:38:11,014:INFO:             IPython: 8.12.0
2023-06-04 20:38:11,014:INFO:          ipywidgets: 8.0.6
2023-06-04 20:38:11,014:INFO:                tqdm: 4.65.0
2023-06-04 20:38:11,014:INFO:               numpy: 1.24.3
2023-06-04 20:38:11,014:INFO:              pandas: 1.5.3
2023-06-04 20:38:11,014:INFO:              jinja2: 3.1.2
2023-06-04 20:38:11,015:INFO:               scipy: 1.10.1
2023-06-04 20:38:11,015:INFO:              joblib: 1.2.0
2023-06-04 20:38:11,015:INFO:             sklearn: 1.2.2
2023-06-04 20:38:11,015:INFO:                pyod: 1.0.9
2023-06-04 20:38:11,015:INFO:            imblearn: 0.10.1
2023-06-04 20:38:11,015:INFO:   category_encoders: 2.6.0
2023-06-04 20:38:11,015:INFO:            lightgbm: 3.3.5
2023-06-04 20:38:11,015:INFO:               numba: 0.57.0
2023-06-04 20:38:11,015:INFO:            requests: 2.28.2
2023-06-04 20:38:11,015:INFO:          matplotlib: 3.7.1
2023-06-04 20:38:11,015:INFO:          scikitplot: 0.3.7
2023-06-04 20:38:11,016:INFO:         yellowbrick: 1.5
2023-06-04 20:38:11,016:INFO:              plotly: 5.14.1
2023-06-04 20:38:11,016:INFO:             kaleido: 0.2.1
2023-06-04 20:38:11,016:INFO:         statsmodels: 0.14.0
2023-06-04 20:38:11,016:INFO:              sktime: 0.18.0
2023-06-04 20:38:11,016:INFO:               tbats: 1.1.3
2023-06-04 20:38:11,016:INFO:            pmdarima: 2.0.3
2023-06-04 20:38:11,016:INFO:              psutil: 5.9.4
2023-06-04 20:38:11,016:INFO:PyCaret optional dependencies:
2023-06-04 20:38:11,042:INFO:                shap: Not installed
2023-06-04 20:38:11,042:INFO:           interpret: Not installed
2023-06-04 20:38:11,042:INFO:                umap: Not installed
2023-06-04 20:38:11,042:INFO:    pandas_profiling: Not installed
2023-06-04 20:38:11,042:INFO:  explainerdashboard: Not installed
2023-06-04 20:38:11,043:INFO:             autoviz: Not installed
2023-06-04 20:38:11,043:INFO:           fairlearn: Not installed
2023-06-04 20:38:11,043:INFO:             xgboost: Not installed
2023-06-04 20:38:11,043:INFO:            catboost: Not installed
2023-06-04 20:38:11,043:INFO:              kmodes: Not installed
2023-06-04 20:38:11,043:INFO:             mlxtend: Not installed
2023-06-04 20:38:11,043:INFO:       statsforecast: Not installed
2023-06-04 20:38:11,044:INFO:        tune_sklearn: Not installed
2023-06-04 20:38:11,044:INFO:                 ray: Not installed
2023-06-04 20:38:11,044:INFO:            hyperopt: Not installed
2023-06-04 20:38:11,044:INFO:              optuna: Not installed
2023-06-04 20:38:11,044:INFO:               skopt: Not installed
2023-06-04 20:38:11,044:INFO:              mlflow: Not installed
2023-06-04 20:38:11,044:INFO:              gradio: Not installed
2023-06-04 20:38:11,044:INFO:             fastapi: Not installed
2023-06-04 20:38:11,044:INFO:             uvicorn: Not installed
2023-06-04 20:38:11,045:INFO:              m2cgen: Not installed
2023-06-04 20:38:11,045:INFO:           evidently: Not installed
2023-06-04 20:38:11,045:INFO:               fugue: Not installed
2023-06-04 20:38:11,045:INFO:           streamlit: Not installed
2023-06-04 20:38:11,045:INFO:             prophet: 1.1.2
2023-06-04 20:38:11,045:INFO:None
2023-06-04 20:38:11,045:INFO:Set up data.
2023-06-04 20:38:11,085:INFO:Set up train/test split.
2023-06-04 20:38:11,135:INFO:Set up index.
2023-06-04 20:38:11,135:INFO:Set up folding strategy.
2023-06-04 20:38:11,135:INFO:Assigning column types.
2023-06-04 20:38:11,146:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-04 20:38:11,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 20:38:11,227:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 20:38:11,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,393:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 20:38:11,394:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 20:38:11,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,428:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-04 20:38:11,486:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 20:38:11,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,585:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 20:38:11,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,616:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-04 20:38:11,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,716:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:11,848:INFO:Preparing preprocessing pipeline...
2023-06-04 20:38:11,852:INFO:Set up simple imputation.
2023-06-04 20:38:11,869:INFO:Set up encoding of ordinal features.
2023-06-04 20:38:11,874:INFO:Set up encoding of categorical features.
2023-06-04 20:38:12,045:INFO:Finished creating preprocessing pipeline.
2023-06-04 20:38:12,077:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\shiva\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'hypertension',
                                             'heart_disease', 'smoking_history',
                                             'bmi', 'HbA1c_level',
                                             'blood_glucose_level'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['gender'],
                                    transformer=OrdinalEncoder(cols=['gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-06-04 20:38:12,077:INFO:Creating final display dataframe.
2023-06-04 20:38:12,628:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          diabetes
2                   Target type            Binary
3           Original data shape        (76885, 9)
4        Transformed data shape        (76885, 9)
5   Transformed train set shape        (57663, 9)
6    Transformed test set shape        (19222, 9)
7              Ordinal features                 1
8              Numeric features                 7
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              2203
2023-06-04 20:38:12,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:12,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:12,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:12,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:38:12,892:INFO:setup() successfully completed in 2.18s...............
2023-06-04 20:38:12,892:INFO:Initializing compare_models()
2023-06-04 20:38:12,892:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-06-04 20:38:12,893:INFO:Checking exceptions
2023-06-04 20:38:12,909:INFO:Preparing display monitor
2023-06-04 20:38:12,916:INFO:Initializing Logistic Regression
2023-06-04 20:38:12,916:INFO:Total runtime is 0.0 minutes
2023-06-04 20:38:12,917:INFO:SubProcess create_model() called ==================================
2023-06-04 20:38:12,917:INFO:Initializing create_model()
2023-06-04 20:38:12,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:38:12,918:INFO:Checking exceptions
2023-06-04 20:38:12,918:INFO:Importing libraries
2023-06-04 20:38:12,918:INFO:Copying training dataset
2023-06-04 20:38:12,958:INFO:Defining folds
2023-06-04 20:38:12,958:INFO:Declaring metric variables
2023-06-04 20:38:12,959:INFO:Importing untrained model
2023-06-04 20:38:12,959:INFO:Logistic Regression Imported successfully
2023-06-04 20:38:12,960:INFO:Starting cross validation
2023-06-04 20:38:12,962:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:38:22,049:INFO:Calculating mean and std
2023-06-04 20:38:22,051:INFO:Creating metrics dataframe
2023-06-04 20:38:22,206:INFO:Uploading results into container
2023-06-04 20:38:22,208:INFO:Uploading model into container now
2023-06-04 20:38:22,208:INFO:_master_model_container: 1
2023-06-04 20:38:22,209:INFO:_display_container: 2
2023-06-04 20:38:22,209:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 20:38:22,210:INFO:create_model() successfully completed......................................
2023-06-04 20:38:22,351:INFO:SubProcess create_model() end ==================================
2023-06-04 20:38:22,351:INFO:Creating metrics dataframe
2023-06-04 20:38:22,361:INFO:Initializing K Neighbors Classifier
2023-06-04 20:38:22,361:INFO:Total runtime is 0.15742890437444051 minutes
2023-06-04 20:38:22,362:INFO:SubProcess create_model() called ==================================
2023-06-04 20:38:22,362:INFO:Initializing create_model()
2023-06-04 20:38:22,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:38:22,362:INFO:Checking exceptions
2023-06-04 20:38:22,363:INFO:Importing libraries
2023-06-04 20:38:22,363:INFO:Copying training dataset
2023-06-04 20:38:22,391:INFO:Defining folds
2023-06-04 20:38:22,391:INFO:Declaring metric variables
2023-06-04 20:38:22,392:INFO:Importing untrained model
2023-06-04 20:38:22,392:INFO:K Neighbors Classifier Imported successfully
2023-06-04 20:38:22,393:INFO:Starting cross validation
2023-06-04 20:38:22,395:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:38:29,092:INFO:Calculating mean and std
2023-06-04 20:38:29,094:INFO:Creating metrics dataframe
2023-06-04 20:38:29,315:INFO:Uploading results into container
2023-06-04 20:38:29,316:INFO:Uploading model into container now
2023-06-04 20:38:29,317:INFO:_master_model_container: 2
2023-06-04 20:38:29,317:INFO:_display_container: 2
2023-06-04 20:38:29,318:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-04 20:38:29,318:INFO:create_model() successfully completed......................................
2023-06-04 20:38:29,486:INFO:SubProcess create_model() end ==================================
2023-06-04 20:38:29,486:INFO:Creating metrics dataframe
2023-06-04 20:38:29,498:INFO:Initializing Naive Bayes
2023-06-04 20:38:29,498:INFO:Total runtime is 0.2763710141181946 minutes
2023-06-04 20:38:29,499:INFO:SubProcess create_model() called ==================================
2023-06-04 20:38:29,499:INFO:Initializing create_model()
2023-06-04 20:38:29,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:38:29,499:INFO:Checking exceptions
2023-06-04 20:38:29,499:INFO:Importing libraries
2023-06-04 20:38:29,500:INFO:Copying training dataset
2023-06-04 20:38:29,528:INFO:Defining folds
2023-06-04 20:38:29,528:INFO:Declaring metric variables
2023-06-04 20:38:29,529:INFO:Importing untrained model
2023-06-04 20:38:29,529:INFO:Naive Bayes Imported successfully
2023-06-04 20:38:29,530:INFO:Starting cross validation
2023-06-04 20:38:29,531:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:38:30,729:INFO:Calculating mean and std
2023-06-04 20:38:30,730:INFO:Creating metrics dataframe
2023-06-04 20:38:30,887:INFO:Uploading results into container
2023-06-04 20:38:30,888:INFO:Uploading model into container now
2023-06-04 20:38:30,889:INFO:_master_model_container: 3
2023-06-04 20:38:30,889:INFO:_display_container: 2
2023-06-04 20:38:30,889:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-04 20:38:30,889:INFO:create_model() successfully completed......................................
2023-06-04 20:38:31,028:INFO:SubProcess create_model() end ==================================
2023-06-04 20:38:31,028:INFO:Creating metrics dataframe
2023-06-04 20:38:31,042:INFO:Initializing Decision Tree Classifier
2023-06-04 20:38:31,043:INFO:Total runtime is 0.3021195928255717 minutes
2023-06-04 20:38:31,043:INFO:SubProcess create_model() called ==================================
2023-06-04 20:38:31,044:INFO:Initializing create_model()
2023-06-04 20:38:31,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:38:31,044:INFO:Checking exceptions
2023-06-04 20:38:31,044:INFO:Importing libraries
2023-06-04 20:38:31,045:INFO:Copying training dataset
2023-06-04 20:38:31,083:INFO:Defining folds
2023-06-04 20:38:31,083:INFO:Declaring metric variables
2023-06-04 20:38:31,083:INFO:Importing untrained model
2023-06-04 20:38:31,084:INFO:Decision Tree Classifier Imported successfully
2023-06-04 20:38:31,085:INFO:Starting cross validation
2023-06-04 20:38:31,087:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:38:32,340:INFO:Calculating mean and std
2023-06-04 20:38:32,341:INFO:Creating metrics dataframe
2023-06-04 20:38:32,534:INFO:Uploading results into container
2023-06-04 20:38:32,535:INFO:Uploading model into container now
2023-06-04 20:38:32,536:INFO:_master_model_container: 4
2023-06-04 20:38:32,536:INFO:_display_container: 2
2023-06-04 20:38:32,536:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-04 20:38:32,537:INFO:create_model() successfully completed......................................
2023-06-04 20:38:32,680:INFO:SubProcess create_model() end ==================================
2023-06-04 20:38:32,681:INFO:Creating metrics dataframe
2023-06-04 20:38:32,690:INFO:Initializing SVM - Linear Kernel
2023-06-04 20:38:32,691:INFO:Total runtime is 0.329597806930542 minutes
2023-06-04 20:38:32,691:INFO:SubProcess create_model() called ==================================
2023-06-04 20:38:32,691:INFO:Initializing create_model()
2023-06-04 20:38:32,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:38:32,692:INFO:Checking exceptions
2023-06-04 20:38:32,692:INFO:Importing libraries
2023-06-04 20:38:32,692:INFO:Copying training dataset
2023-06-04 20:38:32,722:INFO:Defining folds
2023-06-04 20:38:32,722:INFO:Declaring metric variables
2023-06-04 20:38:32,723:INFO:Importing untrained model
2023-06-04 20:38:32,723:INFO:SVM - Linear Kernel Imported successfully
2023-06-04 20:38:32,725:INFO:Starting cross validation
2023-06-04 20:38:32,726:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:38:34,571:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 20:38:34,593:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 20:38:34,945:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 20:38:35,052:INFO:Calculating mean and std
2023-06-04 20:38:35,053:INFO:Creating metrics dataframe
2023-06-04 20:38:35,207:INFO:Uploading results into container
2023-06-04 20:38:35,208:INFO:Uploading model into container now
2023-06-04 20:38:35,209:INFO:_master_model_container: 5
2023-06-04 20:38:35,210:INFO:_display_container: 2
2023-06-04 20:38:35,210:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-04 20:38:35,211:INFO:create_model() successfully completed......................................
2023-06-04 20:38:35,417:INFO:SubProcess create_model() end ==================================
2023-06-04 20:38:35,418:INFO:Creating metrics dataframe
2023-06-04 20:38:35,428:INFO:Initializing Ridge Classifier
2023-06-04 20:38:35,429:INFO:Total runtime is 0.37521988153457647 minutes
2023-06-04 20:38:35,429:INFO:SubProcess create_model() called ==================================
2023-06-04 20:38:35,430:INFO:Initializing create_model()
2023-06-04 20:38:35,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:38:35,430:INFO:Checking exceptions
2023-06-04 20:38:35,430:INFO:Importing libraries
2023-06-04 20:38:35,431:INFO:Copying training dataset
2023-06-04 20:38:35,479:INFO:Defining folds
2023-06-04 20:38:35,479:INFO:Declaring metric variables
2023-06-04 20:38:35,479:INFO:Importing untrained model
2023-06-04 20:38:35,480:INFO:Ridge Classifier Imported successfully
2023-06-04 20:38:35,481:INFO:Starting cross validation
2023-06-04 20:38:35,483:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:38:36,108:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 20:38:36,126:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 20:38:36,154:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 20:38:36,158:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 20:38:36,618:INFO:Calculating mean and std
2023-06-04 20:38:36,619:INFO:Creating metrics dataframe
2023-06-04 20:38:36,824:INFO:Uploading results into container
2023-06-04 20:38:36,826:INFO:Uploading model into container now
2023-06-04 20:38:36,827:INFO:_master_model_container: 6
2023-06-04 20:38:36,828:INFO:_display_container: 2
2023-06-04 20:38:36,829:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-04 20:38:36,829:INFO:create_model() successfully completed......................................
2023-06-04 20:38:37,029:INFO:SubProcess create_model() end ==================================
2023-06-04 20:38:37,030:INFO:Creating metrics dataframe
2023-06-04 20:38:37,043:INFO:Initializing Random Forest Classifier
2023-06-04 20:38:37,044:INFO:Total runtime is 0.4021403312683106 minutes
2023-06-04 20:38:37,044:INFO:SubProcess create_model() called ==================================
2023-06-04 20:38:37,044:INFO:Initializing create_model()
2023-06-04 20:38:37,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:38:37,045:INFO:Checking exceptions
2023-06-04 20:38:37,045:INFO:Importing libraries
2023-06-04 20:38:37,045:INFO:Copying training dataset
2023-06-04 20:38:37,123:INFO:Defining folds
2023-06-04 20:38:37,123:INFO:Declaring metric variables
2023-06-04 20:38:37,124:INFO:Importing untrained model
2023-06-04 20:38:37,125:INFO:Random Forest Classifier Imported successfully
2023-06-04 20:38:37,126:INFO:Starting cross validation
2023-06-04 20:38:37,129:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:38:43,005:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:38:43,021:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:38:44,536:INFO:Calculating mean and std
2023-06-04 20:38:44,538:INFO:Creating metrics dataframe
2023-06-04 20:38:44,848:INFO:Uploading results into container
2023-06-04 20:38:44,850:INFO:Uploading model into container now
2023-06-04 20:38:44,851:INFO:_master_model_container: 7
2023-06-04 20:38:44,851:INFO:_display_container: 2
2023-06-04 20:38:44,852:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-04 20:38:44,853:INFO:create_model() successfully completed......................................
2023-06-04 20:38:45,012:INFO:SubProcess create_model() end ==================================
2023-06-04 20:38:45,013:INFO:Creating metrics dataframe
2023-06-04 20:38:45,027:INFO:Initializing Quadratic Discriminant Analysis
2023-06-04 20:38:45,027:INFO:Total runtime is 0.5351946552594503 minutes
2023-06-04 20:38:45,028:INFO:SubProcess create_model() called ==================================
2023-06-04 20:38:45,028:INFO:Initializing create_model()
2023-06-04 20:38:45,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:38:45,029:INFO:Checking exceptions
2023-06-04 20:38:45,029:INFO:Importing libraries
2023-06-04 20:38:45,029:INFO:Copying training dataset
2023-06-04 20:38:45,068:INFO:Defining folds
2023-06-04 20:38:45,068:INFO:Declaring metric variables
2023-06-04 20:38:45,069:INFO:Importing untrained model
2023-06-04 20:38:45,070:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-04 20:38:45,070:INFO:Starting cross validation
2023-06-04 20:38:45,072:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:38:46,260:INFO:Calculating mean and std
2023-06-04 20:38:46,261:INFO:Creating metrics dataframe
2023-06-04 20:38:46,399:INFO:Uploading results into container
2023-06-04 20:38:46,400:INFO:Uploading model into container now
2023-06-04 20:38:46,400:INFO:_master_model_container: 8
2023-06-04 20:38:46,400:INFO:_display_container: 2
2023-06-04 20:38:46,401:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-04 20:38:46,401:INFO:create_model() successfully completed......................................
2023-06-04 20:38:46,511:INFO:SubProcess create_model() end ==================================
2023-06-04 20:38:46,511:INFO:Creating metrics dataframe
2023-06-04 20:38:46,520:INFO:Initializing Ada Boost Classifier
2023-06-04 20:38:46,520:INFO:Total runtime is 0.5600734949111938 minutes
2023-06-04 20:38:46,520:INFO:SubProcess create_model() called ==================================
2023-06-04 20:38:46,521:INFO:Initializing create_model()
2023-06-04 20:38:46,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:38:46,521:INFO:Checking exceptions
2023-06-04 20:38:46,521:INFO:Importing libraries
2023-06-04 20:38:46,521:INFO:Copying training dataset
2023-06-04 20:38:46,544:INFO:Defining folds
2023-06-04 20:38:46,544:INFO:Declaring metric variables
2023-06-04 20:38:46,544:INFO:Importing untrained model
2023-06-04 20:38:46,545:INFO:Ada Boost Classifier Imported successfully
2023-06-04 20:38:46,545:INFO:Starting cross validation
2023-06-04 20:38:46,546:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:38:51,276:INFO:Calculating mean and std
2023-06-04 20:38:51,278:INFO:Creating metrics dataframe
2023-06-04 20:38:51,453:INFO:Uploading results into container
2023-06-04 20:38:51,454:INFO:Uploading model into container now
2023-06-04 20:38:51,456:INFO:_master_model_container: 9
2023-06-04 20:38:51,456:INFO:_display_container: 2
2023-06-04 20:38:51,456:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-04 20:38:51,456:INFO:create_model() successfully completed......................................
2023-06-04 20:38:51,632:INFO:SubProcess create_model() end ==================================
2023-06-04 20:38:51,632:INFO:Creating metrics dataframe
2023-06-04 20:38:51,642:INFO:Initializing Gradient Boosting Classifier
2023-06-04 20:38:51,642:INFO:Total runtime is 0.6454399863878886 minutes
2023-06-04 20:38:51,643:INFO:SubProcess create_model() called ==================================
2023-06-04 20:38:51,643:INFO:Initializing create_model()
2023-06-04 20:38:51,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:38:51,643:INFO:Checking exceptions
2023-06-04 20:38:51,643:INFO:Importing libraries
2023-06-04 20:38:51,643:INFO:Copying training dataset
2023-06-04 20:38:51,691:INFO:Defining folds
2023-06-04 20:38:51,692:INFO:Declaring metric variables
2023-06-04 20:38:51,692:INFO:Importing untrained model
2023-06-04 20:38:51,693:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 20:38:51,694:INFO:Starting cross validation
2023-06-04 20:38:51,696:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:39:01,297:INFO:Calculating mean and std
2023-06-04 20:39:01,297:INFO:Creating metrics dataframe
2023-06-04 20:39:01,414:INFO:Uploading results into container
2023-06-04 20:39:01,415:INFO:Uploading model into container now
2023-06-04 20:39:01,416:INFO:_master_model_container: 10
2023-06-04 20:39:01,416:INFO:_display_container: 2
2023-06-04 20:39:01,416:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:39:01,416:INFO:create_model() successfully completed......................................
2023-06-04 20:39:01,533:INFO:SubProcess create_model() end ==================================
2023-06-04 20:39:01,533:INFO:Creating metrics dataframe
2023-06-04 20:39:01,541:INFO:Initializing Linear Discriminant Analysis
2023-06-04 20:39:01,541:INFO:Total runtime is 0.810428516070048 minutes
2023-06-04 20:39:01,542:INFO:SubProcess create_model() called ==================================
2023-06-04 20:39:01,542:INFO:Initializing create_model()
2023-06-04 20:39:01,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:39:01,543:INFO:Checking exceptions
2023-06-04 20:39:01,543:INFO:Importing libraries
2023-06-04 20:39:01,543:INFO:Copying training dataset
2023-06-04 20:39:01,568:INFO:Defining folds
2023-06-04 20:39:01,569:INFO:Declaring metric variables
2023-06-04 20:39:01,569:INFO:Importing untrained model
2023-06-04 20:39:01,569:INFO:Linear Discriminant Analysis Imported successfully
2023-06-04 20:39:01,569:INFO:Starting cross validation
2023-06-04 20:39:01,570:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:39:02,470:INFO:Calculating mean and std
2023-06-04 20:39:02,471:INFO:Creating metrics dataframe
2023-06-04 20:39:02,579:INFO:Uploading results into container
2023-06-04 20:39:02,579:INFO:Uploading model into container now
2023-06-04 20:39:02,580:INFO:_master_model_container: 11
2023-06-04 20:39:02,580:INFO:_display_container: 2
2023-06-04 20:39:02,580:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-04 20:39:02,580:INFO:create_model() successfully completed......................................
2023-06-04 20:39:02,715:INFO:SubProcess create_model() end ==================================
2023-06-04 20:39:02,715:INFO:Creating metrics dataframe
2023-06-04 20:39:02,727:INFO:Initializing Extra Trees Classifier
2023-06-04 20:39:02,727:INFO:Total runtime is 0.8301835894584655 minutes
2023-06-04 20:39:02,727:INFO:SubProcess create_model() called ==================================
2023-06-04 20:39:02,728:INFO:Initializing create_model()
2023-06-04 20:39:02,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:39:02,728:INFO:Checking exceptions
2023-06-04 20:39:02,728:INFO:Importing libraries
2023-06-04 20:39:02,728:INFO:Copying training dataset
2023-06-04 20:39:02,767:INFO:Defining folds
2023-06-04 20:39:02,768:INFO:Declaring metric variables
2023-06-04 20:39:02,768:INFO:Importing untrained model
2023-06-04 20:39:02,769:INFO:Extra Trees Classifier Imported successfully
2023-06-04 20:39:02,769:INFO:Starting cross validation
2023-06-04 20:39:02,770:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:39:09,156:INFO:Calculating mean and std
2023-06-04 20:39:09,157:INFO:Creating metrics dataframe
2023-06-04 20:39:09,366:INFO:Uploading results into container
2023-06-04 20:39:09,367:INFO:Uploading model into container now
2023-06-04 20:39:09,367:INFO:_master_model_container: 12
2023-06-04 20:39:09,367:INFO:_display_container: 2
2023-06-04 20:39:09,368:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-04 20:39:09,368:INFO:create_model() successfully completed......................................
2023-06-04 20:39:09,513:INFO:SubProcess create_model() end ==================================
2023-06-04 20:39:09,514:INFO:Creating metrics dataframe
2023-06-04 20:39:09,527:INFO:Initializing Light Gradient Boosting Machine
2023-06-04 20:39:09,527:INFO:Total runtime is 0.9435311317443846 minutes
2023-06-04 20:39:09,528:INFO:SubProcess create_model() called ==================================
2023-06-04 20:39:09,528:INFO:Initializing create_model()
2023-06-04 20:39:09,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:39:09,529:INFO:Checking exceptions
2023-06-04 20:39:09,529:INFO:Importing libraries
2023-06-04 20:39:09,529:INFO:Copying training dataset
2023-06-04 20:39:09,571:INFO:Defining folds
2023-06-04 20:39:09,571:INFO:Declaring metric variables
2023-06-04 20:39:09,571:INFO:Importing untrained model
2023-06-04 20:39:09,572:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-04 20:39:09,572:INFO:Starting cross validation
2023-06-04 20:39:09,575:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:39:11,366:INFO:Calculating mean and std
2023-06-04 20:39:11,367:INFO:Creating metrics dataframe
2023-06-04 20:39:11,492:INFO:Uploading results into container
2023-06-04 20:39:11,492:INFO:Uploading model into container now
2023-06-04 20:39:11,493:INFO:_master_model_container: 13
2023-06-04 20:39:11,493:INFO:_display_container: 2
2023-06-04 20:39:11,493:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-04 20:39:11,493:INFO:create_model() successfully completed......................................
2023-06-04 20:39:11,616:INFO:SubProcess create_model() end ==================================
2023-06-04 20:39:11,616:INFO:Creating metrics dataframe
2023-06-04 20:39:11,624:INFO:Initializing Dummy Classifier
2023-06-04 20:39:11,624:INFO:Total runtime is 0.9784729441006977 minutes
2023-06-04 20:39:11,624:INFO:SubProcess create_model() called ==================================
2023-06-04 20:39:11,624:INFO:Initializing create_model()
2023-06-04 20:39:11,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A95E07110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:39:11,624:INFO:Checking exceptions
2023-06-04 20:39:11,625:INFO:Importing libraries
2023-06-04 20:39:11,625:INFO:Copying training dataset
2023-06-04 20:39:11,647:INFO:Defining folds
2023-06-04 20:39:11,647:INFO:Declaring metric variables
2023-06-04 20:39:11,647:INFO:Importing untrained model
2023-06-04 20:39:11,648:INFO:Dummy Classifier Imported successfully
2023-06-04 20:39:11,648:INFO:Starting cross validation
2023-06-04 20:39:11,649:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:39:12,032:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 20:39:12,047:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 20:39:12,089:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 20:39:12,098:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 20:39:12,364:INFO:Calculating mean and std
2023-06-04 20:39:12,365:INFO:Creating metrics dataframe
2023-06-04 20:39:12,490:INFO:Uploading results into container
2023-06-04 20:39:12,491:INFO:Uploading model into container now
2023-06-04 20:39:12,491:INFO:_master_model_container: 14
2023-06-04 20:39:12,491:INFO:_display_container: 2
2023-06-04 20:39:12,491:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-04 20:39:12,492:INFO:create_model() successfully completed......................................
2023-06-04 20:39:12,607:INFO:SubProcess create_model() end ==================================
2023-06-04 20:39:12,608:INFO:Creating metrics dataframe
2023-06-04 20:39:12,620:INFO:Initializing create_model()
2023-06-04 20:39:12,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:39:12,620:INFO:Checking exceptions
2023-06-04 20:39:12,621:INFO:Importing libraries
2023-06-04 20:39:12,622:INFO:Copying training dataset
2023-06-04 20:39:12,651:INFO:Defining folds
2023-06-04 20:39:12,651:INFO:Declaring metric variables
2023-06-04 20:39:12,651:INFO:Importing untrained model
2023-06-04 20:39:12,651:INFO:Declaring custom model
2023-06-04 20:39:12,652:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 20:39:12,653:INFO:Cross validation set to False
2023-06-04 20:39:12,654:INFO:Fitting Model
2023-06-04 20:39:18,716:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:39:18,716:INFO:create_model() successfully completed......................................
2023-06-04 20:39:18,938:INFO:_master_model_container: 14
2023-06-04 20:39:18,938:INFO:_display_container: 2
2023-06-04 20:39:18,939:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:39:18,939:INFO:compare_models() successfully completed......................................
2023-06-04 20:39:18,940:INFO:Initializing evaluate_model()
2023-06-04 20:39:18,940:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-04 20:39:19,283:INFO:Initializing plot_model()
2023-06-04 20:39:19,283:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, use_train_data=False, verbose=False, system=True, display=None, display_format=None)
2023-06-04 20:39:19,283:INFO:Checking exceptions
2023-06-04 20:39:19,297:INFO:Preloading libraries
2023-06-04 20:39:19,312:INFO:Copying training dataset
2023-06-04 20:39:19,312:INFO:Plot type: pipeline
2023-06-04 20:39:19,396:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:572: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  fig, ax = plt.subplots(

2023-06-04 20:39:19,646:INFO:Initializing tune_model()
2023-06-04 20:39:19,646:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2023-06-04 20:39:19,646:INFO:Checking exceptions
2023-06-04 20:39:19,660:INFO:Copying training dataset
2023-06-04 20:39:19,680:INFO:Checking base model
2023-06-04 20:39:19,680:INFO:Base model : Gradient Boosting Classifier
2023-06-04 20:39:19,681:INFO:Declaring metric variables
2023-06-04 20:39:19,681:INFO:Defining Hyperparameters
2023-06-04 20:39:19,808:INFO:Tuning with n_jobs=-1
2023-06-04 20:39:19,808:INFO:Initializing RandomizedSearchCV
2023-06-04 20:39:21,336:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:39:21,406:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:39:54,486:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:39:54,599:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:39:55,380:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:39:57,054:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:00,237:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:01,547:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:03,576:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:07,609:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:10,186:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:10,724:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:13,285:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:14,973:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:15,230:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:15,996:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:16,630:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:17,425:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:17,495:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:20,194:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:21,451:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:22,484:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:22,874:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:22,915:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:23,303:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:24,584:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:26,334:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:26,459:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:26,483:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:26,497:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:28,303:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:28,350:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:29,019:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:29,030:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:30,709:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:30,710:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:30,824:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:30,989:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:31,329:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:31,330:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:33,022:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-04 20:40:34,377:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-04 20:40:34,620:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:35,247:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:35,284:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-04 20:40:35,492:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-04 20:40:36,681:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:37,379:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:37,897:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 2.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:37,921:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:40:38,482:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:38,956:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:39,337:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:40,903:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:41,335:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:41,438:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:40:43,147:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-04 20:40:43,540:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:43,712:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-04 20:40:43,749:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:44,594:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:40:47,246:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-04 20:41:04,531:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:41:09,296:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:41:10,057:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:10,126:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:41:12,446:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:12,898:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:17,915:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:23,577:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:28,317:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:41:29,435:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:29,437:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:30,780:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:30,965:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:35,054:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:36,570:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:41:37,600:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:38,184:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:41:39,011:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:40,973:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:41:58,286:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:41:59,062:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:03,102:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:42:03,243:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:03,618:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:42:05,035:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:05,786:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:06,202:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:07,885:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:42:08,275:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:08,853:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:42:10,759:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:42:27,232:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:42:42,492:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:44,217:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:42:45,323:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:46,319:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:46,348:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:46,842:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:47,877:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:42:48,102:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:42:49,463:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:42:51,499:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:43:00,008:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:43:01,172:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:43:04,619:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:43:05,802:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:43:14,420:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:43:44,325:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:43:45,081:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:43:45,767:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:43:46,811:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:43:47,429:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:43:48,450:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:43:49,107:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:43:50,531:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-04 20:43:51,406:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:44:08,097:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-06-04 20:44:08,098:INFO:Hyperparameter search completed
2023-06-04 20:44:08,098:INFO:SubProcess create_model() called ==================================
2023-06-04 20:44:08,100:INFO:Initializing create_model()
2023-06-04 20:44:08,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A96F878D0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-06-04 20:44:08,101:INFO:Checking exceptions
2023-06-04 20:44:08,101:INFO:Importing libraries
2023-06-04 20:44:08,101:INFO:Copying training dataset
2023-06-04 20:44:08,150:INFO:Defining folds
2023-06-04 20:44:08,150:INFO:Declaring metric variables
2023-06-04 20:44:08,151:INFO:Importing untrained model
2023-06-04 20:44:08,151:INFO:Declaring custom model
2023-06-04 20:44:08,152:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 20:44:08,152:INFO:Starting cross validation
2023-06-04 20:44:08,153:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:44:12,127:INFO:Calculating mean and std
2023-06-04 20:44:12,128:INFO:Creating metrics dataframe
2023-06-04 20:44:12,132:INFO:Finalizing model
2023-06-04 20:44:18,144:INFO:Uploading results into container
2023-06-04 20:44:18,145:INFO:Uploading model into container now
2023-06-04 20:44:18,145:INFO:_master_model_container: 15
2023-06-04 20:44:18,145:INFO:_display_container: 3
2023-06-04 20:44:18,146:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:44:18,146:INFO:create_model() successfully completed......................................
2023-06-04 20:44:18,298:INFO:SubProcess create_model() end ==================================
2023-06-04 20:44:18,298:INFO:choose_better activated
2023-06-04 20:44:18,299:INFO:SubProcess create_model() called ==================================
2023-06-04 20:44:18,300:INFO:Initializing create_model()
2023-06-04 20:44:18,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A94ED8310>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:44:18,300:INFO:Checking exceptions
2023-06-04 20:44:18,302:INFO:Importing libraries
2023-06-04 20:44:18,302:INFO:Copying training dataset
2023-06-04 20:44:18,336:INFO:Defining folds
2023-06-04 20:44:18,336:INFO:Declaring metric variables
2023-06-04 20:44:18,337:INFO:Importing untrained model
2023-06-04 20:44:18,337:INFO:Declaring custom model
2023-06-04 20:44:18,338:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 20:44:18,339:INFO:Starting cross validation
2023-06-04 20:44:18,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:44:37,677:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-04 20:44:39,070:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:44:39,126:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:44:39,337:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:44:39,816:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:44:40,869:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:44:48,045:INFO:Calculating mean and std
2023-06-04 20:44:48,046:INFO:Creating metrics dataframe
2023-06-04 20:44:48,048:INFO:Finalizing model
2023-06-04 20:44:48,633:INFO:Uploading results into container
2023-06-04 20:44:48,633:INFO:Uploading model into container now
2023-06-04 20:44:48,634:INFO:_master_model_container: 16
2023-06-04 20:44:48,634:INFO:_display_container: 4
2023-06-04 20:44:48,634:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:44:48,634:INFO:create_model() successfully completed......................................
2023-06-04 20:44:48,797:INFO:SubProcess create_model() end ==================================
2023-06-04 20:44:48,799:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-04 20:44:48,801:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-04 20:44:48,802:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-06-04 20:44:48,803:INFO:choose_better completed
2023-06-04 20:44:48,804:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-04 20:44:48,840:INFO:_master_model_container: 16
2023-06-04 20:44:48,841:INFO:_display_container: 3
2023-06-04 20:44:48,842:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:44:48,842:INFO:tune_model() successfully completed......................................
2023-06-04 20:48:48,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 20:48:48,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 20:48:48,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 20:48:48,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 20:48:49,547:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-04 20:49:01,330:INFO:PyCaret ClassificationExperiment
2023-06-04 20:49:01,330:INFO:Logging name: clf-default-name
2023-06-04 20:49:01,330:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-04 20:49:01,331:INFO:version 3.0.0
2023-06-04 20:49:01,331:INFO:Initializing setup()
2023-06-04 20:49:01,331:INFO:self.USI: d030
2023-06-04 20:49:01,331:INFO:self._variable_keys: {'seed', 'n_jobs_param', 'X_train', '_available_plots', 'fold_groups_param', 'is_multiclass', 'y_test', 'exp_name_log', 'target_param', 'idx', 'gpu_param', 'gpu_n_jobs_param', 'fold_generator', 'log_plots_param', 'pipeline', 'fold_shuffle_param', 'data', 'X', 'y', 'logging_param', 'exp_id', 'html_param', 'X_test', 'y_train', 'memory', 'USI', 'fix_imbalance', '_ml_usecase'}
2023-06-04 20:49:01,331:INFO:Checking environment
2023-06-04 20:49:01,331:INFO:python_version: 3.11.3
2023-06-04 20:49:01,331:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2023-06-04 20:49:01,331:INFO:machine: AMD64
2023-06-04 20:49:01,355:INFO:platform: Windows-10-10.0.19045-SP0
2023-06-04 20:49:01,358:INFO:Memory: svmem(total=8384401408, available=1671118848, percent=80.1, used=6713282560, free=1671118848)
2023-06-04 20:49:01,358:INFO:Physical Core: 4
2023-06-04 20:49:01,359:INFO:Logical Core: 8
2023-06-04 20:49:01,359:INFO:Checking libraries
2023-06-04 20:49:01,359:INFO:System:
2023-06-04 20:49:01,359:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2023-06-04 20:49:01,359:INFO:executable: C:\Program Files\Python311\python.exe
2023-06-04 20:49:01,359:INFO:   machine: Windows-10-10.0.19045-SP0
2023-06-04 20:49:01,359:INFO:PyCaret required dependencies:
2023-06-04 20:49:01,359:INFO:                 pip: 22.3.1
2023-06-04 20:49:01,359:INFO:          setuptools: 65.5.0
2023-06-04 20:49:01,359:INFO:             pycaret: 3.0.0
2023-06-04 20:49:01,359:INFO:             IPython: 8.12.0
2023-06-04 20:49:01,360:INFO:          ipywidgets: 8.0.6
2023-06-04 20:49:01,360:INFO:                tqdm: 4.65.0
2023-06-04 20:49:01,360:INFO:               numpy: 1.24.3
2023-06-04 20:49:01,360:INFO:              pandas: 1.5.3
2023-06-04 20:49:01,360:INFO:              jinja2: 3.1.2
2023-06-04 20:49:01,360:INFO:               scipy: 1.10.1
2023-06-04 20:49:01,360:INFO:              joblib: 1.2.0
2023-06-04 20:49:01,360:INFO:             sklearn: 1.2.2
2023-06-04 20:49:01,360:INFO:                pyod: 1.0.9
2023-06-04 20:49:01,360:INFO:            imblearn: 0.10.1
2023-06-04 20:49:01,360:INFO:   category_encoders: 2.6.0
2023-06-04 20:49:01,361:INFO:            lightgbm: 3.3.5
2023-06-04 20:49:01,361:INFO:               numba: 0.57.0
2023-06-04 20:49:01,361:INFO:            requests: 2.28.2
2023-06-04 20:49:01,361:INFO:          matplotlib: 3.7.1
2023-06-04 20:49:01,361:INFO:          scikitplot: 0.3.7
2023-06-04 20:49:01,361:INFO:         yellowbrick: 1.5
2023-06-04 20:49:01,361:INFO:              plotly: 5.14.1
2023-06-04 20:49:01,361:INFO:             kaleido: 0.2.1
2023-06-04 20:49:01,361:INFO:         statsmodels: 0.14.0
2023-06-04 20:49:01,361:INFO:              sktime: 0.18.0
2023-06-04 20:49:01,361:INFO:               tbats: 1.1.3
2023-06-04 20:49:01,361:INFO:            pmdarima: 2.0.3
2023-06-04 20:49:01,362:INFO:              psutil: 5.9.4
2023-06-04 20:49:01,362:INFO:PyCaret optional dependencies:
2023-06-04 20:49:01,383:INFO:                shap: Not installed
2023-06-04 20:49:01,384:INFO:           interpret: Not installed
2023-06-04 20:49:01,384:INFO:                umap: Not installed
2023-06-04 20:49:01,384:INFO:    pandas_profiling: Not installed
2023-06-04 20:49:01,384:INFO:  explainerdashboard: Not installed
2023-06-04 20:49:01,384:INFO:             autoviz: Not installed
2023-06-04 20:49:01,384:INFO:           fairlearn: Not installed
2023-06-04 20:49:01,384:INFO:             xgboost: Not installed
2023-06-04 20:49:01,384:INFO:            catboost: Not installed
2023-06-04 20:49:01,384:INFO:              kmodes: Not installed
2023-06-04 20:49:01,384:INFO:             mlxtend: Not installed
2023-06-04 20:49:01,384:INFO:       statsforecast: Not installed
2023-06-04 20:49:01,384:INFO:        tune_sklearn: Not installed
2023-06-04 20:49:01,385:INFO:                 ray: Not installed
2023-06-04 20:49:01,385:INFO:            hyperopt: Not installed
2023-06-04 20:49:01,385:INFO:              optuna: Not installed
2023-06-04 20:49:01,385:INFO:               skopt: Not installed
2023-06-04 20:49:01,385:INFO:              mlflow: Not installed
2023-06-04 20:49:01,385:INFO:              gradio: Not installed
2023-06-04 20:49:01,385:INFO:             fastapi: Not installed
2023-06-04 20:49:01,385:INFO:             uvicorn: Not installed
2023-06-04 20:49:01,385:INFO:              m2cgen: Not installed
2023-06-04 20:49:01,385:INFO:           evidently: Not installed
2023-06-04 20:49:01,385:INFO:               fugue: Not installed
2023-06-04 20:49:01,385:INFO:           streamlit: Not installed
2023-06-04 20:49:01,385:INFO:             prophet: 1.1.2
2023-06-04 20:49:01,386:INFO:None
2023-06-04 20:49:01,386:INFO:Set up data.
2023-06-04 20:49:01,410:INFO:Set up train/test split.
2023-06-04 20:49:01,441:INFO:Set up index.
2023-06-04 20:49:01,441:INFO:Set up folding strategy.
2023-06-04 20:49:01,442:INFO:Assigning column types.
2023-06-04 20:49:01,450:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-04 20:49:01,490:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 20:49:01,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 20:49:01,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:01,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:01,587:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 20:49:01,588:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 20:49:01,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:01,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:01,614:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-04 20:49:01,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 20:49:01,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:01,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:01,858:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 20:49:01,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:01,925:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:01,925:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-04 20:49:02,086:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:02,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:02,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:02,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:02,281:INFO:Preparing preprocessing pipeline...
2023-06-04 20:49:02,286:INFO:Set up simple imputation.
2023-06-04 20:49:02,307:INFO:Set up encoding of ordinal features.
2023-06-04 20:49:02,314:INFO:Set up encoding of categorical features.
2023-06-04 20:49:02,555:INFO:Finished creating preprocessing pipeline.
2023-06-04 20:49:02,596:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\shiva\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'hypertension',
                                             'heart_disease', 'smoking_history',
                                             'bmi', 'HbA1c_level',
                                             'blood_glucose_level'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['gender'],
                                    transformer=OrdinalEncoder(cols=['gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-06-04 20:49:02,596:INFO:Creating final display dataframe.
2023-06-04 20:49:03,066:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          diabetes
2                   Target type            Binary
3           Original data shape        (76885, 9)
4        Transformed data shape        (76885, 9)
5   Transformed train set shape        (57663, 9)
6    Transformed test set shape        (19222, 9)
7              Ordinal features                 1
8              Numeric features                 7
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              d030
2023-06-04 20:49:03,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:03,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:03,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:03,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 20:49:03,418:INFO:setup() successfully completed in 2.32s...............
2023-06-04 20:49:03,418:INFO:Initializing compare_models()
2023-06-04 20:49:03,418:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-06-04 20:49:03,418:INFO:Checking exceptions
2023-06-04 20:49:03,430:INFO:Preparing display monitor
2023-06-04 20:49:03,434:INFO:Initializing Logistic Regression
2023-06-04 20:49:03,434:INFO:Total runtime is 2.876917521158854e-06 minutes
2023-06-04 20:49:03,434:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:03,435:INFO:Initializing create_model()
2023-06-04 20:49:03,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:03,435:INFO:Checking exceptions
2023-06-04 20:49:03,435:INFO:Importing libraries
2023-06-04 20:49:03,435:INFO:Copying training dataset
2023-06-04 20:49:03,461:INFO:Defining folds
2023-06-04 20:49:03,461:INFO:Declaring metric variables
2023-06-04 20:49:03,462:INFO:Importing untrained model
2023-06-04 20:49:03,462:INFO:Logistic Regression Imported successfully
2023-06-04 20:49:03,462:INFO:Starting cross validation
2023-06-04 20:49:03,464:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:13,078:INFO:Calculating mean and std
2023-06-04 20:49:13,080:INFO:Creating metrics dataframe
2023-06-04 20:49:13,341:INFO:Uploading results into container
2023-06-04 20:49:13,342:INFO:Uploading model into container now
2023-06-04 20:49:13,343:INFO:_master_model_container: 1
2023-06-04 20:49:13,343:INFO:_display_container: 2
2023-06-04 20:49:13,344:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 20:49:13,344:INFO:create_model() successfully completed......................................
2023-06-04 20:49:13,465:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:13,465:INFO:Creating metrics dataframe
2023-06-04 20:49:13,471:INFO:Initializing K Neighbors Classifier
2023-06-04 20:49:13,471:INFO:Total runtime is 0.16729492346445718 minutes
2023-06-04 20:49:13,473:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:13,473:INFO:Initializing create_model()
2023-06-04 20:49:13,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:13,473:INFO:Checking exceptions
2023-06-04 20:49:13,473:INFO:Importing libraries
2023-06-04 20:49:13,473:INFO:Copying training dataset
2023-06-04 20:49:13,496:INFO:Defining folds
2023-06-04 20:49:13,496:INFO:Declaring metric variables
2023-06-04 20:49:13,497:INFO:Importing untrained model
2023-06-04 20:49:13,497:INFO:K Neighbors Classifier Imported successfully
2023-06-04 20:49:13,497:INFO:Starting cross validation
2023-06-04 20:49:13,498:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:18,075:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:49:20,661:INFO:Calculating mean and std
2023-06-04 20:49:20,663:INFO:Creating metrics dataframe
2023-06-04 20:49:21,092:INFO:Uploading results into container
2023-06-04 20:49:21,093:INFO:Uploading model into container now
2023-06-04 20:49:21,093:INFO:_master_model_container: 2
2023-06-04 20:49:21,093:INFO:_display_container: 2
2023-06-04 20:49:21,094:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-04 20:49:21,094:INFO:create_model() successfully completed......................................
2023-06-04 20:49:21,245:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:21,245:INFO:Creating metrics dataframe
2023-06-04 20:49:21,256:INFO:Initializing Naive Bayes
2023-06-04 20:49:21,256:INFO:Total runtime is 0.29704032739003494 minutes
2023-06-04 20:49:21,257:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:21,257:INFO:Initializing create_model()
2023-06-04 20:49:21,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:21,257:INFO:Checking exceptions
2023-06-04 20:49:21,258:INFO:Importing libraries
2023-06-04 20:49:21,258:INFO:Copying training dataset
2023-06-04 20:49:21,295:INFO:Defining folds
2023-06-04 20:49:21,296:INFO:Declaring metric variables
2023-06-04 20:49:21,296:INFO:Importing untrained model
2023-06-04 20:49:21,297:INFO:Naive Bayes Imported successfully
2023-06-04 20:49:21,297:INFO:Starting cross validation
2023-06-04 20:49:21,299:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:22,981:INFO:Calculating mean and std
2023-06-04 20:49:22,982:INFO:Creating metrics dataframe
2023-06-04 20:49:23,452:INFO:Uploading results into container
2023-06-04 20:49:23,454:INFO:Uploading model into container now
2023-06-04 20:49:23,454:INFO:_master_model_container: 3
2023-06-04 20:49:23,454:INFO:_display_container: 2
2023-06-04 20:49:23,454:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-04 20:49:23,455:INFO:create_model() successfully completed......................................
2023-06-04 20:49:23,586:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:23,587:INFO:Creating metrics dataframe
2023-06-04 20:49:23,595:INFO:Initializing Decision Tree Classifier
2023-06-04 20:49:23,595:INFO:Total runtime is 0.3360260407129923 minutes
2023-06-04 20:49:23,595:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:23,596:INFO:Initializing create_model()
2023-06-04 20:49:23,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:23,596:INFO:Checking exceptions
2023-06-04 20:49:23,596:INFO:Importing libraries
2023-06-04 20:49:23,596:INFO:Copying training dataset
2023-06-04 20:49:23,624:INFO:Defining folds
2023-06-04 20:49:23,624:INFO:Declaring metric variables
2023-06-04 20:49:23,625:INFO:Importing untrained model
2023-06-04 20:49:23,625:INFO:Decision Tree Classifier Imported successfully
2023-06-04 20:49:23,626:INFO:Starting cross validation
2023-06-04 20:49:23,628:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:25,385:INFO:Calculating mean and std
2023-06-04 20:49:25,386:INFO:Creating metrics dataframe
2023-06-04 20:49:25,895:INFO:Uploading results into container
2023-06-04 20:49:25,896:INFO:Uploading model into container now
2023-06-04 20:49:25,897:INFO:_master_model_container: 4
2023-06-04 20:49:25,897:INFO:_display_container: 2
2023-06-04 20:49:25,898:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-04 20:49:25,899:INFO:create_model() successfully completed......................................
2023-06-04 20:49:26,050:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:26,050:INFO:Creating metrics dataframe
2023-06-04 20:49:26,067:INFO:Initializing SVM - Linear Kernel
2023-06-04 20:49:26,067:INFO:Total runtime is 0.3772276878356933 minutes
2023-06-04 20:49:26,068:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:26,070:INFO:Initializing create_model()
2023-06-04 20:49:26,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:26,071:INFO:Checking exceptions
2023-06-04 20:49:26,071:INFO:Importing libraries
2023-06-04 20:49:26,072:INFO:Copying training dataset
2023-06-04 20:49:26,134:INFO:Defining folds
2023-06-04 20:49:26,135:INFO:Declaring metric variables
2023-06-04 20:49:26,135:INFO:Importing untrained model
2023-06-04 20:49:26,137:INFO:SVM - Linear Kernel Imported successfully
2023-06-04 20:49:26,138:INFO:Starting cross validation
2023-06-04 20:49:26,141:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:26,541:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 20:49:26,543:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 20:49:26,579:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 20:49:26,608:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 20:49:27,745:INFO:Calculating mean and std
2023-06-04 20:49:27,746:INFO:Creating metrics dataframe
2023-06-04 20:49:28,141:INFO:Uploading results into container
2023-06-04 20:49:28,142:INFO:Uploading model into container now
2023-06-04 20:49:28,143:INFO:_master_model_container: 5
2023-06-04 20:49:28,143:INFO:_display_container: 2
2023-06-04 20:49:28,143:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-04 20:49:28,144:INFO:create_model() successfully completed......................................
2023-06-04 20:49:28,319:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:28,319:INFO:Creating metrics dataframe
2023-06-04 20:49:28,328:INFO:Initializing Ridge Classifier
2023-06-04 20:49:28,329:INFO:Total runtime is 0.41491182645161945 minutes
2023-06-04 20:49:28,329:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:28,329:INFO:Initializing create_model()
2023-06-04 20:49:28,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:28,330:INFO:Checking exceptions
2023-06-04 20:49:28,330:INFO:Importing libraries
2023-06-04 20:49:28,330:INFO:Copying training dataset
2023-06-04 20:49:28,380:INFO:Defining folds
2023-06-04 20:49:28,382:INFO:Declaring metric variables
2023-06-04 20:49:28,382:INFO:Importing untrained model
2023-06-04 20:49:28,386:INFO:Ridge Classifier Imported successfully
2023-06-04 20:49:28,387:INFO:Starting cross validation
2023-06-04 20:49:28,391:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:28,822:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 20:49:28,849:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 20:49:28,979:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 20:49:28,986:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 20:49:29,976:INFO:Calculating mean and std
2023-06-04 20:49:29,977:INFO:Creating metrics dataframe
2023-06-04 20:49:30,429:INFO:Uploading results into container
2023-06-04 20:49:30,431:INFO:Uploading model into container now
2023-06-04 20:49:30,432:INFO:_master_model_container: 6
2023-06-04 20:49:30,432:INFO:_display_container: 2
2023-06-04 20:49:30,433:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-04 20:49:30,433:INFO:create_model() successfully completed......................................
2023-06-04 20:49:30,577:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:30,577:INFO:Creating metrics dataframe
2023-06-04 20:49:30,588:INFO:Initializing Random Forest Classifier
2023-06-04 20:49:30,588:INFO:Total runtime is 0.45257559219996135 minutes
2023-06-04 20:49:30,588:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:30,589:INFO:Initializing create_model()
2023-06-04 20:49:30,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:30,589:INFO:Checking exceptions
2023-06-04 20:49:30,589:INFO:Importing libraries
2023-06-04 20:49:30,590:INFO:Copying training dataset
2023-06-04 20:49:30,628:INFO:Defining folds
2023-06-04 20:49:30,628:INFO:Declaring metric variables
2023-06-04 20:49:30,629:INFO:Importing untrained model
2023-06-04 20:49:30,629:INFO:Random Forest Classifier Imported successfully
2023-06-04 20:49:30,631:INFO:Starting cross validation
2023-06-04 20:49:30,632:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:33,084:INFO:Calculating mean and std
2023-06-04 20:49:33,086:INFO:Creating metrics dataframe
2023-06-04 20:49:33,540:INFO:Uploading results into container
2023-06-04 20:49:33,541:INFO:Uploading model into container now
2023-06-04 20:49:33,542:INFO:_master_model_container: 7
2023-06-04 20:49:33,542:INFO:_display_container: 2
2023-06-04 20:49:33,543:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-04 20:49:33,544:INFO:create_model() successfully completed......................................
2023-06-04 20:49:33,699:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:33,700:INFO:Creating metrics dataframe
2023-06-04 20:49:33,710:INFO:Initializing Quadratic Discriminant Analysis
2023-06-04 20:49:33,710:INFO:Total runtime is 0.5046090841293335 minutes
2023-06-04 20:49:33,710:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:33,711:INFO:Initializing create_model()
2023-06-04 20:49:33,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:33,711:INFO:Checking exceptions
2023-06-04 20:49:33,712:INFO:Importing libraries
2023-06-04 20:49:33,712:INFO:Copying training dataset
2023-06-04 20:49:33,747:INFO:Defining folds
2023-06-04 20:49:33,748:INFO:Declaring metric variables
2023-06-04 20:49:33,748:INFO:Importing untrained model
2023-06-04 20:49:33,749:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-04 20:49:33,749:INFO:Starting cross validation
2023-06-04 20:49:33,751:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:35,307:INFO:Calculating mean and std
2023-06-04 20:49:35,309:INFO:Creating metrics dataframe
2023-06-04 20:49:35,804:INFO:Uploading results into container
2023-06-04 20:49:35,805:INFO:Uploading model into container now
2023-06-04 20:49:35,806:INFO:_master_model_container: 8
2023-06-04 20:49:35,806:INFO:_display_container: 2
2023-06-04 20:49:35,807:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-04 20:49:35,807:INFO:create_model() successfully completed......................................
2023-06-04 20:49:35,938:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:35,938:INFO:Creating metrics dataframe
2023-06-04 20:49:35,949:INFO:Initializing Ada Boost Classifier
2023-06-04 20:49:35,950:INFO:Total runtime is 0.5419260819753011 minutes
2023-06-04 20:49:35,950:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:35,950:INFO:Initializing create_model()
2023-06-04 20:49:35,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:35,951:INFO:Checking exceptions
2023-06-04 20:49:35,951:INFO:Importing libraries
2023-06-04 20:49:35,951:INFO:Copying training dataset
2023-06-04 20:49:35,982:INFO:Defining folds
2023-06-04 20:49:35,982:INFO:Declaring metric variables
2023-06-04 20:49:35,983:INFO:Importing untrained model
2023-06-04 20:49:35,983:INFO:Ada Boost Classifier Imported successfully
2023-06-04 20:49:35,984:INFO:Starting cross validation
2023-06-04 20:49:35,985:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:38,057:INFO:Calculating mean and std
2023-06-04 20:49:38,058:INFO:Creating metrics dataframe
2023-06-04 20:49:38,455:INFO:Uploading results into container
2023-06-04 20:49:38,456:INFO:Uploading model into container now
2023-06-04 20:49:38,456:INFO:_master_model_container: 9
2023-06-04 20:49:38,457:INFO:_display_container: 2
2023-06-04 20:49:38,457:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-04 20:49:38,457:INFO:create_model() successfully completed......................................
2023-06-04 20:49:38,581:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:38,582:INFO:Creating metrics dataframe
2023-06-04 20:49:38,589:INFO:Initializing Gradient Boosting Classifier
2023-06-04 20:49:38,589:INFO:Total runtime is 0.5859253724416097 minutes
2023-06-04 20:49:38,590:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:38,590:INFO:Initializing create_model()
2023-06-04 20:49:38,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:38,590:INFO:Checking exceptions
2023-06-04 20:49:38,590:INFO:Importing libraries
2023-06-04 20:49:38,590:INFO:Copying training dataset
2023-06-04 20:49:38,619:INFO:Defining folds
2023-06-04 20:49:38,619:INFO:Declaring metric variables
2023-06-04 20:49:38,619:INFO:Importing untrained model
2023-06-04 20:49:38,620:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 20:49:38,621:INFO:Starting cross validation
2023-06-04 20:49:38,622:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:40,197:INFO:Calculating mean and std
2023-06-04 20:49:40,198:INFO:Creating metrics dataframe
2023-06-04 20:49:40,533:INFO:Uploading results into container
2023-06-04 20:49:40,535:INFO:Uploading model into container now
2023-06-04 20:49:40,536:INFO:_master_model_container: 10
2023-06-04 20:49:40,536:INFO:_display_container: 2
2023-06-04 20:49:40,536:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:49:40,537:INFO:create_model() successfully completed......................................
2023-06-04 20:49:40,689:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:40,689:INFO:Creating metrics dataframe
2023-06-04 20:49:40,698:INFO:Initializing Linear Discriminant Analysis
2023-06-04 20:49:40,698:INFO:Total runtime is 0.6210644801457723 minutes
2023-06-04 20:49:40,699:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:40,699:INFO:Initializing create_model()
2023-06-04 20:49:40,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:40,699:INFO:Checking exceptions
2023-06-04 20:49:40,699:INFO:Importing libraries
2023-06-04 20:49:40,700:INFO:Copying training dataset
2023-06-04 20:49:40,743:INFO:Defining folds
2023-06-04 20:49:40,743:INFO:Declaring metric variables
2023-06-04 20:49:40,743:INFO:Importing untrained model
2023-06-04 20:49:40,743:INFO:Linear Discriminant Analysis Imported successfully
2023-06-04 20:49:40,744:INFO:Starting cross validation
2023-06-04 20:49:40,745:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:42,368:INFO:Calculating mean and std
2023-06-04 20:49:42,369:INFO:Creating metrics dataframe
2023-06-04 20:49:42,733:INFO:Uploading results into container
2023-06-04 20:49:42,734:INFO:Uploading model into container now
2023-06-04 20:49:42,735:INFO:_master_model_container: 11
2023-06-04 20:49:42,735:INFO:_display_container: 2
2023-06-04 20:49:42,735:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-04 20:49:42,735:INFO:create_model() successfully completed......................................
2023-06-04 20:49:42,861:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:42,861:INFO:Creating metrics dataframe
2023-06-04 20:49:42,868:INFO:Initializing Extra Trees Classifier
2023-06-04 20:49:42,869:INFO:Total runtime is 0.6572515805562338 minutes
2023-06-04 20:49:42,869:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:42,870:INFO:Initializing create_model()
2023-06-04 20:49:42,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:42,870:INFO:Checking exceptions
2023-06-04 20:49:42,870:INFO:Importing libraries
2023-06-04 20:49:42,870:INFO:Copying training dataset
2023-06-04 20:49:42,899:INFO:Defining folds
2023-06-04 20:49:42,899:INFO:Declaring metric variables
2023-06-04 20:49:42,899:INFO:Importing untrained model
2023-06-04 20:49:42,900:INFO:Extra Trees Classifier Imported successfully
2023-06-04 20:49:42,900:INFO:Starting cross validation
2023-06-04 20:49:42,901:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:45,536:INFO:Calculating mean and std
2023-06-04 20:49:45,537:INFO:Creating metrics dataframe
2023-06-04 20:49:45,865:INFO:Uploading results into container
2023-06-04 20:49:45,866:INFO:Uploading model into container now
2023-06-04 20:49:45,867:INFO:_master_model_container: 12
2023-06-04 20:49:45,867:INFO:_display_container: 2
2023-06-04 20:49:45,868:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-04 20:49:45,868:INFO:create_model() successfully completed......................................
2023-06-04 20:49:46,023:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:46,023:INFO:Creating metrics dataframe
2023-06-04 20:49:46,035:INFO:Initializing Light Gradient Boosting Machine
2023-06-04 20:49:46,035:INFO:Total runtime is 0.7100165128707886 minutes
2023-06-04 20:49:46,035:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:46,036:INFO:Initializing create_model()
2023-06-04 20:49:46,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:46,036:INFO:Checking exceptions
2023-06-04 20:49:46,036:INFO:Importing libraries
2023-06-04 20:49:46,038:INFO:Copying training dataset
2023-06-04 20:49:46,083:INFO:Defining folds
2023-06-04 20:49:46,083:INFO:Declaring metric variables
2023-06-04 20:49:46,084:INFO:Importing untrained model
2023-06-04 20:49:46,085:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-04 20:49:46,085:INFO:Starting cross validation
2023-06-04 20:49:46,087:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:48,297:INFO:Calculating mean and std
2023-06-04 20:49:48,298:INFO:Creating metrics dataframe
2023-06-04 20:49:48,631:INFO:Uploading results into container
2023-06-04 20:49:48,631:INFO:Uploading model into container now
2023-06-04 20:49:48,632:INFO:_master_model_container: 13
2023-06-04 20:49:48,632:INFO:_display_container: 2
2023-06-04 20:49:48,632:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-04 20:49:48,632:INFO:create_model() successfully completed......................................
2023-06-04 20:49:48,767:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:48,767:INFO:Creating metrics dataframe
2023-06-04 20:49:48,777:INFO:Initializing Dummy Classifier
2023-06-04 20:49:48,777:INFO:Total runtime is 0.7557127912839254 minutes
2023-06-04 20:49:48,777:INFO:SubProcess create_model() called ==================================
2023-06-04 20:49:48,778:INFO:Initializing create_model()
2023-06-04 20:49:48,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001133F40C750>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:48,778:INFO:Checking exceptions
2023-06-04 20:49:48,778:INFO:Importing libraries
2023-06-04 20:49:48,778:INFO:Copying training dataset
2023-06-04 20:49:48,809:INFO:Defining folds
2023-06-04 20:49:48,809:INFO:Declaring metric variables
2023-06-04 20:49:48,810:INFO:Importing untrained model
2023-06-04 20:49:48,810:INFO:Dummy Classifier Imported successfully
2023-06-04 20:49:48,810:INFO:Starting cross validation
2023-06-04 20:49:48,812:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:49:49,314:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 20:49:49,342:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 20:49:49,392:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 20:49:49,412:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 20:49:50,272:INFO:Calculating mean and std
2023-06-04 20:49:50,273:INFO:Creating metrics dataframe
2023-06-04 20:49:50,648:INFO:Uploading results into container
2023-06-04 20:49:50,649:INFO:Uploading model into container now
2023-06-04 20:49:50,650:INFO:_master_model_container: 14
2023-06-04 20:49:50,650:INFO:_display_container: 2
2023-06-04 20:49:50,650:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-04 20:49:50,650:INFO:create_model() successfully completed......................................
2023-06-04 20:49:50,794:INFO:SubProcess create_model() end ==================================
2023-06-04 20:49:50,794:INFO:Creating metrics dataframe
2023-06-04 20:49:50,810:INFO:Initializing create_model()
2023-06-04 20:49:50,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:49:50,810:INFO:Checking exceptions
2023-06-04 20:49:50,813:INFO:Importing libraries
2023-06-04 20:49:50,815:INFO:Copying training dataset
2023-06-04 20:49:50,853:INFO:Defining folds
2023-06-04 20:49:50,853:INFO:Declaring metric variables
2023-06-04 20:49:50,854:INFO:Importing untrained model
2023-06-04 20:49:50,854:INFO:Declaring custom model
2023-06-04 20:49:50,855:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 20:49:50,857:INFO:Cross validation set to False
2023-06-04 20:49:50,857:INFO:Fitting Model
2023-06-04 20:49:51,428:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:49:51,429:INFO:create_model() successfully completed......................................
2023-06-04 20:49:51,617:INFO:_master_model_container: 14
2023-06-04 20:49:51,618:INFO:_display_container: 2
2023-06-04 20:49:51,619:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:49:51,619:INFO:compare_models() successfully completed......................................
2023-06-04 20:49:51,620:INFO:Initializing evaluate_model()
2023-06-04 20:49:51,620:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-04 20:49:51,803:INFO:Initializing plot_model()
2023-06-04 20:49:51,803:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, use_train_data=False, verbose=False, system=True, display=None, display_format=None)
2023-06-04 20:49:51,803:INFO:Checking exceptions
2023-06-04 20:49:51,812:INFO:Preloading libraries
2023-06-04 20:49:51,823:INFO:Copying training dataset
2023-06-04 20:49:51,823:INFO:Plot type: pipeline
2023-06-04 20:49:51,879:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:572: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  fig, ax = plt.subplots(

2023-06-04 20:49:52,071:INFO:Initializing tune_model()
2023-06-04 20:49:52,071:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2023-06-04 20:49:52,071:INFO:Checking exceptions
2023-06-04 20:49:52,085:INFO:Copying training dataset
2023-06-04 20:49:52,114:INFO:Checking base model
2023-06-04 20:49:52,114:INFO:Base model : Gradient Boosting Classifier
2023-06-04 20:49:52,115:INFO:Declaring metric variables
2023-06-04 20:49:52,115:INFO:Defining Hyperparameters
2023-06-04 20:49:52,273:INFO:Tuning with n_jobs=-1
2023-06-04 20:49:52,273:INFO:Initializing RandomizedSearchCV
2023-06-04 20:49:55,424:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:49:55,810:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:50:35,050:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-06-04 20:50:35,051:INFO:Hyperparameter search completed
2023-06-04 20:50:35,051:INFO:SubProcess create_model() called ==================================
2023-06-04 20:50:35,051:INFO:Initializing create_model()
2023-06-04 20:50:35,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000113410EEBD0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-06-04 20:50:35,052:INFO:Checking exceptions
2023-06-04 20:50:35,052:INFO:Importing libraries
2023-06-04 20:50:35,052:INFO:Copying training dataset
2023-06-04 20:50:35,084:INFO:Defining folds
2023-06-04 20:50:35,084:INFO:Declaring metric variables
2023-06-04 20:50:35,084:INFO:Importing untrained model
2023-06-04 20:50:35,084:INFO:Declaring custom model
2023-06-04 20:50:35,085:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 20:50:35,085:INFO:Starting cross validation
2023-06-04 20:50:35,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:50:36,876:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:50:36,930:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:50:40,431:INFO:Calculating mean and std
2023-06-04 20:50:40,437:INFO:Creating metrics dataframe
2023-06-04 20:50:40,440:INFO:Finalizing model
2023-06-04 20:50:41,300:INFO:Uploading results into container
2023-06-04 20:50:41,301:INFO:Uploading model into container now
2023-06-04 20:50:41,301:INFO:_master_model_container: 15
2023-06-04 20:50:41,301:INFO:_display_container: 3
2023-06-04 20:50:41,302:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:50:41,302:INFO:create_model() successfully completed......................................
2023-06-04 20:50:41,463:INFO:SubProcess create_model() end ==================================
2023-06-04 20:50:41,467:INFO:choose_better activated
2023-06-04 20:50:41,467:INFO:SubProcess create_model() called ==================================
2023-06-04 20:50:41,467:INFO:Initializing create_model()
2023-06-04 20:50:41,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001133D435390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 20:50:41,467:INFO:Checking exceptions
2023-06-04 20:50:41,469:INFO:Importing libraries
2023-06-04 20:50:41,469:INFO:Copying training dataset
2023-06-04 20:50:41,493:INFO:Defining folds
2023-06-04 20:50:41,493:INFO:Declaring metric variables
2023-06-04 20:50:41,493:INFO:Importing untrained model
2023-06-04 20:50:41,493:INFO:Declaring custom model
2023-06-04 20:50:41,493:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 20:50:41,494:INFO:Starting cross validation
2023-06-04 20:50:41,495:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 20:50:43,532:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:50:44,197:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 20:50:46,417:INFO:Calculating mean and std
2023-06-04 20:50:46,417:INFO:Creating metrics dataframe
2023-06-04 20:50:46,418:INFO:Finalizing model
2023-06-04 20:50:46,877:INFO:Uploading results into container
2023-06-04 20:50:46,878:INFO:Uploading model into container now
2023-06-04 20:50:46,879:INFO:_master_model_container: 16
2023-06-04 20:50:46,879:INFO:_display_container: 4
2023-06-04 20:50:46,879:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:50:46,879:INFO:create_model() successfully completed......................................
2023-06-04 20:50:46,998:INFO:SubProcess create_model() end ==================================
2023-06-04 20:50:46,999:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-04 20:50:47,000:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-04 20:50:47,001:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-06-04 20:50:47,001:INFO:choose_better completed
2023-06-04 20:50:47,002:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-04 20:50:47,025:INFO:_master_model_container: 16
2023-06-04 20:50:47,026:INFO:_display_container: 3
2023-06-04 20:50:47,028:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 20:50:47,029:INFO:tune_model() successfully completed......................................
2023-06-04 21:03:46,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:03:46,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:03:46,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:03:46,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:03:47,278:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-04 21:05:17,831:INFO:PyCaret ClassificationExperiment
2023-06-04 21:05:17,832:INFO:Logging name: clf-default-name
2023-06-04 21:05:17,832:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-04 21:05:17,832:INFO:version 3.0.0
2023-06-04 21:05:17,833:INFO:Initializing setup()
2023-06-04 21:05:17,833:INFO:self.USI: 4d05
2023-06-04 21:05:17,833:INFO:self._variable_keys: {'exp_id', 'fold_generator', '_available_plots', 'fix_imbalance', 'html_param', 'idx', 'n_jobs_param', 'target_param', 'y_test', 'gpu_param', 'X_train', 'is_multiclass', 'memory', 'fold_groups_param', 'log_plots_param', 'data', 'X', 'fold_shuffle_param', 'logging_param', 'pipeline', 'seed', 'USI', 'X_test', 'gpu_n_jobs_param', 'y_train', 'exp_name_log', 'y', '_ml_usecase'}
2023-06-04 21:05:17,833:INFO:Checking environment
2023-06-04 21:05:17,834:INFO:python_version: 3.11.3
2023-06-04 21:05:17,834:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2023-06-04 21:05:17,834:INFO:machine: AMD64
2023-06-04 21:05:17,865:INFO:platform: Windows-10-10.0.19045-SP0
2023-06-04 21:05:17,869:INFO:Memory: svmem(total=8384401408, available=1702412288, percent=79.7, used=6681989120, free=1702412288)
2023-06-04 21:05:17,869:INFO:Physical Core: 4
2023-06-04 21:05:17,869:INFO:Logical Core: 8
2023-06-04 21:05:17,870:INFO:Checking libraries
2023-06-04 21:05:17,870:INFO:System:
2023-06-04 21:05:17,870:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2023-06-04 21:05:17,870:INFO:executable: C:\Program Files\Python311\python.exe
2023-06-04 21:05:17,870:INFO:   machine: Windows-10-10.0.19045-SP0
2023-06-04 21:05:17,870:INFO:PyCaret required dependencies:
2023-06-04 21:05:17,871:INFO:                 pip: 22.3.1
2023-06-04 21:05:17,871:INFO:          setuptools: 65.5.0
2023-06-04 21:05:17,871:INFO:             pycaret: 3.0.0
2023-06-04 21:05:17,871:INFO:             IPython: 8.12.0
2023-06-04 21:05:17,871:INFO:          ipywidgets: 8.0.6
2023-06-04 21:05:17,871:INFO:                tqdm: 4.65.0
2023-06-04 21:05:17,871:INFO:               numpy: 1.24.3
2023-06-04 21:05:17,872:INFO:              pandas: 1.5.3
2023-06-04 21:05:17,872:INFO:              jinja2: 3.1.2
2023-06-04 21:05:17,872:INFO:               scipy: 1.10.1
2023-06-04 21:05:17,872:INFO:              joblib: 1.2.0
2023-06-04 21:05:17,872:INFO:             sklearn: 1.2.2
2023-06-04 21:05:17,872:INFO:                pyod: 1.0.9
2023-06-04 21:05:17,872:INFO:            imblearn: 0.10.1
2023-06-04 21:05:17,873:INFO:   category_encoders: 2.6.0
2023-06-04 21:05:17,873:INFO:            lightgbm: 3.3.5
2023-06-04 21:05:17,873:INFO:               numba: 0.57.0
2023-06-04 21:05:17,873:INFO:            requests: 2.28.2
2023-06-04 21:05:17,873:INFO:          matplotlib: 3.7.1
2023-06-04 21:05:17,873:INFO:          scikitplot: 0.3.7
2023-06-04 21:05:17,874:INFO:         yellowbrick: 1.5
2023-06-04 21:05:17,874:INFO:              plotly: 5.14.1
2023-06-04 21:05:17,874:INFO:             kaleido: 0.2.1
2023-06-04 21:05:17,874:INFO:         statsmodels: 0.14.0
2023-06-04 21:05:17,874:INFO:              sktime: 0.18.0
2023-06-04 21:05:17,874:INFO:               tbats: 1.1.3
2023-06-04 21:05:17,874:INFO:            pmdarima: 2.0.3
2023-06-04 21:05:17,874:INFO:              psutil: 5.9.4
2023-06-04 21:05:17,874:INFO:PyCaret optional dependencies:
2023-06-04 21:05:17,894:INFO:                shap: Not installed
2023-06-04 21:05:17,894:INFO:           interpret: Not installed
2023-06-04 21:05:17,894:INFO:                umap: Not installed
2023-06-04 21:05:17,894:INFO:    pandas_profiling: Not installed
2023-06-04 21:05:17,894:INFO:  explainerdashboard: Not installed
2023-06-04 21:05:17,894:INFO:             autoviz: Not installed
2023-06-04 21:05:17,894:INFO:           fairlearn: Not installed
2023-06-04 21:05:17,894:INFO:             xgboost: Not installed
2023-06-04 21:05:17,894:INFO:            catboost: Not installed
2023-06-04 21:05:17,895:INFO:              kmodes: Not installed
2023-06-04 21:05:17,895:INFO:             mlxtend: Not installed
2023-06-04 21:05:17,895:INFO:       statsforecast: Not installed
2023-06-04 21:05:17,895:INFO:        tune_sklearn: Not installed
2023-06-04 21:05:17,895:INFO:                 ray: Not installed
2023-06-04 21:05:17,895:INFO:            hyperopt: Not installed
2023-06-04 21:05:17,895:INFO:              optuna: Not installed
2023-06-04 21:05:17,895:INFO:               skopt: Not installed
2023-06-04 21:05:17,895:INFO:              mlflow: Not installed
2023-06-04 21:05:17,895:INFO:              gradio: Not installed
2023-06-04 21:05:17,895:INFO:             fastapi: Not installed
2023-06-04 21:05:17,895:INFO:             uvicorn: Not installed
2023-06-04 21:05:17,895:INFO:              m2cgen: Not installed
2023-06-04 21:05:17,896:INFO:           evidently: Not installed
2023-06-04 21:05:17,896:INFO:               fugue: Not installed
2023-06-04 21:05:17,896:INFO:           streamlit: Not installed
2023-06-04 21:05:17,896:INFO:             prophet: 1.1.2
2023-06-04 21:05:17,896:INFO:None
2023-06-04 21:05:17,896:INFO:Set up data.
2023-06-04 21:05:17,927:INFO:Set up train/test split.
2023-06-04 21:05:17,973:INFO:Set up index.
2023-06-04 21:05:17,973:INFO:Set up folding strategy.
2023-06-04 21:05:17,973:INFO:Assigning column types.
2023-06-04 21:05:17,984:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-04 21:05:18,055:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 21:05:18,059:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:05:18,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,151:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 21:05:18,212:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:05:18,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,243:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,243:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-04 21:05:18,328:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:05:18,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,429:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:05:18,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,462:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-04 21:05:18,550:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,620:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,623:INFO:Preparing preprocessing pipeline...
2023-06-04 21:05:18,625:INFO:Set up simple imputation.
2023-06-04 21:05:18,634:INFO:Set up encoding of ordinal features.
2023-06-04 21:05:18,638:INFO:Set up encoding of categorical features.
2023-06-04 21:05:18,750:INFO:Finished creating preprocessing pipeline.
2023-06-04 21:05:18,769:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\shiva\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'hypertension',
                                             'heart_disease', 'smoking_history',
                                             'bmi', 'HbA1c_level',
                                             'blood_glucose_level'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['gender'],
                                    transformer=OrdinalEncoder(cols=['gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-06-04 21:05:18,770:INFO:Creating final display dataframe.
2023-06-04 21:05:18,875:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          diabetes
2                   Target type            Binary
3           Original data shape        (76885, 9)
4        Transformed data shape        (76885, 9)
5   Transformed train set shape        (57663, 9)
6    Transformed test set shape        (19222, 9)
7              Ordinal features                 1
8              Numeric features                 7
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              4d05
2023-06-04 21:05:18,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:18,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:19,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:19,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:05:19,036:INFO:setup() successfully completed in 1.54s...............
2023-06-04 21:05:19,036:INFO:Initializing compare_models()
2023-06-04 21:05:19,037:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-06-04 21:05:19,037:INFO:Checking exceptions
2023-06-04 21:05:19,045:INFO:Preparing display monitor
2023-06-04 21:05:19,049:INFO:Initializing Logistic Regression
2023-06-04 21:05:19,049:INFO:Total runtime is 0.0 minutes
2023-06-04 21:05:19,049:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:19,050:INFO:Initializing create_model()
2023-06-04 21:05:19,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:19,050:INFO:Checking exceptions
2023-06-04 21:05:19,050:INFO:Importing libraries
2023-06-04 21:05:19,050:INFO:Copying training dataset
2023-06-04 21:05:19,079:INFO:Defining folds
2023-06-04 21:05:19,079:INFO:Declaring metric variables
2023-06-04 21:05:19,079:INFO:Importing untrained model
2023-06-04 21:05:19,079:INFO:Logistic Regression Imported successfully
2023-06-04 21:05:19,080:INFO:Starting cross validation
2023-06-04 21:05:19,081:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:05:26,555:INFO:Calculating mean and std
2023-06-04 21:05:26,557:INFO:Creating metrics dataframe
2023-06-04 21:05:26,804:INFO:Uploading results into container
2023-06-04 21:05:26,806:INFO:Uploading model into container now
2023-06-04 21:05:26,807:INFO:_master_model_container: 1
2023-06-04 21:05:26,807:INFO:_display_container: 2
2023-06-04 21:05:26,808:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 21:05:26,808:INFO:create_model() successfully completed......................................
2023-06-04 21:05:26,954:INFO:SubProcess create_model() end ==================================
2023-06-04 21:05:26,955:INFO:Creating metrics dataframe
2023-06-04 21:05:26,963:INFO:Initializing K Neighbors Classifier
2023-06-04 21:05:26,963:INFO:Total runtime is 0.13189415136973062 minutes
2023-06-04 21:05:26,964:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:26,964:INFO:Initializing create_model()
2023-06-04 21:05:26,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:26,964:INFO:Checking exceptions
2023-06-04 21:05:26,964:INFO:Importing libraries
2023-06-04 21:05:26,965:INFO:Copying training dataset
2023-06-04 21:05:26,992:INFO:Defining folds
2023-06-04 21:05:26,992:INFO:Declaring metric variables
2023-06-04 21:05:26,992:INFO:Importing untrained model
2023-06-04 21:05:26,993:INFO:K Neighbors Classifier Imported successfully
2023-06-04 21:05:26,993:INFO:Starting cross validation
2023-06-04 21:05:26,994:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:05:33,453:INFO:Calculating mean and std
2023-06-04 21:05:33,455:INFO:Creating metrics dataframe
2023-06-04 21:05:33,858:INFO:Uploading results into container
2023-06-04 21:05:33,859:INFO:Uploading model into container now
2023-06-04 21:05:33,860:INFO:_master_model_container: 2
2023-06-04 21:05:33,860:INFO:_display_container: 2
2023-06-04 21:05:33,861:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-04 21:05:33,862:INFO:create_model() successfully completed......................................
2023-06-04 21:05:34,019:INFO:SubProcess create_model() end ==================================
2023-06-04 21:05:34,019:INFO:Creating metrics dataframe
2023-06-04 21:05:34,031:INFO:Initializing Naive Bayes
2023-06-04 21:05:34,031:INFO:Total runtime is 0.24970424572626748 minutes
2023-06-04 21:05:34,031:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:34,032:INFO:Initializing create_model()
2023-06-04 21:05:34,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:34,032:INFO:Checking exceptions
2023-06-04 21:05:34,033:INFO:Importing libraries
2023-06-04 21:05:34,033:INFO:Copying training dataset
2023-06-04 21:05:34,072:INFO:Defining folds
2023-06-04 21:05:34,072:INFO:Declaring metric variables
2023-06-04 21:05:34,073:INFO:Importing untrained model
2023-06-04 21:05:34,073:INFO:Naive Bayes Imported successfully
2023-06-04 21:05:34,074:INFO:Starting cross validation
2023-06-04 21:05:34,076:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:05:35,928:INFO:Calculating mean and std
2023-06-04 21:05:35,929:INFO:Creating metrics dataframe
2023-06-04 21:05:36,407:INFO:Uploading results into container
2023-06-04 21:05:36,408:INFO:Uploading model into container now
2023-06-04 21:05:36,409:INFO:_master_model_container: 3
2023-06-04 21:05:36,409:INFO:_display_container: 2
2023-06-04 21:05:36,410:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-04 21:05:36,410:INFO:create_model() successfully completed......................................
2023-06-04 21:05:36,568:INFO:SubProcess create_model() end ==================================
2023-06-04 21:05:36,568:INFO:Creating metrics dataframe
2023-06-04 21:05:36,578:INFO:Initializing Decision Tree Classifier
2023-06-04 21:05:36,579:INFO:Total runtime is 0.2921711802482605 minutes
2023-06-04 21:05:36,579:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:36,580:INFO:Initializing create_model()
2023-06-04 21:05:36,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:36,580:INFO:Checking exceptions
2023-06-04 21:05:36,580:INFO:Importing libraries
2023-06-04 21:05:36,580:INFO:Copying training dataset
2023-06-04 21:05:36,608:INFO:Defining folds
2023-06-04 21:05:36,608:INFO:Declaring metric variables
2023-06-04 21:05:36,608:INFO:Importing untrained model
2023-06-04 21:05:36,609:INFO:Decision Tree Classifier Imported successfully
2023-06-04 21:05:36,609:INFO:Starting cross validation
2023-06-04 21:05:36,611:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:05:38,320:INFO:Calculating mean and std
2023-06-04 21:05:38,322:INFO:Creating metrics dataframe
2023-06-04 21:05:38,866:INFO:Uploading results into container
2023-06-04 21:05:38,867:INFO:Uploading model into container now
2023-06-04 21:05:38,868:INFO:_master_model_container: 4
2023-06-04 21:05:38,868:INFO:_display_container: 2
2023-06-04 21:05:38,869:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-04 21:05:38,869:INFO:create_model() successfully completed......................................
2023-06-04 21:05:39,038:INFO:SubProcess create_model() end ==================================
2023-06-04 21:05:39,038:INFO:Creating metrics dataframe
2023-06-04 21:05:39,054:INFO:Initializing SVM - Linear Kernel
2023-06-04 21:05:39,054:INFO:Total runtime is 0.33341856400171915 minutes
2023-06-04 21:05:39,056:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:39,056:INFO:Initializing create_model()
2023-06-04 21:05:39,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:39,057:INFO:Checking exceptions
2023-06-04 21:05:39,057:INFO:Importing libraries
2023-06-04 21:05:39,057:INFO:Copying training dataset
2023-06-04 21:05:39,100:INFO:Defining folds
2023-06-04 21:05:39,100:INFO:Declaring metric variables
2023-06-04 21:05:39,100:INFO:Importing untrained model
2023-06-04 21:05:39,101:INFO:SVM - Linear Kernel Imported successfully
2023-06-04 21:05:39,102:INFO:Starting cross validation
2023-06-04 21:05:39,104:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:05:39,513:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:05:39,527:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:05:39,536:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:05:39,582:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:05:40,959:INFO:Calculating mean and std
2023-06-04 21:05:40,959:INFO:Creating metrics dataframe
2023-06-04 21:05:41,471:INFO:Uploading results into container
2023-06-04 21:05:41,472:INFO:Uploading model into container now
2023-06-04 21:05:41,473:INFO:_master_model_container: 5
2023-06-04 21:05:41,473:INFO:_display_container: 2
2023-06-04 21:05:41,473:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-04 21:05:41,473:INFO:create_model() successfully completed......................................
2023-06-04 21:05:41,597:INFO:SubProcess create_model() end ==================================
2023-06-04 21:05:41,598:INFO:Creating metrics dataframe
2023-06-04 21:05:41,607:INFO:Initializing Ridge Classifier
2023-06-04 21:05:41,607:INFO:Total runtime is 0.37596969604492186 minutes
2023-06-04 21:05:41,608:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:41,608:INFO:Initializing create_model()
2023-06-04 21:05:41,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:41,608:INFO:Checking exceptions
2023-06-04 21:05:41,609:INFO:Importing libraries
2023-06-04 21:05:41,609:INFO:Copying training dataset
2023-06-04 21:05:41,647:INFO:Defining folds
2023-06-04 21:05:41,647:INFO:Declaring metric variables
2023-06-04 21:05:41,647:INFO:Importing untrained model
2023-06-04 21:05:41,649:INFO:Ridge Classifier Imported successfully
2023-06-04 21:05:41,649:INFO:Starting cross validation
2023-06-04 21:05:41,651:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:05:42,090:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:05:42,103:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:05:42,208:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:05:42,344:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:05:43,224:INFO:Calculating mean and std
2023-06-04 21:05:43,225:INFO:Creating metrics dataframe
2023-06-04 21:05:43,710:INFO:Uploading results into container
2023-06-04 21:05:43,712:INFO:Uploading model into container now
2023-06-04 21:05:43,715:INFO:_master_model_container: 6
2023-06-04 21:05:43,715:INFO:_display_container: 2
2023-06-04 21:05:43,715:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-04 21:05:43,716:INFO:create_model() successfully completed......................................
2023-06-04 21:05:43,893:INFO:SubProcess create_model() end ==================================
2023-06-04 21:05:43,893:INFO:Creating metrics dataframe
2023-06-04 21:05:43,902:INFO:Initializing Random Forest Classifier
2023-06-04 21:05:43,902:INFO:Total runtime is 0.414217476050059 minutes
2023-06-04 21:05:43,902:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:43,902:INFO:Initializing create_model()
2023-06-04 21:05:43,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:43,903:INFO:Checking exceptions
2023-06-04 21:05:43,903:INFO:Importing libraries
2023-06-04 21:05:43,903:INFO:Copying training dataset
2023-06-04 21:05:43,939:INFO:Defining folds
2023-06-04 21:05:43,939:INFO:Declaring metric variables
2023-06-04 21:05:43,939:INFO:Importing untrained model
2023-06-04 21:05:43,940:INFO:Random Forest Classifier Imported successfully
2023-06-04 21:05:43,940:INFO:Starting cross validation
2023-06-04 21:05:43,942:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:05:46,301:INFO:Calculating mean and std
2023-06-04 21:05:46,302:INFO:Creating metrics dataframe
2023-06-04 21:05:46,702:INFO:Uploading results into container
2023-06-04 21:05:46,703:INFO:Uploading model into container now
2023-06-04 21:05:46,704:INFO:_master_model_container: 7
2023-06-04 21:05:46,704:INFO:_display_container: 2
2023-06-04 21:05:46,705:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-04 21:05:46,705:INFO:create_model() successfully completed......................................
2023-06-04 21:05:46,838:INFO:SubProcess create_model() end ==================================
2023-06-04 21:05:46,838:INFO:Creating metrics dataframe
2023-06-04 21:05:46,847:INFO:Initializing Quadratic Discriminant Analysis
2023-06-04 21:05:46,847:INFO:Total runtime is 0.4632931192715963 minutes
2023-06-04 21:05:46,848:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:46,848:INFO:Initializing create_model()
2023-06-04 21:05:46,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:46,848:INFO:Checking exceptions
2023-06-04 21:05:46,848:INFO:Importing libraries
2023-06-04 21:05:46,849:INFO:Copying training dataset
2023-06-04 21:05:46,875:INFO:Defining folds
2023-06-04 21:05:46,877:INFO:Declaring metric variables
2023-06-04 21:05:46,877:INFO:Importing untrained model
2023-06-04 21:05:46,877:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-04 21:05:46,879:INFO:Starting cross validation
2023-06-04 21:05:46,880:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:05:48,467:INFO:Calculating mean and std
2023-06-04 21:05:48,468:INFO:Creating metrics dataframe
2023-06-04 21:05:48,865:INFO:Uploading results into container
2023-06-04 21:05:48,866:INFO:Uploading model into container now
2023-06-04 21:05:48,866:INFO:_master_model_container: 8
2023-06-04 21:05:48,866:INFO:_display_container: 2
2023-06-04 21:05:48,867:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-04 21:05:48,867:INFO:create_model() successfully completed......................................
2023-06-04 21:05:49,045:INFO:SubProcess create_model() end ==================================
2023-06-04 21:05:49,045:INFO:Creating metrics dataframe
2023-06-04 21:05:49,052:INFO:Initializing Ada Boost Classifier
2023-06-04 21:05:49,052:INFO:Total runtime is 0.5000571171442668 minutes
2023-06-04 21:05:49,053:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:49,053:INFO:Initializing create_model()
2023-06-04 21:05:49,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:49,053:INFO:Checking exceptions
2023-06-04 21:05:49,053:INFO:Importing libraries
2023-06-04 21:05:49,054:INFO:Copying training dataset
2023-06-04 21:05:49,091:INFO:Defining folds
2023-06-04 21:05:49,091:INFO:Declaring metric variables
2023-06-04 21:05:49,092:INFO:Importing untrained model
2023-06-04 21:05:49,093:INFO:Ada Boost Classifier Imported successfully
2023-06-04 21:05:49,093:INFO:Starting cross validation
2023-06-04 21:05:49,094:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:05:51,446:INFO:Calculating mean and std
2023-06-04 21:05:51,447:INFO:Creating metrics dataframe
2023-06-04 21:05:51,943:INFO:Uploading results into container
2023-06-04 21:05:51,944:INFO:Uploading model into container now
2023-06-04 21:05:51,944:INFO:_master_model_container: 9
2023-06-04 21:05:51,944:INFO:_display_container: 2
2023-06-04 21:05:51,945:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-04 21:05:51,945:INFO:create_model() successfully completed......................................
2023-06-04 21:05:52,114:INFO:SubProcess create_model() end ==================================
2023-06-04 21:05:52,115:INFO:Creating metrics dataframe
2023-06-04 21:05:52,126:INFO:Initializing Gradient Boosting Classifier
2023-06-04 21:05:52,127:INFO:Total runtime is 0.5513054211934408 minutes
2023-06-04 21:05:52,127:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:52,128:INFO:Initializing create_model()
2023-06-04 21:05:52,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:52,128:INFO:Checking exceptions
2023-06-04 21:05:52,129:INFO:Importing libraries
2023-06-04 21:05:52,129:INFO:Copying training dataset
2023-06-04 21:05:52,181:INFO:Defining folds
2023-06-04 21:05:52,181:INFO:Declaring metric variables
2023-06-04 21:05:52,182:INFO:Importing untrained model
2023-06-04 21:05:52,182:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:05:52,183:INFO:Starting cross validation
2023-06-04 21:05:52,186:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:05:54,245:INFO:Calculating mean and std
2023-06-04 21:05:54,245:INFO:Creating metrics dataframe
2023-06-04 21:05:54,691:INFO:Uploading results into container
2023-06-04 21:05:54,693:INFO:Uploading model into container now
2023-06-04 21:05:54,694:INFO:_master_model_container: 10
2023-06-04 21:05:54,695:INFO:_display_container: 2
2023-06-04 21:05:54,696:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:05:54,696:INFO:create_model() successfully completed......................................
2023-06-04 21:05:54,893:INFO:SubProcess create_model() end ==================================
2023-06-04 21:05:54,893:INFO:Creating metrics dataframe
2023-06-04 21:05:54,903:INFO:Initializing Linear Discriminant Analysis
2023-06-04 21:05:54,905:INFO:Total runtime is 0.5975911021232606 minutes
2023-06-04 21:05:54,905:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:54,905:INFO:Initializing create_model()
2023-06-04 21:05:54,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:54,905:INFO:Checking exceptions
2023-06-04 21:05:54,907:INFO:Importing libraries
2023-06-04 21:05:54,907:INFO:Copying training dataset
2023-06-04 21:05:54,991:INFO:Defining folds
2023-06-04 21:05:54,991:INFO:Declaring metric variables
2023-06-04 21:05:54,992:INFO:Importing untrained model
2023-06-04 21:05:54,993:INFO:Linear Discriminant Analysis Imported successfully
2023-06-04 21:05:54,996:INFO:Starting cross validation
2023-06-04 21:05:55,001:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:05:56,660:INFO:Calculating mean and std
2023-06-04 21:05:56,662:INFO:Creating metrics dataframe
2023-06-04 21:05:57,162:INFO:Uploading results into container
2023-06-04 21:05:57,165:INFO:Uploading model into container now
2023-06-04 21:05:57,165:INFO:_master_model_container: 11
2023-06-04 21:05:57,165:INFO:_display_container: 2
2023-06-04 21:05:57,165:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-04 21:05:57,167:INFO:create_model() successfully completed......................................
2023-06-04 21:05:57,330:INFO:SubProcess create_model() end ==================================
2023-06-04 21:05:57,331:INFO:Creating metrics dataframe
2023-06-04 21:05:57,346:INFO:Initializing Extra Trees Classifier
2023-06-04 21:05:57,346:INFO:Total runtime is 0.6382828434308371 minutes
2023-06-04 21:05:57,347:INFO:SubProcess create_model() called ==================================
2023-06-04 21:05:57,348:INFO:Initializing create_model()
2023-06-04 21:05:57,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:05:57,348:INFO:Checking exceptions
2023-06-04 21:05:57,348:INFO:Importing libraries
2023-06-04 21:05:57,349:INFO:Copying training dataset
2023-06-04 21:05:57,386:INFO:Defining folds
2023-06-04 21:05:57,386:INFO:Declaring metric variables
2023-06-04 21:05:57,386:INFO:Importing untrained model
2023-06-04 21:05:57,387:INFO:Extra Trees Classifier Imported successfully
2023-06-04 21:05:57,387:INFO:Starting cross validation
2023-06-04 21:05:57,390:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:06:00,397:INFO:Calculating mean and std
2023-06-04 21:06:00,398:INFO:Creating metrics dataframe
2023-06-04 21:06:00,843:INFO:Uploading results into container
2023-06-04 21:06:00,845:INFO:Uploading model into container now
2023-06-04 21:06:00,846:INFO:_master_model_container: 12
2023-06-04 21:06:00,847:INFO:_display_container: 2
2023-06-04 21:06:00,849:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-04 21:06:00,849:INFO:create_model() successfully completed......................................
2023-06-04 21:06:01,015:INFO:SubProcess create_model() end ==================================
2023-06-04 21:06:01,015:INFO:Creating metrics dataframe
2023-06-04 21:06:01,025:INFO:Initializing Light Gradient Boosting Machine
2023-06-04 21:06:01,025:INFO:Total runtime is 0.6996018052101136 minutes
2023-06-04 21:06:01,026:INFO:SubProcess create_model() called ==================================
2023-06-04 21:06:01,026:INFO:Initializing create_model()
2023-06-04 21:06:01,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:06:01,026:INFO:Checking exceptions
2023-06-04 21:06:01,027:INFO:Importing libraries
2023-06-04 21:06:01,027:INFO:Copying training dataset
2023-06-04 21:06:01,063:INFO:Defining folds
2023-06-04 21:06:01,064:INFO:Declaring metric variables
2023-06-04 21:06:01,064:INFO:Importing untrained model
2023-06-04 21:06:01,065:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-04 21:06:01,066:INFO:Starting cross validation
2023-06-04 21:06:01,067:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:06:03,195:INFO:Calculating mean and std
2023-06-04 21:06:03,196:INFO:Creating metrics dataframe
2023-06-04 21:06:03,679:INFO:Uploading results into container
2023-06-04 21:06:03,679:INFO:Uploading model into container now
2023-06-04 21:06:03,680:INFO:_master_model_container: 13
2023-06-04 21:06:03,680:INFO:_display_container: 2
2023-06-04 21:06:03,681:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-04 21:06:03,681:INFO:create_model() successfully completed......................................
2023-06-04 21:06:03,844:INFO:SubProcess create_model() end ==================================
2023-06-04 21:06:03,844:INFO:Creating metrics dataframe
2023-06-04 21:06:03,854:INFO:Initializing Dummy Classifier
2023-06-04 21:06:03,854:INFO:Total runtime is 0.7467430988947551 minutes
2023-06-04 21:06:03,855:INFO:SubProcess create_model() called ==================================
2023-06-04 21:06:03,855:INFO:Initializing create_model()
2023-06-04 21:06:03,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD745CC50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:06:03,855:INFO:Checking exceptions
2023-06-04 21:06:03,855:INFO:Importing libraries
2023-06-04 21:06:03,855:INFO:Copying training dataset
2023-06-04 21:06:03,887:INFO:Defining folds
2023-06-04 21:06:03,887:INFO:Declaring metric variables
2023-06-04 21:06:03,888:INFO:Importing untrained model
2023-06-04 21:06:03,888:INFO:Dummy Classifier Imported successfully
2023-06-04 21:06:03,889:INFO:Starting cross validation
2023-06-04 21:06:03,891:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:06:04,388:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:06:04,543:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:06:04,553:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:06:04,590:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:06:05,497:INFO:Calculating mean and std
2023-06-04 21:06:05,498:INFO:Creating metrics dataframe
2023-06-04 21:06:05,952:INFO:Uploading results into container
2023-06-04 21:06:05,953:INFO:Uploading model into container now
2023-06-04 21:06:05,953:INFO:_master_model_container: 14
2023-06-04 21:06:05,954:INFO:_display_container: 2
2023-06-04 21:06:05,954:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-04 21:06:05,954:INFO:create_model() successfully completed......................................
2023-06-04 21:06:06,145:INFO:SubProcess create_model() end ==================================
2023-06-04 21:06:06,145:INFO:Creating metrics dataframe
2023-06-04 21:06:06,160:INFO:Initializing create_model()
2023-06-04 21:06:06,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:06:06,160:INFO:Checking exceptions
2023-06-04 21:06:06,163:INFO:Importing libraries
2023-06-04 21:06:06,163:INFO:Copying training dataset
2023-06-04 21:06:06,243:INFO:Defining folds
2023-06-04 21:06:06,243:INFO:Declaring metric variables
2023-06-04 21:06:06,243:INFO:Importing untrained model
2023-06-04 21:06:06,243:INFO:Declaring custom model
2023-06-04 21:06:06,246:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:06:06,254:INFO:Cross validation set to False
2023-06-04 21:06:06,255:INFO:Fitting Model
2023-06-04 21:06:07,039:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:06:07,040:INFO:create_model() successfully completed......................................
2023-06-04 21:06:07,242:INFO:_master_model_container: 14
2023-06-04 21:06:07,242:INFO:_display_container: 2
2023-06-04 21:06:07,245:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:06:07,245:INFO:compare_models() successfully completed......................................
2023-06-04 21:06:07,246:INFO:Initializing evaluate_model()
2023-06-04 21:06:07,246:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-04 21:06:07,473:INFO:Initializing plot_model()
2023-06-04 21:06:07,473:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, use_train_data=False, verbose=False, system=True, display=None, display_format=None)
2023-06-04 21:06:07,473:INFO:Checking exceptions
2023-06-04 21:06:07,502:INFO:Preloading libraries
2023-06-04 21:06:07,523:INFO:Copying training dataset
2023-06-04 21:06:07,523:INFO:Plot type: pipeline
2023-06-04 21:06:07,593:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:572: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  fig, ax = plt.subplots(

2023-06-04 21:06:07,863:INFO:Initializing tune_model()
2023-06-04 21:06:07,863:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2023-06-04 21:06:07,863:INFO:Checking exceptions
2023-06-04 21:06:07,887:INFO:Copying training dataset
2023-06-04 21:06:07,924:INFO:Checking base model
2023-06-04 21:06:07,924:INFO:Base model : Gradient Boosting Classifier
2023-06-04 21:06:07,925:INFO:Declaring metric variables
2023-06-04 21:06:07,926:INFO:Defining Hyperparameters
2023-06-04 21:06:08,087:INFO:Tuning with n_jobs=-1
2023-06-04 21:06:08,088:INFO:Initializing RandomizedSearchCV
2023-06-04 21:06:54,350:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-06-04 21:06:54,350:INFO:Hyperparameter search completed
2023-06-04 21:06:54,351:INFO:SubProcess create_model() called ==================================
2023-06-04 21:06:54,351:INFO:Initializing create_model()
2023-06-04 21:06:54,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94F7B10>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-06-04 21:06:54,351:INFO:Checking exceptions
2023-06-04 21:06:54,351:INFO:Importing libraries
2023-06-04 21:06:54,351:INFO:Copying training dataset
2023-06-04 21:06:54,377:INFO:Defining folds
2023-06-04 21:06:54,377:INFO:Declaring metric variables
2023-06-04 21:06:54,377:INFO:Importing untrained model
2023-06-04 21:06:54,377:INFO:Declaring custom model
2023-06-04 21:06:54,378:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:06:54,378:INFO:Starting cross validation
2023-06-04 21:06:54,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:06:55,828:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 21:06:58,211:INFO:Calculating mean and std
2023-06-04 21:06:58,212:INFO:Creating metrics dataframe
2023-06-04 21:06:58,214:INFO:Finalizing model
2023-06-04 21:06:58,669:INFO:Uploading results into container
2023-06-04 21:06:58,669:INFO:Uploading model into container now
2023-06-04 21:06:58,670:INFO:_master_model_container: 15
2023-06-04 21:06:58,670:INFO:_display_container: 3
2023-06-04 21:06:58,672:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:06:58,672:INFO:create_model() successfully completed......................................
2023-06-04 21:06:58,812:INFO:SubProcess create_model() end ==================================
2023-06-04 21:06:58,813:INFO:choose_better activated
2023-06-04 21:06:58,813:INFO:SubProcess create_model() called ==================================
2023-06-04 21:06:58,814:INFO:Initializing create_model()
2023-06-04 21:06:58,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD5683E10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:06:58,815:INFO:Checking exceptions
2023-06-04 21:06:58,816:INFO:Importing libraries
2023-06-04 21:06:58,817:INFO:Copying training dataset
2023-06-04 21:06:58,843:INFO:Defining folds
2023-06-04 21:06:58,844:INFO:Declaring metric variables
2023-06-04 21:06:58,844:INFO:Importing untrained model
2023-06-04 21:06:58,844:INFO:Declaring custom model
2023-06-04 21:06:58,845:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:06:58,845:INFO:Starting cross validation
2023-06-04 21:06:58,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:07:02,462:INFO:Calculating mean and std
2023-06-04 21:07:02,463:INFO:Creating metrics dataframe
2023-06-04 21:07:02,465:INFO:Finalizing model
2023-06-04 21:07:02,991:INFO:Uploading results into container
2023-06-04 21:07:02,992:INFO:Uploading model into container now
2023-06-04 21:07:02,993:INFO:_master_model_container: 16
2023-06-04 21:07:02,993:INFO:_display_container: 4
2023-06-04 21:07:02,993:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:07:02,993:INFO:create_model() successfully completed......................................
2023-06-04 21:07:03,107:INFO:SubProcess create_model() end ==================================
2023-06-04 21:07:03,108:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-04 21:07:03,108:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-04 21:07:03,109:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-06-04 21:07:03,109:INFO:choose_better completed
2023-06-04 21:07:03,110:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-04 21:07:03,133:INFO:_master_model_container: 16
2023-06-04 21:07:03,135:INFO:_display_container: 3
2023-06-04 21:07:03,138:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:07:03,138:INFO:tune_model() successfully completed......................................
2023-06-04 21:14:00,086:INFO:PyCaret ClassificationExperiment
2023-06-04 21:14:00,087:INFO:Logging name: clf-default-name
2023-06-04 21:14:00,087:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-04 21:14:00,087:INFO:version 3.0.0
2023-06-04 21:14:00,087:INFO:Initializing setup()
2023-06-04 21:14:00,087:INFO:self.USI: c449
2023-06-04 21:14:00,088:INFO:self._variable_keys: {'exp_id', 'fold_generator', '_available_plots', 'fix_imbalance', 'html_param', 'idx', 'n_jobs_param', 'target_param', 'y_test', 'gpu_param', 'X_train', 'is_multiclass', 'memory', 'fold_groups_param', 'log_plots_param', 'data', 'X', 'fold_shuffle_param', 'logging_param', 'pipeline', 'seed', 'USI', 'X_test', 'gpu_n_jobs_param', 'y_train', 'exp_name_log', 'y', '_ml_usecase'}
2023-06-04 21:14:00,088:INFO:Checking environment
2023-06-04 21:14:00,088:INFO:python_version: 3.11.3
2023-06-04 21:14:00,088:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2023-06-04 21:14:00,089:INFO:machine: AMD64
2023-06-04 21:14:00,089:INFO:platform: Windows-10-10.0.19045-SP0
2023-06-04 21:14:00,096:INFO:Memory: svmem(total=8384401408, available=1758285824, percent=79.0, used=6626115584, free=1758285824)
2023-06-04 21:14:00,096:INFO:Physical Core: 4
2023-06-04 21:14:00,096:INFO:Logical Core: 8
2023-06-04 21:14:00,097:INFO:Checking libraries
2023-06-04 21:14:00,097:INFO:System:
2023-06-04 21:14:00,097:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2023-06-04 21:14:00,097:INFO:executable: C:\Program Files\Python311\python.exe
2023-06-04 21:14:00,097:INFO:   machine: Windows-10-10.0.19045-SP0
2023-06-04 21:14:00,097:INFO:PyCaret required dependencies:
2023-06-04 21:14:00,098:INFO:                 pip: 22.3.1
2023-06-04 21:14:00,098:INFO:          setuptools: 65.5.0
2023-06-04 21:14:00,098:INFO:             pycaret: 3.0.0
2023-06-04 21:14:00,099:INFO:             IPython: 8.12.0
2023-06-04 21:14:00,099:INFO:          ipywidgets: 8.0.6
2023-06-04 21:14:00,099:INFO:                tqdm: 4.65.0
2023-06-04 21:14:00,099:INFO:               numpy: 1.24.3
2023-06-04 21:14:00,099:INFO:              pandas: 1.5.3
2023-06-04 21:14:00,099:INFO:              jinja2: 3.1.2
2023-06-04 21:14:00,099:INFO:               scipy: 1.10.1
2023-06-04 21:14:00,099:INFO:              joblib: 1.2.0
2023-06-04 21:14:00,099:INFO:             sklearn: 1.2.2
2023-06-04 21:14:00,099:INFO:                pyod: 1.0.9
2023-06-04 21:14:00,099:INFO:            imblearn: 0.10.1
2023-06-04 21:14:00,099:INFO:   category_encoders: 2.6.0
2023-06-04 21:14:00,099:INFO:            lightgbm: 3.3.5
2023-06-04 21:14:00,099:INFO:               numba: 0.57.0
2023-06-04 21:14:00,100:INFO:            requests: 2.28.2
2023-06-04 21:14:00,100:INFO:          matplotlib: 3.7.1
2023-06-04 21:14:00,100:INFO:          scikitplot: 0.3.7
2023-06-04 21:14:00,100:INFO:         yellowbrick: 1.5
2023-06-04 21:14:00,100:INFO:              plotly: 5.14.1
2023-06-04 21:14:00,100:INFO:             kaleido: 0.2.1
2023-06-04 21:14:00,100:INFO:         statsmodels: 0.14.0
2023-06-04 21:14:00,100:INFO:              sktime: 0.18.0
2023-06-04 21:14:00,100:INFO:               tbats: 1.1.3
2023-06-04 21:14:00,100:INFO:            pmdarima: 2.0.3
2023-06-04 21:14:00,100:INFO:              psutil: 5.9.4
2023-06-04 21:14:00,100:INFO:PyCaret optional dependencies:
2023-06-04 21:14:00,100:INFO:                shap: Not installed
2023-06-04 21:14:00,100:INFO:           interpret: Not installed
2023-06-04 21:14:00,100:INFO:                umap: Not installed
2023-06-04 21:14:00,100:INFO:    pandas_profiling: Not installed
2023-06-04 21:14:00,100:INFO:  explainerdashboard: Not installed
2023-06-04 21:14:00,100:INFO:             autoviz: Not installed
2023-06-04 21:14:00,100:INFO:           fairlearn: Not installed
2023-06-04 21:14:00,100:INFO:             xgboost: Not installed
2023-06-04 21:14:00,100:INFO:            catboost: Not installed
2023-06-04 21:14:00,101:INFO:              kmodes: Not installed
2023-06-04 21:14:00,101:INFO:             mlxtend: Not installed
2023-06-04 21:14:00,101:INFO:       statsforecast: Not installed
2023-06-04 21:14:00,101:INFO:        tune_sklearn: Not installed
2023-06-04 21:14:00,101:INFO:                 ray: Not installed
2023-06-04 21:14:00,101:INFO:            hyperopt: Not installed
2023-06-04 21:14:00,101:INFO:              optuna: Not installed
2023-06-04 21:14:00,101:INFO:               skopt: Not installed
2023-06-04 21:14:00,101:INFO:              mlflow: Not installed
2023-06-04 21:14:00,101:INFO:              gradio: Not installed
2023-06-04 21:14:00,101:INFO:             fastapi: Not installed
2023-06-04 21:14:00,101:INFO:             uvicorn: Not installed
2023-06-04 21:14:00,101:INFO:              m2cgen: Not installed
2023-06-04 21:14:00,101:INFO:           evidently: Not installed
2023-06-04 21:14:00,101:INFO:               fugue: Not installed
2023-06-04 21:14:00,101:INFO:           streamlit: Not installed
2023-06-04 21:14:00,101:INFO:             prophet: 1.1.2
2023-06-04 21:14:00,101:INFO:None
2023-06-04 21:14:00,101:INFO:Set up data.
2023-06-04 21:14:00,129:INFO:Set up train/test split.
2023-06-04 21:14:00,159:INFO:Set up index.
2023-06-04 21:14:00,160:INFO:Set up folding strategy.
2023-06-04 21:14:00,160:INFO:Assigning column types.
2023-06-04 21:14:00,168:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-04 21:14:00,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 21:14:00,212:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:14:00,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,295:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 21:14:00,295:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:14:00,320:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,321:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-04 21:14:00,365:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:14:00,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,435:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:14:00,463:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,464:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-04 21:14:00,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:00,614:INFO:Preparing preprocessing pipeline...
2023-06-04 21:14:00,618:INFO:Set up simple imputation.
2023-06-04 21:14:00,640:INFO:Set up encoding of ordinal features.
2023-06-04 21:14:00,648:INFO:Set up encoding of categorical features.
2023-06-04 21:14:00,868:INFO:Finished creating preprocessing pipeline.
2023-06-04 21:14:00,910:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\shiva\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'hypertension',
                                             'heart_disease', 'smoking_history',
                                             'bmi', 'HbA1c_level',
                                             'blood_glucose_level'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['gender'],
                                    transformer=OrdinalEncoder(cols=['gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-06-04 21:14:00,911:INFO:Creating final display dataframe.
2023-06-04 21:14:01,097:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          diabetes
2                   Target type            Binary
3           Original data shape        (76885, 9)
4        Transformed data shape        (76885, 9)
5   Transformed train set shape        (57663, 9)
6    Transformed test set shape        (19222, 9)
7              Ordinal features                 1
8              Numeric features                 7
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              c449
2023-06-04 21:14:01,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:01,281:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:01,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:01,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:14:01,453:INFO:setup() successfully completed in 1.59s...............
2023-06-04 21:14:01,454:INFO:Initializing compare_models()
2023-06-04 21:14:01,454:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-06-04 21:14:01,454:INFO:Checking exceptions
2023-06-04 21:14:01,474:INFO:Preparing display monitor
2023-06-04 21:14:01,480:INFO:Initializing Logistic Regression
2023-06-04 21:14:01,480:INFO:Total runtime is 0.0 minutes
2023-06-04 21:14:01,481:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:01,481:INFO:Initializing create_model()
2023-06-04 21:14:01,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:01,482:INFO:Checking exceptions
2023-06-04 21:14:01,483:INFO:Importing libraries
2023-06-04 21:14:01,483:INFO:Copying training dataset
2023-06-04 21:14:01,519:INFO:Defining folds
2023-06-04 21:14:01,519:INFO:Declaring metric variables
2023-06-04 21:14:01,521:INFO:Importing untrained model
2023-06-04 21:14:01,521:INFO:Logistic Regression Imported successfully
2023-06-04 21:14:01,522:INFO:Starting cross validation
2023-06-04 21:14:01,524:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:10,465:INFO:Calculating mean and std
2023-06-04 21:14:10,467:INFO:Creating metrics dataframe
2023-06-04 21:14:11,104:INFO:Uploading results into container
2023-06-04 21:14:11,105:INFO:Uploading model into container now
2023-06-04 21:14:11,105:INFO:_master_model_container: 1
2023-06-04 21:14:11,106:INFO:_display_container: 2
2023-06-04 21:14:11,107:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 21:14:11,107:INFO:create_model() successfully completed......................................
2023-06-04 21:14:11,278:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:11,278:INFO:Creating metrics dataframe
2023-06-04 21:14:11,283:INFO:Initializing K Neighbors Classifier
2023-06-04 21:14:11,283:INFO:Total runtime is 0.16337576707204182 minutes
2023-06-04 21:14:11,283:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:11,283:INFO:Initializing create_model()
2023-06-04 21:14:11,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:11,283:INFO:Checking exceptions
2023-06-04 21:14:11,283:INFO:Importing libraries
2023-06-04 21:14:11,283:INFO:Copying training dataset
2023-06-04 21:14:11,314:INFO:Defining folds
2023-06-04 21:14:11,314:INFO:Declaring metric variables
2023-06-04 21:14:11,315:INFO:Importing untrained model
2023-06-04 21:14:11,315:INFO:K Neighbors Classifier Imported successfully
2023-06-04 21:14:11,315:INFO:Starting cross validation
2023-06-04 21:14:11,316:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:19,501:INFO:Calculating mean and std
2023-06-04 21:14:19,502:INFO:Creating metrics dataframe
2023-06-04 21:14:20,207:INFO:Uploading results into container
2023-06-04 21:14:20,209:INFO:Uploading model into container now
2023-06-04 21:14:20,211:INFO:_master_model_container: 2
2023-06-04 21:14:20,211:INFO:_display_container: 2
2023-06-04 21:14:20,212:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-04 21:14:20,214:INFO:create_model() successfully completed......................................
2023-06-04 21:14:20,549:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:20,550:INFO:Creating metrics dataframe
2023-06-04 21:14:20,557:INFO:Initializing Naive Bayes
2023-06-04 21:14:20,557:INFO:Total runtime is 0.31793886025746665 minutes
2023-06-04 21:14:20,557:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:20,558:INFO:Initializing create_model()
2023-06-04 21:14:20,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:20,558:INFO:Checking exceptions
2023-06-04 21:14:20,559:INFO:Importing libraries
2023-06-04 21:14:20,559:INFO:Copying training dataset
2023-06-04 21:14:20,656:INFO:Defining folds
2023-06-04 21:14:20,656:INFO:Declaring metric variables
2023-06-04 21:14:20,656:INFO:Importing untrained model
2023-06-04 21:14:20,656:INFO:Naive Bayes Imported successfully
2023-06-04 21:14:20,657:INFO:Starting cross validation
2023-06-04 21:14:20,658:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:22,842:INFO:Calculating mean and std
2023-06-04 21:14:22,844:INFO:Creating metrics dataframe
2023-06-04 21:14:23,454:INFO:Uploading results into container
2023-06-04 21:14:23,458:INFO:Uploading model into container now
2023-06-04 21:14:23,459:INFO:_master_model_container: 3
2023-06-04 21:14:23,460:INFO:_display_container: 2
2023-06-04 21:14:23,460:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-04 21:14:23,461:INFO:create_model() successfully completed......................................
2023-06-04 21:14:23,689:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:23,689:INFO:Creating metrics dataframe
2023-06-04 21:14:23,696:INFO:Initializing Decision Tree Classifier
2023-06-04 21:14:23,696:INFO:Total runtime is 0.37026666402816777 minutes
2023-06-04 21:14:23,697:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:23,697:INFO:Initializing create_model()
2023-06-04 21:14:23,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:23,697:INFO:Checking exceptions
2023-06-04 21:14:23,697:INFO:Importing libraries
2023-06-04 21:14:23,697:INFO:Copying training dataset
2023-06-04 21:14:23,719:INFO:Defining folds
2023-06-04 21:14:23,720:INFO:Declaring metric variables
2023-06-04 21:14:23,720:INFO:Importing untrained model
2023-06-04 21:14:23,720:INFO:Decision Tree Classifier Imported successfully
2023-06-04 21:14:23,721:INFO:Starting cross validation
2023-06-04 21:14:23,722:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:25,012:INFO:Calculating mean and std
2023-06-04 21:14:25,014:INFO:Creating metrics dataframe
2023-06-04 21:14:25,912:INFO:Uploading results into container
2023-06-04 21:14:25,913:INFO:Uploading model into container now
2023-06-04 21:14:25,914:INFO:_master_model_container: 4
2023-06-04 21:14:25,914:INFO:_display_container: 2
2023-06-04 21:14:25,914:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-04 21:14:25,914:INFO:create_model() successfully completed......................................
2023-06-04 21:14:26,080:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:26,081:INFO:Creating metrics dataframe
2023-06-04 21:14:26,095:INFO:Initializing SVM - Linear Kernel
2023-06-04 21:14:26,095:INFO:Total runtime is 0.410246233145396 minutes
2023-06-04 21:14:26,096:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:26,096:INFO:Initializing create_model()
2023-06-04 21:14:26,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:26,096:INFO:Checking exceptions
2023-06-04 21:14:26,096:INFO:Importing libraries
2023-06-04 21:14:26,097:INFO:Copying training dataset
2023-06-04 21:14:26,136:INFO:Defining folds
2023-06-04 21:14:26,137:INFO:Declaring metric variables
2023-06-04 21:14:26,137:INFO:Importing untrained model
2023-06-04 21:14:26,138:INFO:SVM - Linear Kernel Imported successfully
2023-06-04 21:14:26,140:INFO:Starting cross validation
2023-06-04 21:14:26,142:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:26,528:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:14:26,539:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:14:26,541:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:14:26,598:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:14:27,411:INFO:Calculating mean and std
2023-06-04 21:14:27,412:INFO:Creating metrics dataframe
2023-06-04 21:14:27,759:INFO:Uploading results into container
2023-06-04 21:14:27,760:INFO:Uploading model into container now
2023-06-04 21:14:27,761:INFO:_master_model_container: 5
2023-06-04 21:14:27,761:INFO:_display_container: 2
2023-06-04 21:14:27,761:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-04 21:14:27,761:INFO:create_model() successfully completed......................................
2023-06-04 21:14:27,928:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:27,928:INFO:Creating metrics dataframe
2023-06-04 21:14:27,937:INFO:Initializing Ridge Classifier
2023-06-04 21:14:27,937:INFO:Total runtime is 0.4409468770027161 minutes
2023-06-04 21:14:27,938:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:27,938:INFO:Initializing create_model()
2023-06-04 21:14:27,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:27,938:INFO:Checking exceptions
2023-06-04 21:14:27,938:INFO:Importing libraries
2023-06-04 21:14:27,938:INFO:Copying training dataset
2023-06-04 21:14:27,963:INFO:Defining folds
2023-06-04 21:14:27,963:INFO:Declaring metric variables
2023-06-04 21:14:27,964:INFO:Importing untrained model
2023-06-04 21:14:27,964:INFO:Ridge Classifier Imported successfully
2023-06-04 21:14:27,964:INFO:Starting cross validation
2023-06-04 21:14:27,965:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:28,355:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:14:28,358:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:14:28,444:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:14:28,446:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:14:30,143:INFO:Calculating mean and std
2023-06-04 21:14:30,144:INFO:Creating metrics dataframe
2023-06-04 21:14:30,638:INFO:Uploading results into container
2023-06-04 21:14:30,639:INFO:Uploading model into container now
2023-06-04 21:14:30,640:INFO:_master_model_container: 6
2023-06-04 21:14:30,641:INFO:_display_container: 2
2023-06-04 21:14:30,641:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-04 21:14:30,642:INFO:create_model() successfully completed......................................
2023-06-04 21:14:30,879:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:30,880:INFO:Creating metrics dataframe
2023-06-04 21:14:30,905:INFO:Initializing Random Forest Classifier
2023-06-04 21:14:30,905:INFO:Total runtime is 0.4904177904129029 minutes
2023-06-04 21:14:30,905:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:30,906:INFO:Initializing create_model()
2023-06-04 21:14:30,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:30,907:INFO:Checking exceptions
2023-06-04 21:14:30,907:INFO:Importing libraries
2023-06-04 21:14:30,907:INFO:Copying training dataset
2023-06-04 21:14:30,963:INFO:Defining folds
2023-06-04 21:14:30,964:INFO:Declaring metric variables
2023-06-04 21:14:30,965:INFO:Importing untrained model
2023-06-04 21:14:30,967:INFO:Random Forest Classifier Imported successfully
2023-06-04 21:14:30,968:INFO:Starting cross validation
2023-06-04 21:14:30,973:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:33,712:INFO:Calculating mean and std
2023-06-04 21:14:33,713:INFO:Creating metrics dataframe
2023-06-04 21:14:34,148:INFO:Uploading results into container
2023-06-04 21:14:34,149:INFO:Uploading model into container now
2023-06-04 21:14:34,150:INFO:_master_model_container: 7
2023-06-04 21:14:34,150:INFO:_display_container: 2
2023-06-04 21:14:34,151:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-04 21:14:34,151:INFO:create_model() successfully completed......................................
2023-06-04 21:14:34,310:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:34,311:INFO:Creating metrics dataframe
2023-06-04 21:14:34,320:INFO:Initializing Quadratic Discriminant Analysis
2023-06-04 21:14:34,320:INFO:Total runtime is 0.5473346034685771 minutes
2023-06-04 21:14:34,321:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:34,321:INFO:Initializing create_model()
2023-06-04 21:14:34,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:34,321:INFO:Checking exceptions
2023-06-04 21:14:34,321:INFO:Importing libraries
2023-06-04 21:14:34,322:INFO:Copying training dataset
2023-06-04 21:14:34,351:INFO:Defining folds
2023-06-04 21:14:34,351:INFO:Declaring metric variables
2023-06-04 21:14:34,351:INFO:Importing untrained model
2023-06-04 21:14:34,352:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-04 21:14:34,352:INFO:Starting cross validation
2023-06-04 21:14:34,354:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:36,632:INFO:Calculating mean and std
2023-06-04 21:14:36,634:INFO:Creating metrics dataframe
2023-06-04 21:14:37,235:INFO:Uploading results into container
2023-06-04 21:14:37,240:INFO:Uploading model into container now
2023-06-04 21:14:37,242:INFO:_master_model_container: 8
2023-06-04 21:14:37,242:INFO:_display_container: 2
2023-06-04 21:14:37,244:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-04 21:14:37,245:INFO:create_model() successfully completed......................................
2023-06-04 21:14:37,528:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:37,529:INFO:Creating metrics dataframe
2023-06-04 21:14:37,548:INFO:Initializing Ada Boost Classifier
2023-06-04 21:14:37,548:INFO:Total runtime is 0.6011362791061402 minutes
2023-06-04 21:14:37,549:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:37,549:INFO:Initializing create_model()
2023-06-04 21:14:37,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:37,550:INFO:Checking exceptions
2023-06-04 21:14:37,550:INFO:Importing libraries
2023-06-04 21:14:37,550:INFO:Copying training dataset
2023-06-04 21:14:37,636:INFO:Defining folds
2023-06-04 21:14:37,637:INFO:Declaring metric variables
2023-06-04 21:14:37,638:INFO:Importing untrained model
2023-06-04 21:14:37,639:INFO:Ada Boost Classifier Imported successfully
2023-06-04 21:14:37,640:INFO:Starting cross validation
2023-06-04 21:14:37,643:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:41,025:INFO:Calculating mean and std
2023-06-04 21:14:41,026:INFO:Creating metrics dataframe
2023-06-04 21:14:41,469:INFO:Uploading results into container
2023-06-04 21:14:41,470:INFO:Uploading model into container now
2023-06-04 21:14:41,470:INFO:_master_model_container: 9
2023-06-04 21:14:41,471:INFO:_display_container: 2
2023-06-04 21:14:41,471:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-04 21:14:41,471:INFO:create_model() successfully completed......................................
2023-06-04 21:14:41,728:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:41,728:INFO:Creating metrics dataframe
2023-06-04 21:14:41,752:INFO:Initializing Gradient Boosting Classifier
2023-06-04 21:14:41,752:INFO:Total runtime is 0.671203633149465 minutes
2023-06-04 21:14:41,753:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:41,754:INFO:Initializing create_model()
2023-06-04 21:14:41,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:41,754:INFO:Checking exceptions
2023-06-04 21:14:41,754:INFO:Importing libraries
2023-06-04 21:14:41,754:INFO:Copying training dataset
2023-06-04 21:14:41,817:INFO:Defining folds
2023-06-04 21:14:41,817:INFO:Declaring metric variables
2023-06-04 21:14:41,819:INFO:Importing untrained model
2023-06-04 21:14:41,820:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:14:41,821:INFO:Starting cross validation
2023-06-04 21:14:41,824:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:44,264:INFO:Calculating mean and std
2023-06-04 21:14:44,266:INFO:Creating metrics dataframe
2023-06-04 21:14:44,719:INFO:Uploading results into container
2023-06-04 21:14:44,721:INFO:Uploading model into container now
2023-06-04 21:14:44,721:INFO:_master_model_container: 10
2023-06-04 21:14:44,722:INFO:_display_container: 2
2023-06-04 21:14:44,722:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:14:44,723:INFO:create_model() successfully completed......................................
2023-06-04 21:14:44,917:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:44,917:INFO:Creating metrics dataframe
2023-06-04 21:14:44,926:INFO:Initializing Linear Discriminant Analysis
2023-06-04 21:14:44,926:INFO:Total runtime is 0.7240971883138021 minutes
2023-06-04 21:14:44,927:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:44,927:INFO:Initializing create_model()
2023-06-04 21:14:44,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:44,928:INFO:Checking exceptions
2023-06-04 21:14:44,928:INFO:Importing libraries
2023-06-04 21:14:44,928:INFO:Copying training dataset
2023-06-04 21:14:44,961:INFO:Defining folds
2023-06-04 21:14:44,961:INFO:Declaring metric variables
2023-06-04 21:14:44,961:INFO:Importing untrained model
2023-06-04 21:14:44,962:INFO:Linear Discriminant Analysis Imported successfully
2023-06-04 21:14:44,963:INFO:Starting cross validation
2023-06-04 21:14:44,964:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:46,519:INFO:Calculating mean and std
2023-06-04 21:14:46,520:INFO:Creating metrics dataframe
2023-06-04 21:14:46,986:INFO:Uploading results into container
2023-06-04 21:14:46,987:INFO:Uploading model into container now
2023-06-04 21:14:46,987:INFO:_master_model_container: 11
2023-06-04 21:14:46,988:INFO:_display_container: 2
2023-06-04 21:14:46,988:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-04 21:14:46,988:INFO:create_model() successfully completed......................................
2023-06-04 21:14:47,151:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:47,151:INFO:Creating metrics dataframe
2023-06-04 21:14:47,161:INFO:Initializing Extra Trees Classifier
2023-06-04 21:14:47,161:INFO:Total runtime is 0.7613475759824118 minutes
2023-06-04 21:14:47,161:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:47,161:INFO:Initializing create_model()
2023-06-04 21:14:47,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:47,161:INFO:Checking exceptions
2023-06-04 21:14:47,161:INFO:Importing libraries
2023-06-04 21:14:47,161:INFO:Copying training dataset
2023-06-04 21:14:47,196:INFO:Defining folds
2023-06-04 21:14:47,196:INFO:Declaring metric variables
2023-06-04 21:14:47,196:INFO:Importing untrained model
2023-06-04 21:14:47,197:INFO:Extra Trees Classifier Imported successfully
2023-06-04 21:14:47,198:INFO:Starting cross validation
2023-06-04 21:14:47,199:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:51,061:INFO:Calculating mean and std
2023-06-04 21:14:51,062:INFO:Creating metrics dataframe
2023-06-04 21:14:51,552:INFO:Uploading results into container
2023-06-04 21:14:51,554:INFO:Uploading model into container now
2023-06-04 21:14:51,554:INFO:_master_model_container: 12
2023-06-04 21:14:51,555:INFO:_display_container: 2
2023-06-04 21:14:51,555:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-04 21:14:51,555:INFO:create_model() successfully completed......................................
2023-06-04 21:14:51,705:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:51,705:INFO:Creating metrics dataframe
2023-06-04 21:14:51,713:INFO:Initializing Light Gradient Boosting Machine
2023-06-04 21:14:51,713:INFO:Total runtime is 0.8372129837671917 minutes
2023-06-04 21:14:51,713:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:51,713:INFO:Initializing create_model()
2023-06-04 21:14:51,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:51,714:INFO:Checking exceptions
2023-06-04 21:14:51,714:INFO:Importing libraries
2023-06-04 21:14:51,714:INFO:Copying training dataset
2023-06-04 21:14:51,743:INFO:Defining folds
2023-06-04 21:14:51,743:INFO:Declaring metric variables
2023-06-04 21:14:51,743:INFO:Importing untrained model
2023-06-04 21:14:51,744:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-04 21:14:51,745:INFO:Starting cross validation
2023-06-04 21:14:51,747:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:53,860:INFO:Calculating mean and std
2023-06-04 21:14:53,861:INFO:Creating metrics dataframe
2023-06-04 21:14:54,311:INFO:Uploading results into container
2023-06-04 21:14:54,312:INFO:Uploading model into container now
2023-06-04 21:14:54,313:INFO:_master_model_container: 13
2023-06-04 21:14:54,313:INFO:_display_container: 2
2023-06-04 21:14:54,314:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-04 21:14:54,314:INFO:create_model() successfully completed......................................
2023-06-04 21:14:54,441:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:54,441:INFO:Creating metrics dataframe
2023-06-04 21:14:54,450:INFO:Initializing Dummy Classifier
2023-06-04 21:14:54,450:INFO:Total runtime is 0.8828348318735759 minutes
2023-06-04 21:14:54,450:INFO:SubProcess create_model() called ==================================
2023-06-04 21:14:54,451:INFO:Initializing create_model()
2023-06-04 21:14:54,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFD94BF110>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:54,451:INFO:Checking exceptions
2023-06-04 21:14:54,451:INFO:Importing libraries
2023-06-04 21:14:54,451:INFO:Copying training dataset
2023-06-04 21:14:54,475:INFO:Defining folds
2023-06-04 21:14:54,475:INFO:Declaring metric variables
2023-06-04 21:14:54,475:INFO:Importing untrained model
2023-06-04 21:14:54,475:INFO:Dummy Classifier Imported successfully
2023-06-04 21:14:54,476:INFO:Starting cross validation
2023-06-04 21:14:54,477:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:14:54,737:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:14:54,770:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:14:54,867:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:14:54,869:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:14:56,023:INFO:Calculating mean and std
2023-06-04 21:14:56,025:INFO:Creating metrics dataframe
2023-06-04 21:14:56,455:INFO:Uploading results into container
2023-06-04 21:14:56,456:INFO:Uploading model into container now
2023-06-04 21:14:56,457:INFO:_master_model_container: 14
2023-06-04 21:14:56,457:INFO:_display_container: 2
2023-06-04 21:14:56,457:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-04 21:14:56,457:INFO:create_model() successfully completed......................................
2023-06-04 21:14:56,592:INFO:SubProcess create_model() end ==================================
2023-06-04 21:14:56,594:INFO:Creating metrics dataframe
2023-06-04 21:14:56,605:INFO:Initializing create_model()
2023-06-04 21:14:56,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:14:56,605:INFO:Checking exceptions
2023-06-04 21:14:56,610:INFO:Importing libraries
2023-06-04 21:14:56,610:INFO:Copying training dataset
2023-06-04 21:14:56,650:INFO:Defining folds
2023-06-04 21:14:56,650:INFO:Declaring metric variables
2023-06-04 21:14:56,651:INFO:Importing untrained model
2023-06-04 21:14:56,651:INFO:Declaring custom model
2023-06-04 21:14:56,653:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:14:56,654:INFO:Cross validation set to False
2023-06-04 21:14:56,654:INFO:Fitting Model
2023-06-04 21:14:57,278:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:14:57,278:INFO:create_model() successfully completed......................................
2023-06-04 21:14:57,485:INFO:_master_model_container: 14
2023-06-04 21:14:57,485:INFO:_display_container: 2
2023-06-04 21:14:57,486:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:14:57,487:INFO:compare_models() successfully completed......................................
2023-06-04 21:14:57,489:INFO:Initializing evaluate_model()
2023-06-04 21:14:57,490:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-04 21:14:57,519:INFO:Initializing plot_model()
2023-06-04 21:14:57,519:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, use_train_data=False, verbose=False, system=True, display=None, display_format=None)
2023-06-04 21:14:57,519:INFO:Checking exceptions
2023-06-04 21:14:57,540:INFO:Preloading libraries
2023-06-04 21:14:57,557:INFO:Copying training dataset
2023-06-04 21:14:57,557:INFO:Plot type: pipeline
2023-06-04 21:14:57,563:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:572: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  fig, ax = plt.subplots(

2023-06-04 21:14:57,789:INFO:Initializing tune_model()
2023-06-04 21:14:57,790:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2023-06-04 21:14:57,790:INFO:Checking exceptions
2023-06-04 21:14:57,820:INFO:Copying training dataset
2023-06-04 21:14:57,881:INFO:Checking base model
2023-06-04 21:14:57,882:INFO:Base model : Gradient Boosting Classifier
2023-06-04 21:14:57,882:INFO:Declaring metric variables
2023-06-04 21:14:57,883:INFO:Defining Hyperparameters
2023-06-04 21:14:58,087:INFO:Tuning with n_jobs=-1
2023-06-04 21:14:58,087:INFO:Initializing RandomizedSearchCV
2023-06-04 21:15:00,109:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 21:15:00,536:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 21:15:01,387:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-04 21:15:02,941:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 21:15:03,329:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 21:15:48,547:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-06-04 21:15:48,548:INFO:Hyperparameter search completed
2023-06-04 21:15:48,548:INFO:SubProcess create_model() called ==================================
2023-06-04 21:15:48,549:INFO:Initializing create_model()
2023-06-04 21:15:48,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDBC21190>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-06-04 21:15:48,550:INFO:Checking exceptions
2023-06-04 21:15:48,550:INFO:Importing libraries
2023-06-04 21:15:48,550:INFO:Copying training dataset
2023-06-04 21:15:48,604:INFO:Defining folds
2023-06-04 21:15:48,604:INFO:Declaring metric variables
2023-06-04 21:15:48,604:INFO:Importing untrained model
2023-06-04 21:15:48,605:INFO:Declaring custom model
2023-06-04 21:15:48,606:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:15:48,606:INFO:Starting cross validation
2023-06-04 21:15:48,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:15:50,057:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 21:15:50,460:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 21:15:53,779:INFO:Calculating mean and std
2023-06-04 21:15:53,780:INFO:Creating metrics dataframe
2023-06-04 21:15:53,783:INFO:Finalizing model
2023-06-04 21:15:54,491:INFO:Uploading results into container
2023-06-04 21:15:54,492:INFO:Uploading model into container now
2023-06-04 21:15:54,492:INFO:_master_model_container: 15
2023-06-04 21:15:54,492:INFO:_display_container: 3
2023-06-04 21:15:54,493:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:15:54,494:INFO:create_model() successfully completed......................................
2023-06-04 21:15:54,648:INFO:SubProcess create_model() end ==================================
2023-06-04 21:15:54,649:INFO:choose_better activated
2023-06-04 21:15:54,649:INFO:SubProcess create_model() called ==================================
2023-06-04 21:15:54,650:INFO:Initializing create_model()
2023-06-04 21:15:54,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFDBBEE750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:15:54,650:INFO:Checking exceptions
2023-06-04 21:15:54,652:INFO:Importing libraries
2023-06-04 21:15:54,652:INFO:Copying training dataset
2023-06-04 21:15:54,687:INFO:Defining folds
2023-06-04 21:15:54,687:INFO:Declaring metric variables
2023-06-04 21:15:54,687:INFO:Importing untrained model
2023-06-04 21:15:54,687:INFO:Declaring custom model
2023-06-04 21:15:54,688:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:15:54,690:INFO:Starting cross validation
2023-06-04 21:15:54,692:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:15:58,868:INFO:Calculating mean and std
2023-06-04 21:15:58,869:INFO:Creating metrics dataframe
2023-06-04 21:15:58,872:INFO:Finalizing model
2023-06-04 21:15:59,612:INFO:Uploading results into container
2023-06-04 21:15:59,613:INFO:Uploading model into container now
2023-06-04 21:15:59,613:INFO:_master_model_container: 16
2023-06-04 21:15:59,613:INFO:_display_container: 4
2023-06-04 21:15:59,614:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:15:59,614:INFO:create_model() successfully completed......................................
2023-06-04 21:15:59,785:INFO:SubProcess create_model() end ==================================
2023-06-04 21:15:59,787:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-04 21:15:59,789:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-04 21:15:59,790:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-06-04 21:15:59,790:INFO:choose_better completed
2023-06-04 21:15:59,791:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-04 21:15:59,822:INFO:_master_model_container: 16
2023-06-04 21:15:59,824:INFO:_display_container: 3
2023-06-04 21:15:59,826:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:15:59,827:INFO:tune_model() successfully completed......................................
2023-06-04 21:17:32,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:17:32,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:17:32,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:17:32,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:17:32,804:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-04 21:18:08,767:INFO:PyCaret ClassificationExperiment
2023-06-04 21:18:08,767:INFO:Logging name: clf-default-name
2023-06-04 21:18:08,767:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-04 21:18:08,768:INFO:version 3.0.0
2023-06-04 21:18:08,768:INFO:Initializing setup()
2023-06-04 21:18:08,768:INFO:self.USI: 472b
2023-06-04 21:18:08,769:INFO:self._variable_keys: {'logging_param', 'memory', 'pipeline', 'fold_shuffle_param', '_available_plots', 'log_plots_param', 'y_train', 'X_train', '_ml_usecase', 'exp_name_log', 'gpu_n_jobs_param', 'exp_id', 'data', 'y_test', 'X_test', 'USI', 'gpu_param', 'fold_generator', 'is_multiclass', 'target_param', 'fix_imbalance', 'X', 'fold_groups_param', 'idx', 'seed', 'y', 'html_param', 'n_jobs_param'}
2023-06-04 21:18:08,769:INFO:Checking environment
2023-06-04 21:18:08,769:INFO:python_version: 3.11.3
2023-06-04 21:18:08,769:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2023-06-04 21:18:08,769:INFO:machine: AMD64
2023-06-04 21:18:08,797:INFO:platform: Windows-10-10.0.19045-SP0
2023-06-04 21:18:08,801:INFO:Memory: svmem(total=8384401408, available=1303842816, percent=84.4, used=7080558592, free=1303842816)
2023-06-04 21:18:08,801:INFO:Physical Core: 4
2023-06-04 21:18:08,801:INFO:Logical Core: 8
2023-06-04 21:18:08,801:INFO:Checking libraries
2023-06-04 21:18:08,801:INFO:System:
2023-06-04 21:18:08,801:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2023-06-04 21:18:08,801:INFO:executable: C:\Program Files\Python311\python.exe
2023-06-04 21:18:08,801:INFO:   machine: Windows-10-10.0.19045-SP0
2023-06-04 21:18:08,801:INFO:PyCaret required dependencies:
2023-06-04 21:18:08,802:INFO:                 pip: 22.3.1
2023-06-04 21:18:08,802:INFO:          setuptools: 65.5.0
2023-06-04 21:18:08,802:INFO:             pycaret: 3.0.0
2023-06-04 21:18:08,802:INFO:             IPython: 8.12.0
2023-06-04 21:18:08,802:INFO:          ipywidgets: 8.0.6
2023-06-04 21:18:08,802:INFO:                tqdm: 4.65.0
2023-06-04 21:18:08,802:INFO:               numpy: 1.24.3
2023-06-04 21:18:08,802:INFO:              pandas: 1.5.3
2023-06-04 21:18:08,802:INFO:              jinja2: 3.1.2
2023-06-04 21:18:08,802:INFO:               scipy: 1.10.1
2023-06-04 21:18:08,802:INFO:              joblib: 1.2.0
2023-06-04 21:18:08,802:INFO:             sklearn: 1.2.2
2023-06-04 21:18:08,802:INFO:                pyod: 1.0.9
2023-06-04 21:18:08,802:INFO:            imblearn: 0.10.1
2023-06-04 21:18:08,802:INFO:   category_encoders: 2.6.0
2023-06-04 21:18:08,803:INFO:            lightgbm: 3.3.5
2023-06-04 21:18:08,803:INFO:               numba: 0.57.0
2023-06-04 21:18:08,803:INFO:            requests: 2.28.2
2023-06-04 21:18:08,803:INFO:          matplotlib: 3.7.1
2023-06-04 21:18:08,803:INFO:          scikitplot: 0.3.7
2023-06-04 21:18:08,803:INFO:         yellowbrick: 1.5
2023-06-04 21:18:08,803:INFO:              plotly: 5.14.1
2023-06-04 21:18:08,803:INFO:             kaleido: 0.2.1
2023-06-04 21:18:08,803:INFO:         statsmodels: 0.14.0
2023-06-04 21:18:08,803:INFO:              sktime: 0.18.0
2023-06-04 21:18:08,803:INFO:               tbats: 1.1.3
2023-06-04 21:18:08,803:INFO:            pmdarima: 2.0.3
2023-06-04 21:18:08,803:INFO:              psutil: 5.9.4
2023-06-04 21:18:08,803:INFO:PyCaret optional dependencies:
2023-06-04 21:18:08,820:INFO:                shap: Not installed
2023-06-04 21:18:08,820:INFO:           interpret: Not installed
2023-06-04 21:18:08,820:INFO:                umap: Not installed
2023-06-04 21:18:08,820:INFO:    pandas_profiling: Not installed
2023-06-04 21:18:08,821:INFO:  explainerdashboard: Not installed
2023-06-04 21:18:08,821:INFO:             autoviz: Not installed
2023-06-04 21:18:08,821:INFO:           fairlearn: Not installed
2023-06-04 21:18:08,821:INFO:             xgboost: Not installed
2023-06-04 21:18:08,821:INFO:            catboost: Not installed
2023-06-04 21:18:08,821:INFO:              kmodes: Not installed
2023-06-04 21:18:08,821:INFO:             mlxtend: Not installed
2023-06-04 21:18:08,821:INFO:       statsforecast: Not installed
2023-06-04 21:18:08,821:INFO:        tune_sklearn: Not installed
2023-06-04 21:18:08,821:INFO:                 ray: Not installed
2023-06-04 21:18:08,821:INFO:            hyperopt: Not installed
2023-06-04 21:18:08,821:INFO:              optuna: Not installed
2023-06-04 21:18:08,821:INFO:               skopt: Not installed
2023-06-04 21:18:08,821:INFO:              mlflow: Not installed
2023-06-04 21:18:08,821:INFO:              gradio: Not installed
2023-06-04 21:18:08,821:INFO:             fastapi: Not installed
2023-06-04 21:18:08,821:INFO:             uvicorn: Not installed
2023-06-04 21:18:08,822:INFO:              m2cgen: Not installed
2023-06-04 21:18:08,822:INFO:           evidently: Not installed
2023-06-04 21:18:08,822:INFO:               fugue: Not installed
2023-06-04 21:18:08,822:INFO:           streamlit: Not installed
2023-06-04 21:18:08,822:INFO:             prophet: 1.1.2
2023-06-04 21:18:08,822:INFO:None
2023-06-04 21:18:08,822:INFO:Set up data.
2023-06-04 21:18:08,850:INFO:Set up train/test split.
2023-06-04 21:18:08,892:INFO:Set up index.
2023-06-04 21:18:08,892:INFO:Set up folding strategy.
2023-06-04 21:18:08,892:INFO:Assigning column types.
2023-06-04 21:18:08,902:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-04 21:18:08,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 21:18:08,967:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:18:09,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,100:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 21:18:09,224:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:18:09,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,285:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-04 21:18:09,357:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:18:09,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,455:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 21:18:09,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,497:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-04 21:18:09,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:09,702:INFO:Preparing preprocessing pipeline...
2023-06-04 21:18:09,709:INFO:Set up simple imputation.
2023-06-04 21:18:09,731:INFO:Set up encoding of ordinal features.
2023-06-04 21:18:09,738:INFO:Set up encoding of categorical features.
2023-06-04 21:18:09,902:INFO:Finished creating preprocessing pipeline.
2023-06-04 21:18:09,922:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\shiva\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'hypertension',
                                             'heart_disease', 'smoking_history',
                                             'bmi', 'HbA1c_level',
                                             'blood_glucose_level'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['gender'],
                                    transformer=OrdinalEncoder(cols=['gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-06-04 21:18:09,922:INFO:Creating final display dataframe.
2023-06-04 21:18:10,059:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          diabetes
2                   Target type            Binary
3           Original data shape        (76885, 9)
4        Transformed data shape        (76885, 9)
5   Transformed train set shape        (57663, 9)
6    Transformed test set shape        (19222, 9)
7              Ordinal features                 1
8              Numeric features                 7
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              472b
2023-06-04 21:18:10,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:10,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:10,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:10,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 21:18:10,304:INFO:setup() successfully completed in 2.01s...............
2023-06-04 21:18:10,304:INFO:Initializing compare_models()
2023-06-04 21:18:10,304:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-06-04 21:18:10,305:INFO:Checking exceptions
2023-06-04 21:18:10,318:INFO:Preparing display monitor
2023-06-04 21:18:10,323:INFO:Initializing Logistic Regression
2023-06-04 21:18:10,323:INFO:Total runtime is 0.0 minutes
2023-06-04 21:18:10,324:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:10,324:INFO:Initializing create_model()
2023-06-04 21:18:10,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:10,324:INFO:Checking exceptions
2023-06-04 21:18:10,324:INFO:Importing libraries
2023-06-04 21:18:10,325:INFO:Copying training dataset
2023-06-04 21:18:10,359:INFO:Defining folds
2023-06-04 21:18:10,359:INFO:Declaring metric variables
2023-06-04 21:18:10,359:INFO:Importing untrained model
2023-06-04 21:18:10,360:INFO:Logistic Regression Imported successfully
2023-06-04 21:18:10,360:INFO:Starting cross validation
2023-06-04 21:18:10,362:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:18,314:INFO:Calculating mean and std
2023-06-04 21:18:18,315:INFO:Creating metrics dataframe
2023-06-04 21:18:18,817:INFO:Uploading results into container
2023-06-04 21:18:18,819:INFO:Uploading model into container now
2023-06-04 21:18:18,819:INFO:_master_model_container: 1
2023-06-04 21:18:18,819:INFO:_display_container: 2
2023-06-04 21:18:18,821:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 21:18:18,821:INFO:create_model() successfully completed......................................
2023-06-04 21:18:18,967:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:18,968:INFO:Creating metrics dataframe
2023-06-04 21:18:18,975:INFO:Initializing K Neighbors Classifier
2023-06-04 21:18:18,975:INFO:Total runtime is 0.14419853687286377 minutes
2023-06-04 21:18:18,975:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:18,976:INFO:Initializing create_model()
2023-06-04 21:18:18,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:18,976:INFO:Checking exceptions
2023-06-04 21:18:18,976:INFO:Importing libraries
2023-06-04 21:18:18,976:INFO:Copying training dataset
2023-06-04 21:18:19,016:INFO:Defining folds
2023-06-04 21:18:19,016:INFO:Declaring metric variables
2023-06-04 21:18:19,017:INFO:Importing untrained model
2023-06-04 21:18:19,017:INFO:K Neighbors Classifier Imported successfully
2023-06-04 21:18:19,018:INFO:Starting cross validation
2023-06-04 21:18:19,020:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:25,330:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 21:18:26,410:INFO:Calculating mean and std
2023-06-04 21:18:26,411:INFO:Creating metrics dataframe
2023-06-04 21:18:26,911:INFO:Uploading results into container
2023-06-04 21:18:26,913:INFO:Uploading model into container now
2023-06-04 21:18:26,915:INFO:_master_model_container: 2
2023-06-04 21:18:26,915:INFO:_display_container: 2
2023-06-04 21:18:26,916:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-04 21:18:26,917:INFO:create_model() successfully completed......................................
2023-06-04 21:18:27,123:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:27,124:INFO:Creating metrics dataframe
2023-06-04 21:18:27,139:INFO:Initializing Naive Bayes
2023-06-04 21:18:27,140:INFO:Total runtime is 0.2802740414937337 minutes
2023-06-04 21:18:27,140:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:27,141:INFO:Initializing create_model()
2023-06-04 21:18:27,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:27,141:INFO:Checking exceptions
2023-06-04 21:18:27,142:INFO:Importing libraries
2023-06-04 21:18:27,142:INFO:Copying training dataset
2023-06-04 21:18:27,192:INFO:Defining folds
2023-06-04 21:18:27,192:INFO:Declaring metric variables
2023-06-04 21:18:27,193:INFO:Importing untrained model
2023-06-04 21:18:27,195:INFO:Naive Bayes Imported successfully
2023-06-04 21:18:27,196:INFO:Starting cross validation
2023-06-04 21:18:27,198:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:29,184:INFO:Calculating mean and std
2023-06-04 21:18:29,185:INFO:Creating metrics dataframe
2023-06-04 21:18:29,561:INFO:Uploading results into container
2023-06-04 21:18:29,566:INFO:Uploading model into container now
2023-06-04 21:18:29,567:INFO:_master_model_container: 3
2023-06-04 21:18:29,567:INFO:_display_container: 2
2023-06-04 21:18:29,567:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-04 21:18:29,568:INFO:create_model() successfully completed......................................
2023-06-04 21:18:29,724:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:29,725:INFO:Creating metrics dataframe
2023-06-04 21:18:29,734:INFO:Initializing Decision Tree Classifier
2023-06-04 21:18:29,735:INFO:Total runtime is 0.32352509895960485 minutes
2023-06-04 21:18:29,735:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:29,735:INFO:Initializing create_model()
2023-06-04 21:18:29,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:29,736:INFO:Checking exceptions
2023-06-04 21:18:29,736:INFO:Importing libraries
2023-06-04 21:18:29,736:INFO:Copying training dataset
2023-06-04 21:18:29,761:INFO:Defining folds
2023-06-04 21:18:29,761:INFO:Declaring metric variables
2023-06-04 21:18:29,762:INFO:Importing untrained model
2023-06-04 21:18:29,762:INFO:Decision Tree Classifier Imported successfully
2023-06-04 21:18:29,762:INFO:Starting cross validation
2023-06-04 21:18:29,763:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:32,010:INFO:Calculating mean and std
2023-06-04 21:18:32,011:INFO:Creating metrics dataframe
2023-06-04 21:18:32,417:INFO:Uploading results into container
2023-06-04 21:18:32,419:INFO:Uploading model into container now
2023-06-04 21:18:32,420:INFO:_master_model_container: 4
2023-06-04 21:18:32,420:INFO:_display_container: 2
2023-06-04 21:18:32,421:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-04 21:18:32,422:INFO:create_model() successfully completed......................................
2023-06-04 21:18:32,562:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:32,562:INFO:Creating metrics dataframe
2023-06-04 21:18:32,573:INFO:Initializing SVM - Linear Kernel
2023-06-04 21:18:32,574:INFO:Total runtime is 0.37082522710164384 minutes
2023-06-04 21:18:32,574:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:32,574:INFO:Initializing create_model()
2023-06-04 21:18:32,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:32,575:INFO:Checking exceptions
2023-06-04 21:18:32,575:INFO:Importing libraries
2023-06-04 21:18:32,575:INFO:Copying training dataset
2023-06-04 21:18:32,610:INFO:Defining folds
2023-06-04 21:18:32,610:INFO:Declaring metric variables
2023-06-04 21:18:32,610:INFO:Importing untrained model
2023-06-04 21:18:32,611:INFO:SVM - Linear Kernel Imported successfully
2023-06-04 21:18:32,611:INFO:Starting cross validation
2023-06-04 21:18:32,613:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:32,961:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:18:32,968:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:18:32,974:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:18:32,996:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 21:18:34,060:INFO:Calculating mean and std
2023-06-04 21:18:34,061:INFO:Creating metrics dataframe
2023-06-04 21:18:34,427:INFO:Uploading results into container
2023-06-04 21:18:34,428:INFO:Uploading model into container now
2023-06-04 21:18:34,429:INFO:_master_model_container: 5
2023-06-04 21:18:34,429:INFO:_display_container: 2
2023-06-04 21:18:34,430:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-04 21:18:34,431:INFO:create_model() successfully completed......................................
2023-06-04 21:18:34,584:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:34,584:INFO:Creating metrics dataframe
2023-06-04 21:18:34,596:INFO:Initializing Ridge Classifier
2023-06-04 21:18:34,596:INFO:Total runtime is 0.4045504728953043 minutes
2023-06-04 21:18:34,597:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:34,598:INFO:Initializing create_model()
2023-06-04 21:18:34,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:34,599:INFO:Checking exceptions
2023-06-04 21:18:34,599:INFO:Importing libraries
2023-06-04 21:18:34,599:INFO:Copying training dataset
2023-06-04 21:18:34,648:INFO:Defining folds
2023-06-04 21:18:34,648:INFO:Declaring metric variables
2023-06-04 21:18:34,649:INFO:Importing untrained model
2023-06-04 21:18:34,650:INFO:Ridge Classifier Imported successfully
2023-06-04 21:18:34,651:INFO:Starting cross validation
2023-06-04 21:18:34,653:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:35,059:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:18:35,091:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:18:35,091:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:18:35,155:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 21:18:36,855:INFO:Calculating mean and std
2023-06-04 21:18:36,856:INFO:Creating metrics dataframe
2023-06-04 21:18:37,344:INFO:Uploading results into container
2023-06-04 21:18:37,345:INFO:Uploading model into container now
2023-06-04 21:18:37,346:INFO:_master_model_container: 6
2023-06-04 21:18:37,346:INFO:_display_container: 2
2023-06-04 21:18:37,348:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-04 21:18:37,348:INFO:create_model() successfully completed......................................
2023-06-04 21:18:37,489:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:37,489:INFO:Creating metrics dataframe
2023-06-04 21:18:37,500:INFO:Initializing Random Forest Classifier
2023-06-04 21:18:37,500:INFO:Total runtime is 0.4529481450716654 minutes
2023-06-04 21:18:37,500:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:37,501:INFO:Initializing create_model()
2023-06-04 21:18:37,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:37,501:INFO:Checking exceptions
2023-06-04 21:18:37,501:INFO:Importing libraries
2023-06-04 21:18:37,501:INFO:Copying training dataset
2023-06-04 21:18:37,531:INFO:Defining folds
2023-06-04 21:18:37,532:INFO:Declaring metric variables
2023-06-04 21:18:37,532:INFO:Importing untrained model
2023-06-04 21:18:37,533:INFO:Random Forest Classifier Imported successfully
2023-06-04 21:18:37,533:INFO:Starting cross validation
2023-06-04 21:18:37,535:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:40,010:INFO:Calculating mean and std
2023-06-04 21:18:40,012:INFO:Creating metrics dataframe
2023-06-04 21:18:40,507:INFO:Uploading results into container
2023-06-04 21:18:40,508:INFO:Uploading model into container now
2023-06-04 21:18:40,509:INFO:_master_model_container: 7
2023-06-04 21:18:40,509:INFO:_display_container: 2
2023-06-04 21:18:40,510:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-04 21:18:40,510:INFO:create_model() successfully completed......................................
2023-06-04 21:18:40,672:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:40,672:INFO:Creating metrics dataframe
2023-06-04 21:18:40,685:INFO:Initializing Quadratic Discriminant Analysis
2023-06-04 21:18:40,685:INFO:Total runtime is 0.506025230884552 minutes
2023-06-04 21:18:40,685:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:40,686:INFO:Initializing create_model()
2023-06-04 21:18:40,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:40,686:INFO:Checking exceptions
2023-06-04 21:18:40,686:INFO:Importing libraries
2023-06-04 21:18:40,687:INFO:Copying training dataset
2023-06-04 21:18:40,726:INFO:Defining folds
2023-06-04 21:18:40,727:INFO:Declaring metric variables
2023-06-04 21:18:40,727:INFO:Importing untrained model
2023-06-04 21:18:40,728:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-04 21:18:40,729:INFO:Starting cross validation
2023-06-04 21:18:40,731:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:42,217:INFO:Calculating mean and std
2023-06-04 21:18:42,218:INFO:Creating metrics dataframe
2023-06-04 21:18:42,756:INFO:Uploading results into container
2023-06-04 21:18:42,757:INFO:Uploading model into container now
2023-06-04 21:18:42,757:INFO:_master_model_container: 8
2023-06-04 21:18:42,757:INFO:_display_container: 2
2023-06-04 21:18:42,758:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-04 21:18:42,758:INFO:create_model() successfully completed......................................
2023-06-04 21:18:42,912:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:42,913:INFO:Creating metrics dataframe
2023-06-04 21:18:42,923:INFO:Initializing Ada Boost Classifier
2023-06-04 21:18:42,923:INFO:Total runtime is 0.5433301170667012 minutes
2023-06-04 21:18:42,923:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:42,924:INFO:Initializing create_model()
2023-06-04 21:18:42,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:42,924:INFO:Checking exceptions
2023-06-04 21:18:42,924:INFO:Importing libraries
2023-06-04 21:18:42,925:INFO:Copying training dataset
2023-06-04 21:18:42,955:INFO:Defining folds
2023-06-04 21:18:42,956:INFO:Declaring metric variables
2023-06-04 21:18:42,956:INFO:Importing untrained model
2023-06-04 21:18:42,957:INFO:Ada Boost Classifier Imported successfully
2023-06-04 21:18:42,957:INFO:Starting cross validation
2023-06-04 21:18:42,958:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:45,123:INFO:Calculating mean and std
2023-06-04 21:18:45,124:INFO:Creating metrics dataframe
2023-06-04 21:18:45,754:INFO:Uploading results into container
2023-06-04 21:18:45,755:INFO:Uploading model into container now
2023-06-04 21:18:45,756:INFO:_master_model_container: 9
2023-06-04 21:18:45,756:INFO:_display_container: 2
2023-06-04 21:18:45,756:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-04 21:18:45,756:INFO:create_model() successfully completed......................................
2023-06-04 21:18:45,913:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:45,913:INFO:Creating metrics dataframe
2023-06-04 21:18:45,925:INFO:Initializing Gradient Boosting Classifier
2023-06-04 21:18:45,925:INFO:Total runtime is 0.5933631857236226 minutes
2023-06-04 21:18:45,926:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:45,926:INFO:Initializing create_model()
2023-06-04 21:18:45,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:45,927:INFO:Checking exceptions
2023-06-04 21:18:45,927:INFO:Importing libraries
2023-06-04 21:18:45,927:INFO:Copying training dataset
2023-06-04 21:18:45,966:INFO:Defining folds
2023-06-04 21:18:45,966:INFO:Declaring metric variables
2023-06-04 21:18:45,967:INFO:Importing untrained model
2023-06-04 21:18:45,968:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:18:45,968:INFO:Starting cross validation
2023-06-04 21:18:45,970:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:47,676:INFO:Calculating mean and std
2023-06-04 21:18:47,677:INFO:Creating metrics dataframe
2023-06-04 21:18:48,154:INFO:Uploading results into container
2023-06-04 21:18:48,155:INFO:Uploading model into container now
2023-06-04 21:18:48,156:INFO:_master_model_container: 10
2023-06-04 21:18:48,156:INFO:_display_container: 2
2023-06-04 21:18:48,157:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:18:48,157:INFO:create_model() successfully completed......................................
2023-06-04 21:18:48,299:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:48,299:INFO:Creating metrics dataframe
2023-06-04 21:18:48,307:INFO:Initializing Linear Discriminant Analysis
2023-06-04 21:18:48,307:INFO:Total runtime is 0.6330575426419576 minutes
2023-06-04 21:18:48,308:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:48,308:INFO:Initializing create_model()
2023-06-04 21:18:48,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:48,308:INFO:Checking exceptions
2023-06-04 21:18:48,308:INFO:Importing libraries
2023-06-04 21:18:48,308:INFO:Copying training dataset
2023-06-04 21:18:48,343:INFO:Defining folds
2023-06-04 21:18:48,344:INFO:Declaring metric variables
2023-06-04 21:18:48,344:INFO:Importing untrained model
2023-06-04 21:18:48,345:INFO:Linear Discriminant Analysis Imported successfully
2023-06-04 21:18:48,345:INFO:Starting cross validation
2023-06-04 21:18:48,347:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:49,898:INFO:Calculating mean and std
2023-06-04 21:18:49,899:INFO:Creating metrics dataframe
2023-06-04 21:18:50,401:INFO:Uploading results into container
2023-06-04 21:18:50,402:INFO:Uploading model into container now
2023-06-04 21:18:50,402:INFO:_master_model_container: 11
2023-06-04 21:18:50,403:INFO:_display_container: 2
2023-06-04 21:18:50,403:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-04 21:18:50,403:INFO:create_model() successfully completed......................................
2023-06-04 21:18:50,558:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:50,559:INFO:Creating metrics dataframe
2023-06-04 21:18:50,569:INFO:Initializing Extra Trees Classifier
2023-06-04 21:18:50,569:INFO:Total runtime is 0.6707601348559061 minutes
2023-06-04 21:18:50,570:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:50,570:INFO:Initializing create_model()
2023-06-04 21:18:50,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:50,570:INFO:Checking exceptions
2023-06-04 21:18:50,571:INFO:Importing libraries
2023-06-04 21:18:50,571:INFO:Copying training dataset
2023-06-04 21:18:50,614:INFO:Defining folds
2023-06-04 21:18:50,615:INFO:Declaring metric variables
2023-06-04 21:18:50,615:INFO:Importing untrained model
2023-06-04 21:18:50,616:INFO:Extra Trees Classifier Imported successfully
2023-06-04 21:18:50,616:INFO:Starting cross validation
2023-06-04 21:18:50,617:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:53,469:INFO:Calculating mean and std
2023-06-04 21:18:53,470:INFO:Creating metrics dataframe
2023-06-04 21:18:54,018:INFO:Uploading results into container
2023-06-04 21:18:54,019:INFO:Uploading model into container now
2023-06-04 21:18:54,020:INFO:_master_model_container: 12
2023-06-04 21:18:54,021:INFO:_display_container: 2
2023-06-04 21:18:54,021:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-04 21:18:54,021:INFO:create_model() successfully completed......................................
2023-06-04 21:18:54,167:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:54,167:INFO:Creating metrics dataframe
2023-06-04 21:18:54,184:INFO:Initializing Light Gradient Boosting Machine
2023-06-04 21:18:54,184:INFO:Total runtime is 0.7310119112332661 minutes
2023-06-04 21:18:54,185:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:54,186:INFO:Initializing create_model()
2023-06-04 21:18:54,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:54,187:INFO:Checking exceptions
2023-06-04 21:18:54,187:INFO:Importing libraries
2023-06-04 21:18:54,188:INFO:Copying training dataset
2023-06-04 21:18:54,236:INFO:Defining folds
2023-06-04 21:18:54,237:INFO:Declaring metric variables
2023-06-04 21:18:54,237:INFO:Importing untrained model
2023-06-04 21:18:54,239:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-04 21:18:54,240:INFO:Starting cross validation
2023-06-04 21:18:54,242:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:56,243:INFO:Calculating mean and std
2023-06-04 21:18:56,244:INFO:Creating metrics dataframe
2023-06-04 21:18:56,810:INFO:Uploading results into container
2023-06-04 21:18:56,812:INFO:Uploading model into container now
2023-06-04 21:18:56,813:INFO:_master_model_container: 13
2023-06-04 21:18:56,813:INFO:_display_container: 2
2023-06-04 21:18:56,814:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-04 21:18:56,814:INFO:create_model() successfully completed......................................
2023-06-04 21:18:56,953:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:56,953:INFO:Creating metrics dataframe
2023-06-04 21:18:56,965:INFO:Initializing Dummy Classifier
2023-06-04 21:18:56,965:INFO:Total runtime is 0.7773630221684773 minutes
2023-06-04 21:18:56,966:INFO:SubProcess create_model() called ==================================
2023-06-04 21:18:56,967:INFO:Initializing create_model()
2023-06-04 21:18:56,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025132426F50>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:56,967:INFO:Checking exceptions
2023-06-04 21:18:56,967:INFO:Importing libraries
2023-06-04 21:18:56,967:INFO:Copying training dataset
2023-06-04 21:18:57,005:INFO:Defining folds
2023-06-04 21:18:57,006:INFO:Declaring metric variables
2023-06-04 21:18:57,006:INFO:Importing untrained model
2023-06-04 21:18:57,007:INFO:Dummy Classifier Imported successfully
2023-06-04 21:18:57,007:INFO:Starting cross validation
2023-06-04 21:18:57,010:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:18:57,298:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:18:57,354:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:18:57,430:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:18:57,432:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 21:18:58,482:INFO:Calculating mean and std
2023-06-04 21:18:58,483:INFO:Creating metrics dataframe
2023-06-04 21:18:59,053:INFO:Uploading results into container
2023-06-04 21:18:59,054:INFO:Uploading model into container now
2023-06-04 21:18:59,055:INFO:_master_model_container: 14
2023-06-04 21:18:59,055:INFO:_display_container: 2
2023-06-04 21:18:59,056:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-04 21:18:59,056:INFO:create_model() successfully completed......................................
2023-06-04 21:18:59,225:INFO:SubProcess create_model() end ==================================
2023-06-04 21:18:59,225:INFO:Creating metrics dataframe
2023-06-04 21:18:59,237:INFO:Initializing create_model()
2023-06-04 21:18:59,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:18:59,238:INFO:Checking exceptions
2023-06-04 21:18:59,243:INFO:Importing libraries
2023-06-04 21:18:59,243:INFO:Copying training dataset
2023-06-04 21:18:59,288:INFO:Defining folds
2023-06-04 21:18:59,288:INFO:Declaring metric variables
2023-06-04 21:18:59,288:INFO:Importing untrained model
2023-06-04 21:18:59,288:INFO:Declaring custom model
2023-06-04 21:18:59,289:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:18:59,290:INFO:Cross validation set to False
2023-06-04 21:18:59,290:INFO:Fitting Model
2023-06-04 21:18:59,767:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:18:59,768:INFO:create_model() successfully completed......................................
2023-06-04 21:18:59,963:INFO:_master_model_container: 14
2023-06-04 21:18:59,963:INFO:_display_container: 2
2023-06-04 21:18:59,964:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:18:59,964:INFO:compare_models() successfully completed......................................
2023-06-04 21:18:59,967:INFO:Initializing evaluate_model()
2023-06-04 21:18:59,967:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-04 21:19:00,216:INFO:Initializing plot_model()
2023-06-04 21:19:00,216:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, use_train_data=False, verbose=False, system=True, display=None, display_format=None)
2023-06-04 21:19:00,217:INFO:Checking exceptions
2023-06-04 21:19:00,237:INFO:Preloading libraries
2023-06-04 21:19:00,258:INFO:Copying training dataset
2023-06-04 21:19:00,258:INFO:Plot type: pipeline
2023-06-04 21:19:00,321:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:572: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  fig, ax = plt.subplots(

2023-06-04 21:19:00,591:INFO:Initializing tune_model()
2023-06-04 21:19:00,591:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2023-06-04 21:19:00,591:INFO:Checking exceptions
2023-06-04 21:19:00,625:INFO:Copying training dataset
2023-06-04 21:19:00,680:INFO:Checking base model
2023-06-04 21:19:00,681:INFO:Base model : Gradient Boosting Classifier
2023-06-04 21:19:00,683:INFO:Declaring metric variables
2023-06-04 21:19:00,684:INFO:Defining Hyperparameters
2023-06-04 21:19:00,835:INFO:Tuning with n_jobs=-1
2023-06-04 21:19:00,835:INFO:Initializing RandomizedSearchCV
2023-06-04 21:19:47,708:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-06-04 21:19:47,708:INFO:Hyperparameter search completed
2023-06-04 21:19:47,708:INFO:SubProcess create_model() called ==================================
2023-06-04 21:19:47,709:INFO:Initializing create_model()
2023-06-04 21:19:47,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025133E53950>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-06-04 21:19:47,710:INFO:Checking exceptions
2023-06-04 21:19:47,710:INFO:Importing libraries
2023-06-04 21:19:47,710:INFO:Copying training dataset
2023-06-04 21:19:47,750:INFO:Defining folds
2023-06-04 21:19:47,750:INFO:Declaring metric variables
2023-06-04 21:19:47,750:INFO:Importing untrained model
2023-06-04 21:19:47,750:INFO:Declaring custom model
2023-06-04 21:19:47,752:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:19:47,752:INFO:Starting cross validation
2023-06-04 21:19:47,753:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:19:52,501:INFO:Calculating mean and std
2023-06-04 21:19:52,503:INFO:Creating metrics dataframe
2023-06-04 21:19:52,511:INFO:Finalizing model
2023-06-04 21:19:53,712:INFO:Uploading results into container
2023-06-04 21:19:53,714:INFO:Uploading model into container now
2023-06-04 21:19:53,715:INFO:_master_model_container: 15
2023-06-04 21:19:53,715:INFO:_display_container: 3
2023-06-04 21:19:53,717:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:19:53,717:INFO:create_model() successfully completed......................................
2023-06-04 21:19:53,893:INFO:SubProcess create_model() end ==================================
2023-06-04 21:19:53,893:INFO:choose_better activated
2023-06-04 21:19:53,895:INFO:SubProcess create_model() called ==================================
2023-06-04 21:19:53,896:INFO:Initializing create_model()
2023-06-04 21:19:53,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025130AF0E90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 21:19:53,897:INFO:Checking exceptions
2023-06-04 21:19:53,899:INFO:Importing libraries
2023-06-04 21:19:53,899:INFO:Copying training dataset
2023-06-04 21:19:53,943:INFO:Defining folds
2023-06-04 21:19:53,943:INFO:Declaring metric variables
2023-06-04 21:19:53,944:INFO:Importing untrained model
2023-06-04 21:19:53,944:INFO:Declaring custom model
2023-06-04 21:19:53,946:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 21:19:53,946:INFO:Starting cross validation
2023-06-04 21:19:53,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 21:20:00,534:INFO:Calculating mean and std
2023-06-04 21:20:00,534:INFO:Creating metrics dataframe
2023-06-04 21:20:00,537:INFO:Finalizing model
2023-06-04 21:20:01,400:INFO:Uploading results into container
2023-06-04 21:20:01,402:INFO:Uploading model into container now
2023-06-04 21:20:01,404:INFO:_master_model_container: 16
2023-06-04 21:20:01,404:INFO:_display_container: 4
2023-06-04 21:20:01,406:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:20:01,406:INFO:create_model() successfully completed......................................
2023-06-04 21:20:01,613:INFO:SubProcess create_model() end ==================================
2023-06-04 21:20:01,614:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-04 21:20:01,615:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-04 21:20:01,616:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-06-04 21:20:01,616:INFO:choose_better completed
2023-06-04 21:20:01,617:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-04 21:20:01,654:INFO:_master_model_container: 16
2023-06-04 21:20:01,654:INFO:_display_container: 3
2023-06-04 21:20:01,655:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 21:20:01,656:INFO:tune_model() successfully completed......................................
2023-06-04 21:22:55,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:22:55,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:22:55,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:22:55,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 21:22:56,046:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:06:23,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:06:23,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:06:23,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:06:23,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:06:25,310:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:08:46,926:INFO:PyCaret ClassificationExperiment
2023-06-05 00:08:46,927:INFO:Logging name: clf-default-name
2023-06-05 00:08:46,927:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-05 00:08:46,927:INFO:version 3.0.0
2023-06-05 00:08:46,927:INFO:Initializing setup()
2023-06-05 00:08:46,927:INFO:self.USI: 74b7
2023-06-05 00:08:46,928:INFO:self._variable_keys: {'y', 'exp_id', 'gpu_n_jobs_param', 'fix_imbalance', 'n_jobs_param', 'fold_groups_param', 'seed', '_ml_usecase', 'log_plots_param', 'target_param', 'fold_shuffle_param', 'idx', 'memory', 'html_param', 'data', 'fold_generator', 'y_test', 'X_test', 'pipeline', 'gpu_param', '_available_plots', 'USI', 'exp_name_log', 'X_train', 'logging_param', 'X', 'is_multiclass', 'y_train'}
2023-06-05 00:08:46,928:INFO:Checking environment
2023-06-05 00:08:46,929:INFO:python_version: 3.11.3
2023-06-05 00:08:46,929:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2023-06-05 00:08:46,929:INFO:machine: AMD64
2023-06-05 00:08:46,965:INFO:platform: Windows-10-10.0.19045-SP0
2023-06-05 00:08:46,969:INFO:Memory: svmem(total=8384401408, available=1286270976, percent=84.7, used=7098130432, free=1286270976)
2023-06-05 00:08:46,970:INFO:Physical Core: 4
2023-06-05 00:08:46,970:INFO:Logical Core: 8
2023-06-05 00:08:46,970:INFO:Checking libraries
2023-06-05 00:08:46,970:INFO:System:
2023-06-05 00:08:46,970:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2023-06-05 00:08:46,971:INFO:executable: C:\Program Files\Python311\python.exe
2023-06-05 00:08:46,971:INFO:   machine: Windows-10-10.0.19045-SP0
2023-06-05 00:08:46,972:INFO:PyCaret required dependencies:
2023-06-05 00:08:46,972:INFO:                 pip: 22.3.1
2023-06-05 00:08:46,973:INFO:          setuptools: 65.5.0
2023-06-05 00:08:46,973:INFO:             pycaret: 3.0.0
2023-06-05 00:08:46,973:INFO:             IPython: 8.12.0
2023-06-05 00:08:46,973:INFO:          ipywidgets: 8.0.6
2023-06-05 00:08:46,974:INFO:                tqdm: 4.65.0
2023-06-05 00:08:46,974:INFO:               numpy: 1.24.3
2023-06-05 00:08:46,974:INFO:              pandas: 1.5.3
2023-06-05 00:08:46,974:INFO:              jinja2: 3.1.2
2023-06-05 00:08:46,975:INFO:               scipy: 1.10.1
2023-06-05 00:08:46,975:INFO:              joblib: 1.2.0
2023-06-05 00:08:46,975:INFO:             sklearn: 1.2.2
2023-06-05 00:08:46,975:INFO:                pyod: 1.0.9
2023-06-05 00:08:46,976:INFO:            imblearn: 0.10.1
2023-06-05 00:08:46,976:INFO:   category_encoders: 2.6.0
2023-06-05 00:08:46,976:INFO:            lightgbm: 3.3.5
2023-06-05 00:08:46,976:INFO:               numba: 0.57.0
2023-06-05 00:08:46,976:INFO:            requests: 2.28.2
2023-06-05 00:08:46,976:INFO:          matplotlib: 3.7.1
2023-06-05 00:08:46,976:INFO:          scikitplot: 0.3.7
2023-06-05 00:08:46,976:INFO:         yellowbrick: 1.5
2023-06-05 00:08:46,976:INFO:              plotly: 5.14.1
2023-06-05 00:08:46,976:INFO:             kaleido: 0.2.1
2023-06-05 00:08:46,976:INFO:         statsmodels: 0.14.0
2023-06-05 00:08:46,976:INFO:              sktime: 0.18.0
2023-06-05 00:08:46,976:INFO:               tbats: 1.1.3
2023-06-05 00:08:46,976:INFO:            pmdarima: 2.0.3
2023-06-05 00:08:46,976:INFO:              psutil: 5.9.4
2023-06-05 00:08:46,976:INFO:PyCaret optional dependencies:
2023-06-05 00:08:46,991:INFO:                shap: Not installed
2023-06-05 00:08:46,991:INFO:           interpret: Not installed
2023-06-05 00:08:46,991:INFO:                umap: Not installed
2023-06-05 00:08:46,991:INFO:    pandas_profiling: Not installed
2023-06-05 00:08:46,991:INFO:  explainerdashboard: Not installed
2023-06-05 00:08:46,991:INFO:             autoviz: Not installed
2023-06-05 00:08:46,991:INFO:           fairlearn: Not installed
2023-06-05 00:08:46,991:INFO:             xgboost: Not installed
2023-06-05 00:08:46,991:INFO:            catboost: Not installed
2023-06-05 00:08:46,991:INFO:              kmodes: Not installed
2023-06-05 00:08:46,991:INFO:             mlxtend: Not installed
2023-06-05 00:08:46,991:INFO:       statsforecast: Not installed
2023-06-05 00:08:46,991:INFO:        tune_sklearn: Not installed
2023-06-05 00:08:46,991:INFO:                 ray: Not installed
2023-06-05 00:08:46,991:INFO:            hyperopt: Not installed
2023-06-05 00:08:46,991:INFO:              optuna: Not installed
2023-06-05 00:08:46,991:INFO:               skopt: Not installed
2023-06-05 00:08:46,991:INFO:              mlflow: Not installed
2023-06-05 00:08:46,991:INFO:              gradio: Not installed
2023-06-05 00:08:46,991:INFO:             fastapi: Not installed
2023-06-05 00:08:46,991:INFO:             uvicorn: Not installed
2023-06-05 00:08:46,991:INFO:              m2cgen: Not installed
2023-06-05 00:08:46,991:INFO:           evidently: Not installed
2023-06-05 00:08:46,991:INFO:               fugue: Not installed
2023-06-05 00:08:46,991:INFO:           streamlit: Not installed
2023-06-05 00:08:46,991:INFO:             prophet: 1.1.2
2023-06-05 00:08:46,991:INFO:None
2023-06-05 00:08:46,991:INFO:Set up data.
2023-06-05 00:08:47,021:INFO:Set up train/test split.
2023-06-05 00:08:47,045:INFO:Set up index.
2023-06-05 00:08:47,053:INFO:Set up folding strategy.
2023-06-05 00:08:47,053:INFO:Assigning column types.
2023-06-05 00:08:47,057:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-05 00:08:47,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 00:08:47,106:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:08:47,155:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 00:08:47,458:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:08:47,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,503:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,504:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-05 00:08:47,550:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:08:47,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,620:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:08:47,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,648:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-05 00:08:47,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:47,778:INFO:Preparing preprocessing pipeline...
2023-06-05 00:08:47,790:INFO:Set up simple imputation.
2023-06-05 00:08:47,803:INFO:Set up encoding of ordinal features.
2023-06-05 00:08:47,808:INFO:Set up encoding of categorical features.
2023-06-05 00:08:47,932:INFO:Finished creating preprocessing pipeline.
2023-06-05 00:08:47,954:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\shiva\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'hypertension',
                                             'heart_disease', 'smoking_history',
                                             'bmi', 'HbA1c_level',
                                             'blood_glucose_level'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['gender'],
                                    transformer=OrdinalEncoder(cols=['gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-06-05 00:08:47,954:INFO:Creating final display dataframe.
2023-06-05 00:08:48,061:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          diabetes
2                   Target type            Binary
3           Original data shape        (76885, 9)
4        Transformed data shape        (76885, 9)
5   Transformed train set shape        (57663, 9)
6    Transformed test set shape        (19222, 9)
7              Ordinal features                 1
8              Numeric features                 7
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              74b7
2023-06-05 00:08:48,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:48,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:48,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:48,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:08:48,251:INFO:setup() successfully completed in 2.08s...............
2023-06-05 00:08:48,251:INFO:Initializing compare_models()
2023-06-05 00:08:48,251:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-06-05 00:08:48,251:INFO:Checking exceptions
2023-06-05 00:08:48,262:INFO:Preparing display monitor
2023-06-05 00:08:48,275:INFO:Initializing Logistic Regression
2023-06-05 00:08:48,275:INFO:Total runtime is 0.0 minutes
2023-06-05 00:08:48,276:INFO:SubProcess create_model() called ==================================
2023-06-05 00:08:48,276:INFO:Initializing create_model()
2023-06-05 00:08:48,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:08:48,277:INFO:Checking exceptions
2023-06-05 00:08:48,277:INFO:Importing libraries
2023-06-05 00:08:48,277:INFO:Copying training dataset
2023-06-05 00:08:48,319:INFO:Defining folds
2023-06-05 00:08:48,319:INFO:Declaring metric variables
2023-06-05 00:08:48,319:INFO:Importing untrained model
2023-06-05 00:08:48,320:INFO:Logistic Regression Imported successfully
2023-06-05 00:08:48,320:INFO:Starting cross validation
2023-06-05 00:08:48,322:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:08:57,114:INFO:Calculating mean and std
2023-06-05 00:08:57,120:INFO:Creating metrics dataframe
2023-06-05 00:08:57,812:INFO:Uploading results into container
2023-06-05 00:08:57,813:INFO:Uploading model into container now
2023-06-05 00:08:57,814:INFO:_master_model_container: 1
2023-06-05 00:08:57,815:INFO:_display_container: 2
2023-06-05 00:08:57,815:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-05 00:08:57,815:INFO:create_model() successfully completed......................................
2023-06-05 00:08:57,959:INFO:SubProcess create_model() end ==================================
2023-06-05 00:08:57,959:INFO:Creating metrics dataframe
2023-06-05 00:08:57,969:INFO:Initializing K Neighbors Classifier
2023-06-05 00:08:57,970:INFO:Total runtime is 0.16159306367238363 minutes
2023-06-05 00:08:57,971:INFO:SubProcess create_model() called ==================================
2023-06-05 00:08:57,971:INFO:Initializing create_model()
2023-06-05 00:08:57,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:08:57,972:INFO:Checking exceptions
2023-06-05 00:08:57,972:INFO:Importing libraries
2023-06-05 00:08:57,972:INFO:Copying training dataset
2023-06-05 00:08:58,013:INFO:Defining folds
2023-06-05 00:08:58,014:INFO:Declaring metric variables
2023-06-05 00:08:58,014:INFO:Importing untrained model
2023-06-05 00:08:58,015:INFO:K Neighbors Classifier Imported successfully
2023-06-05 00:08:58,016:INFO:Starting cross validation
2023-06-05 00:08:58,018:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:10,834:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-05 00:09:12,054:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-05 00:09:14,261:INFO:Calculating mean and std
2023-06-05 00:09:14,261:INFO:Creating metrics dataframe
2023-06-05 00:09:15,257:INFO:Uploading results into container
2023-06-05 00:09:15,267:INFO:Uploading model into container now
2023-06-05 00:09:15,268:INFO:_master_model_container: 2
2023-06-05 00:09:15,268:INFO:_display_container: 2
2023-06-05 00:09:15,269:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-05 00:09:15,269:INFO:create_model() successfully completed......................................
2023-06-05 00:09:15,467:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:15,467:INFO:Creating metrics dataframe
2023-06-05 00:09:15,484:INFO:Initializing Naive Bayes
2023-06-05 00:09:15,484:INFO:Total runtime is 0.45348942279815674 minutes
2023-06-05 00:09:15,484:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:15,484:INFO:Initializing create_model()
2023-06-05 00:09:15,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:15,484:INFO:Checking exceptions
2023-06-05 00:09:15,484:INFO:Importing libraries
2023-06-05 00:09:15,484:INFO:Copying training dataset
2023-06-05 00:09:15,535:INFO:Defining folds
2023-06-05 00:09:15,535:INFO:Declaring metric variables
2023-06-05 00:09:15,535:INFO:Importing untrained model
2023-06-05 00:09:15,535:INFO:Naive Bayes Imported successfully
2023-06-05 00:09:15,543:INFO:Starting cross validation
2023-06-05 00:09:15,545:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:18,354:INFO:Calculating mean and std
2023-06-05 00:09:18,354:INFO:Creating metrics dataframe
2023-06-05 00:09:19,349:INFO:Uploading results into container
2023-06-05 00:09:19,349:INFO:Uploading model into container now
2023-06-05 00:09:19,349:INFO:_master_model_container: 3
2023-06-05 00:09:19,349:INFO:_display_container: 2
2023-06-05 00:09:19,349:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-05 00:09:19,349:INFO:create_model() successfully completed......................................
2023-06-05 00:09:19,518:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:19,518:INFO:Creating metrics dataframe
2023-06-05 00:09:19,532:INFO:Initializing Decision Tree Classifier
2023-06-05 00:09:19,532:INFO:Total runtime is 0.5209513624509176 minutes
2023-06-05 00:09:19,532:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:19,532:INFO:Initializing create_model()
2023-06-05 00:09:19,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:19,532:INFO:Checking exceptions
2023-06-05 00:09:19,532:INFO:Importing libraries
2023-06-05 00:09:19,532:INFO:Copying training dataset
2023-06-05 00:09:19,561:INFO:Defining folds
2023-06-05 00:09:19,561:INFO:Declaring metric variables
2023-06-05 00:09:19,570:INFO:Importing untrained model
2023-06-05 00:09:19,571:INFO:Decision Tree Classifier Imported successfully
2023-06-05 00:09:19,571:INFO:Starting cross validation
2023-06-05 00:09:19,572:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:21,976:INFO:Calculating mean and std
2023-06-05 00:09:21,977:INFO:Creating metrics dataframe
2023-06-05 00:09:22,907:INFO:Uploading results into container
2023-06-05 00:09:22,907:INFO:Uploading model into container now
2023-06-05 00:09:22,907:INFO:_master_model_container: 4
2023-06-05 00:09:22,907:INFO:_display_container: 2
2023-06-05 00:09:22,907:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-05 00:09:22,907:INFO:create_model() successfully completed......................................
2023-06-05 00:09:23,066:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:23,066:INFO:Creating metrics dataframe
2023-06-05 00:09:23,081:INFO:Initializing SVM - Linear Kernel
2023-06-05 00:09:23,081:INFO:Total runtime is 0.580110744635264 minutes
2023-06-05 00:09:23,082:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:23,082:INFO:Initializing create_model()
2023-06-05 00:09:23,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:23,083:INFO:Checking exceptions
2023-06-05 00:09:23,083:INFO:Importing libraries
2023-06-05 00:09:23,083:INFO:Copying training dataset
2023-06-05 00:09:23,137:INFO:Defining folds
2023-06-05 00:09:23,137:INFO:Declaring metric variables
2023-06-05 00:09:23,137:INFO:Importing untrained model
2023-06-05 00:09:23,138:INFO:SVM - Linear Kernel Imported successfully
2023-06-05 00:09:23,138:INFO:Starting cross validation
2023-06-05 00:09:23,138:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:23,524:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:09:23,636:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:09:23,679:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:09:23,787:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:09:25,833:INFO:Calculating mean and std
2023-06-05 00:09:25,835:INFO:Creating metrics dataframe
2023-06-05 00:09:26,732:INFO:Uploading results into container
2023-06-05 00:09:26,733:INFO:Uploading model into container now
2023-06-05 00:09:26,733:INFO:_master_model_container: 5
2023-06-05 00:09:26,733:INFO:_display_container: 2
2023-06-05 00:09:26,733:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-05 00:09:26,733:INFO:create_model() successfully completed......................................
2023-06-05 00:09:26,883:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:26,883:INFO:Creating metrics dataframe
2023-06-05 00:09:26,902:INFO:Initializing Ridge Classifier
2023-06-05 00:09:26,902:INFO:Total runtime is 0.6437879522641499 minutes
2023-06-05 00:09:26,902:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:26,902:INFO:Initializing create_model()
2023-06-05 00:09:26,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:26,902:INFO:Checking exceptions
2023-06-05 00:09:26,902:INFO:Importing libraries
2023-06-05 00:09:26,902:INFO:Copying training dataset
2023-06-05 00:09:26,949:INFO:Defining folds
2023-06-05 00:09:26,949:INFO:Declaring metric variables
2023-06-05 00:09:26,949:INFO:Importing untrained model
2023-06-05 00:09:26,949:INFO:Ridge Classifier Imported successfully
2023-06-05 00:09:26,949:INFO:Starting cross validation
2023-06-05 00:09:26,949:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:27,319:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:09:27,350:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:09:27,434:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:09:27,481:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:09:29,738:INFO:Calculating mean and std
2023-06-05 00:09:29,739:INFO:Creating metrics dataframe
2023-06-05 00:09:30,655:INFO:Uploading results into container
2023-06-05 00:09:30,656:INFO:Uploading model into container now
2023-06-05 00:09:30,656:INFO:_master_model_container: 6
2023-06-05 00:09:30,656:INFO:_display_container: 2
2023-06-05 00:09:30,659:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-05 00:09:30,660:INFO:create_model() successfully completed......................................
2023-06-05 00:09:30,846:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:30,847:INFO:Creating metrics dataframe
2023-06-05 00:09:30,861:INFO:Initializing Random Forest Classifier
2023-06-05 00:09:30,861:INFO:Total runtime is 0.709768239657084 minutes
2023-06-05 00:09:30,861:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:30,861:INFO:Initializing create_model()
2023-06-05 00:09:30,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:30,864:INFO:Checking exceptions
2023-06-05 00:09:30,864:INFO:Importing libraries
2023-06-05 00:09:30,864:INFO:Copying training dataset
2023-06-05 00:09:30,921:INFO:Defining folds
2023-06-05 00:09:30,921:INFO:Declaring metric variables
2023-06-05 00:09:30,921:INFO:Importing untrained model
2023-06-05 00:09:30,921:INFO:Random Forest Classifier Imported successfully
2023-06-05 00:09:30,921:INFO:Starting cross validation
2023-06-05 00:09:30,926:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:34,610:INFO:Calculating mean and std
2023-06-05 00:09:34,610:INFO:Creating metrics dataframe
2023-06-05 00:09:35,605:INFO:Uploading results into container
2023-06-05 00:09:35,605:INFO:Uploading model into container now
2023-06-05 00:09:35,605:INFO:_master_model_container: 7
2023-06-05 00:09:35,605:INFO:_display_container: 2
2023-06-05 00:09:35,605:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-05 00:09:35,605:INFO:create_model() successfully completed......................................
2023-06-05 00:09:35,791:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:35,791:INFO:Creating metrics dataframe
2023-06-05 00:09:35,806:INFO:Initializing Quadratic Discriminant Analysis
2023-06-05 00:09:35,806:INFO:Total runtime is 0.792186947663625 minutes
2023-06-05 00:09:35,806:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:35,806:INFO:Initializing create_model()
2023-06-05 00:09:35,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:35,806:INFO:Checking exceptions
2023-06-05 00:09:35,806:INFO:Importing libraries
2023-06-05 00:09:35,806:INFO:Copying training dataset
2023-06-05 00:09:35,845:INFO:Defining folds
2023-06-05 00:09:35,846:INFO:Declaring metric variables
2023-06-05 00:09:35,846:INFO:Importing untrained model
2023-06-05 00:09:35,846:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-05 00:09:35,846:INFO:Starting cross validation
2023-06-05 00:09:35,846:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:38,518:INFO:Calculating mean and std
2023-06-05 00:09:38,518:INFO:Creating metrics dataframe
2023-06-05 00:09:39,421:INFO:Uploading results into container
2023-06-05 00:09:39,421:INFO:Uploading model into container now
2023-06-05 00:09:39,421:INFO:_master_model_container: 8
2023-06-05 00:09:39,421:INFO:_display_container: 2
2023-06-05 00:09:39,421:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-05 00:09:39,421:INFO:create_model() successfully completed......................................
2023-06-05 00:09:39,599:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:39,599:INFO:Creating metrics dataframe
2023-06-05 00:09:39,614:INFO:Initializing Ada Boost Classifier
2023-06-05 00:09:39,614:INFO:Total runtime is 0.8556622147560118 minutes
2023-06-05 00:09:39,615:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:39,616:INFO:Initializing create_model()
2023-06-05 00:09:39,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:39,616:INFO:Checking exceptions
2023-06-05 00:09:39,616:INFO:Importing libraries
2023-06-05 00:09:39,617:INFO:Copying training dataset
2023-06-05 00:09:39,666:INFO:Defining folds
2023-06-05 00:09:39,666:INFO:Declaring metric variables
2023-06-05 00:09:39,666:INFO:Importing untrained model
2023-06-05 00:09:39,666:INFO:Ada Boost Classifier Imported successfully
2023-06-05 00:09:39,666:INFO:Starting cross validation
2023-06-05 00:09:39,666:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:41,371:INFO:Calculating mean and std
2023-06-05 00:09:41,372:INFO:Creating metrics dataframe
2023-06-05 00:09:41,655:INFO:Uploading results into container
2023-06-05 00:09:41,656:INFO:Uploading model into container now
2023-06-05 00:09:41,656:INFO:_master_model_container: 9
2023-06-05 00:09:41,656:INFO:_display_container: 2
2023-06-05 00:09:41,657:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-05 00:09:41,657:INFO:create_model() successfully completed......................................
2023-06-05 00:09:41,785:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:41,786:INFO:Creating metrics dataframe
2023-06-05 00:09:41,796:INFO:Initializing Gradient Boosting Classifier
2023-06-05 00:09:41,796:INFO:Total runtime is 0.8920221328735349 minutes
2023-06-05 00:09:41,796:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:41,797:INFO:Initializing create_model()
2023-06-05 00:09:41,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:41,798:INFO:Checking exceptions
2023-06-05 00:09:41,798:INFO:Importing libraries
2023-06-05 00:09:41,798:INFO:Copying training dataset
2023-06-05 00:09:41,825:INFO:Defining folds
2023-06-05 00:09:41,825:INFO:Declaring metric variables
2023-06-05 00:09:41,825:INFO:Importing untrained model
2023-06-05 00:09:41,826:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:09:41,826:INFO:Starting cross validation
2023-06-05 00:09:41,827:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:42,925:INFO:Calculating mean and std
2023-06-05 00:09:42,926:INFO:Creating metrics dataframe
2023-06-05 00:09:43,207:INFO:Uploading results into container
2023-06-05 00:09:43,208:INFO:Uploading model into container now
2023-06-05 00:09:43,208:INFO:_master_model_container: 10
2023-06-05 00:09:43,209:INFO:_display_container: 2
2023-06-05 00:09:43,209:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:09:43,209:INFO:create_model() successfully completed......................................
2023-06-05 00:09:43,337:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:43,337:INFO:Creating metrics dataframe
2023-06-05 00:09:43,343:INFO:Initializing Linear Discriminant Analysis
2023-06-05 00:09:43,343:INFO:Total runtime is 0.917805488904317 minutes
2023-06-05 00:09:43,343:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:43,351:INFO:Initializing create_model()
2023-06-05 00:09:43,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:43,351:INFO:Checking exceptions
2023-06-05 00:09:43,351:INFO:Importing libraries
2023-06-05 00:09:43,351:INFO:Copying training dataset
2023-06-05 00:09:43,377:INFO:Defining folds
2023-06-05 00:09:43,377:INFO:Declaring metric variables
2023-06-05 00:09:43,377:INFO:Importing untrained model
2023-06-05 00:09:43,378:INFO:Linear Discriminant Analysis Imported successfully
2023-06-05 00:09:43,378:INFO:Starting cross validation
2023-06-05 00:09:43,379:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:44,354:INFO:Calculating mean and std
2023-06-05 00:09:44,354:INFO:Creating metrics dataframe
2023-06-05 00:09:44,608:INFO:Uploading results into container
2023-06-05 00:09:44,608:INFO:Uploading model into container now
2023-06-05 00:09:44,609:INFO:_master_model_container: 11
2023-06-05 00:09:44,609:INFO:_display_container: 2
2023-06-05 00:09:44,609:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-05 00:09:44,609:INFO:create_model() successfully completed......................................
2023-06-05 00:09:44,731:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:44,732:INFO:Creating metrics dataframe
2023-06-05 00:09:44,739:INFO:Initializing Extra Trees Classifier
2023-06-05 00:09:44,740:INFO:Total runtime is 0.941096246242523 minutes
2023-06-05 00:09:44,740:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:44,740:INFO:Initializing create_model()
2023-06-05 00:09:44,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:44,741:INFO:Checking exceptions
2023-06-05 00:09:44,741:INFO:Importing libraries
2023-06-05 00:09:44,741:INFO:Copying training dataset
2023-06-05 00:09:44,769:INFO:Defining folds
2023-06-05 00:09:44,769:INFO:Declaring metric variables
2023-06-05 00:09:44,769:INFO:Importing untrained model
2023-06-05 00:09:44,770:INFO:Extra Trees Classifier Imported successfully
2023-06-05 00:09:44,770:INFO:Starting cross validation
2023-06-05 00:09:44,771:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:46,815:INFO:Calculating mean and std
2023-06-05 00:09:46,815:INFO:Creating metrics dataframe
2023-06-05 00:09:47,078:INFO:Uploading results into container
2023-06-05 00:09:47,079:INFO:Uploading model into container now
2023-06-05 00:09:47,079:INFO:_master_model_container: 12
2023-06-05 00:09:47,079:INFO:_display_container: 2
2023-06-05 00:09:47,080:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-05 00:09:47,080:INFO:create_model() successfully completed......................................
2023-06-05 00:09:47,197:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:47,197:INFO:Creating metrics dataframe
2023-06-05 00:09:47,201:INFO:Initializing Light Gradient Boosting Machine
2023-06-05 00:09:47,201:INFO:Total runtime is 0.9821040948232013 minutes
2023-06-05 00:09:47,201:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:47,201:INFO:Initializing create_model()
2023-06-05 00:09:47,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:47,201:INFO:Checking exceptions
2023-06-05 00:09:47,201:INFO:Importing libraries
2023-06-05 00:09:47,201:INFO:Copying training dataset
2023-06-05 00:09:47,232:INFO:Defining folds
2023-06-05 00:09:47,236:INFO:Declaring metric variables
2023-06-05 00:09:47,236:INFO:Importing untrained model
2023-06-05 00:09:47,238:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-05 00:09:47,238:INFO:Starting cross validation
2023-06-05 00:09:47,240:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:48,428:INFO:Calculating mean and std
2023-06-05 00:09:48,428:INFO:Creating metrics dataframe
2023-06-05 00:09:48,716:INFO:Uploading results into container
2023-06-05 00:09:48,718:INFO:Uploading model into container now
2023-06-05 00:09:48,718:INFO:_master_model_container: 13
2023-06-05 00:09:48,719:INFO:_display_container: 2
2023-06-05 00:09:48,719:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-05 00:09:48,719:INFO:create_model() successfully completed......................................
2023-06-05 00:09:48,851:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:48,851:INFO:Creating metrics dataframe
2023-06-05 00:09:48,857:INFO:Initializing Dummy Classifier
2023-06-05 00:09:48,857:INFO:Total runtime is 1.0097081979115803 minutes
2023-06-05 00:09:48,857:INFO:SubProcess create_model() called ==================================
2023-06-05 00:09:48,857:INFO:Initializing create_model()
2023-06-05 00:09:48,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024745A198D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:48,857:INFO:Checking exceptions
2023-06-05 00:09:48,858:INFO:Importing libraries
2023-06-05 00:09:48,858:INFO:Copying training dataset
2023-06-05 00:09:48,880:INFO:Defining folds
2023-06-05 00:09:48,880:INFO:Declaring metric variables
2023-06-05 00:09:48,880:INFO:Importing untrained model
2023-06-05 00:09:48,880:INFO:Dummy Classifier Imported successfully
2023-06-05 00:09:48,881:INFO:Starting cross validation
2023-06-05 00:09:48,882:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:09:49,103:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:09:49,200:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:09:49,201:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:09:49,230:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:09:49,991:INFO:Calculating mean and std
2023-06-05 00:09:49,991:INFO:Creating metrics dataframe
2023-06-05 00:09:50,551:INFO:Uploading results into container
2023-06-05 00:09:50,553:INFO:Uploading model into container now
2023-06-05 00:09:50,554:INFO:_master_model_container: 14
2023-06-05 00:09:50,554:INFO:_display_container: 2
2023-06-05 00:09:50,554:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-05 00:09:50,554:INFO:create_model() successfully completed......................................
2023-06-05 00:09:50,706:INFO:SubProcess create_model() end ==================================
2023-06-05 00:09:50,706:INFO:Creating metrics dataframe
2023-06-05 00:09:50,724:INFO:Initializing create_model()
2023-06-05 00:09:50,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:09:50,724:INFO:Checking exceptions
2023-06-05 00:09:50,728:INFO:Importing libraries
2023-06-05 00:09:50,728:INFO:Copying training dataset
2023-06-05 00:09:50,778:INFO:Defining folds
2023-06-05 00:09:50,778:INFO:Declaring metric variables
2023-06-05 00:09:50,778:INFO:Importing untrained model
2023-06-05 00:09:50,779:INFO:Declaring custom model
2023-06-05 00:09:50,780:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:09:50,782:INFO:Cross validation set to False
2023-06-05 00:09:50,782:INFO:Fitting Model
2023-06-05 00:09:51,632:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:09:51,632:INFO:create_model() successfully completed......................................
2023-06-05 00:09:51,784:INFO:_master_model_container: 14
2023-06-05 00:09:51,785:INFO:_display_container: 2
2023-06-05 00:09:51,787:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:09:51,787:INFO:compare_models() successfully completed......................................
2023-06-05 00:09:51,788:INFO:Initializing evaluate_model()
2023-06-05 00:09:51,788:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-05 00:09:52,146:INFO:Initializing plot_model()
2023-06-05 00:09:52,146:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, use_train_data=False, verbose=False, system=True, display=None, display_format=None)
2023-06-05 00:09:52,146:INFO:Checking exceptions
2023-06-05 00:09:52,155:INFO:Preloading libraries
2023-06-05 00:09:52,172:INFO:Copying training dataset
2023-06-05 00:09:52,172:INFO:Plot type: pipeline
2023-06-05 00:09:52,240:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:572: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  fig, ax = plt.subplots(

2023-06-05 00:09:52,461:INFO:Initializing tune_model()
2023-06-05 00:09:52,462:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2023-06-05 00:09:52,462:INFO:Checking exceptions
2023-06-05 00:09:52,477:INFO:Copying training dataset
2023-06-05 00:09:52,506:INFO:Checking base model
2023-06-05 00:09:52,506:INFO:Base model : Gradient Boosting Classifier
2023-06-05 00:09:52,507:INFO:Declaring metric variables
2023-06-05 00:09:52,507:INFO:Defining Hyperparameters
2023-06-05 00:09:52,642:INFO:Tuning with n_jobs=-1
2023-06-05 00:09:52,643:INFO:Initializing RandomizedSearchCV
2023-06-05 00:10:50,855:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-06-05 00:10:50,857:INFO:Hyperparameter search completed
2023-06-05 00:10:50,857:INFO:SubProcess create_model() called ==================================
2023-06-05 00:10:50,858:INFO:Initializing create_model()
2023-06-05 00:10:50,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024747090550>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-06-05 00:10:50,858:INFO:Checking exceptions
2023-06-05 00:10:50,858:INFO:Importing libraries
2023-06-05 00:10:50,860:INFO:Copying training dataset
2023-06-05 00:10:50,951:INFO:Defining folds
2023-06-05 00:10:50,951:INFO:Declaring metric variables
2023-06-05 00:10:50,951:INFO:Importing untrained model
2023-06-05 00:10:50,951:INFO:Declaring custom model
2023-06-05 00:10:50,951:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:10:50,951:INFO:Starting cross validation
2023-06-05 00:10:50,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:10:59,134:INFO:Calculating mean and std
2023-06-05 00:10:59,143:INFO:Creating metrics dataframe
2023-06-05 00:10:59,150:INFO:Finalizing model
2023-06-05 00:11:00,534:INFO:Uploading results into container
2023-06-05 00:11:00,542:INFO:Uploading model into container now
2023-06-05 00:11:00,542:INFO:_master_model_container: 15
2023-06-05 00:11:00,542:INFO:_display_container: 3
2023-06-05 00:11:00,542:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:11:00,542:INFO:create_model() successfully completed......................................
2023-06-05 00:11:00,753:INFO:SubProcess create_model() end ==================================
2023-06-05 00:11:00,753:INFO:choose_better activated
2023-06-05 00:11:00,754:INFO:SubProcess create_model() called ==================================
2023-06-05 00:11:00,754:INFO:Initializing create_model()
2023-06-05 00:11:00,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024745665390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:11:00,754:INFO:Checking exceptions
2023-06-05 00:11:00,754:INFO:Importing libraries
2023-06-05 00:11:00,754:INFO:Copying training dataset
2023-06-05 00:11:00,801:INFO:Defining folds
2023-06-05 00:11:00,801:INFO:Declaring metric variables
2023-06-05 00:11:00,801:INFO:Importing untrained model
2023-06-05 00:11:00,801:INFO:Declaring custom model
2023-06-05 00:11:00,810:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:11:00,810:INFO:Starting cross validation
2023-06-05 00:11:00,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:11:08,687:INFO:Calculating mean and std
2023-06-05 00:11:08,688:INFO:Creating metrics dataframe
2023-06-05 00:11:08,688:INFO:Finalizing model
2023-06-05 00:11:10,011:INFO:Uploading results into container
2023-06-05 00:11:10,018:INFO:Uploading model into container now
2023-06-05 00:11:10,019:INFO:_master_model_container: 16
2023-06-05 00:11:10,020:INFO:_display_container: 4
2023-06-05 00:11:10,020:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:11:10,020:INFO:create_model() successfully completed......................................
2023-06-05 00:11:10,172:INFO:SubProcess create_model() end ==================================
2023-06-05 00:11:10,172:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-05 00:11:10,172:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-05 00:11:10,180:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-06-05 00:11:10,181:INFO:choose_better completed
2023-06-05 00:11:10,182:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-05 00:11:10,211:INFO:_master_model_container: 16
2023-06-05 00:11:10,211:INFO:_display_container: 3
2023-06-05 00:11:10,218:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:11:10,218:INFO:tune_model() successfully completed......................................
2023-06-05 00:12:22,483:INFO:PyCaret ClassificationExperiment
2023-06-05 00:12:22,483:INFO:Logging name: clf-default-name
2023-06-05 00:12:22,483:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-05 00:12:22,483:INFO:version 3.0.0
2023-06-05 00:12:22,483:INFO:Initializing setup()
2023-06-05 00:12:22,483:INFO:self.USI: dbec
2023-06-05 00:12:22,483:INFO:self._variable_keys: {'y', 'exp_id', 'gpu_n_jobs_param', 'fix_imbalance', 'n_jobs_param', 'fold_groups_param', 'seed', '_ml_usecase', 'log_plots_param', 'target_param', 'fold_shuffle_param', 'idx', 'memory', 'html_param', 'data', 'fold_generator', 'y_test', 'X_test', 'pipeline', 'gpu_param', '_available_plots', 'USI', 'exp_name_log', 'X_train', 'logging_param', 'X', 'is_multiclass', 'y_train'}
2023-06-05 00:12:22,483:INFO:Checking environment
2023-06-05 00:12:22,483:INFO:python_version: 3.11.3
2023-06-05 00:12:22,483:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2023-06-05 00:12:22,483:INFO:machine: AMD64
2023-06-05 00:12:22,483:INFO:platform: Windows-10-10.0.19045-SP0
2023-06-05 00:12:22,491:INFO:Memory: svmem(total=8384401408, available=1081237504, percent=87.1, used=7303163904, free=1081237504)
2023-06-05 00:12:22,491:INFO:Physical Core: 4
2023-06-05 00:12:22,491:INFO:Logical Core: 8
2023-06-05 00:12:22,491:INFO:Checking libraries
2023-06-05 00:12:22,491:INFO:System:
2023-06-05 00:12:22,491:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2023-06-05 00:12:22,491:INFO:executable: C:\Program Files\Python311\python.exe
2023-06-05 00:12:22,491:INFO:   machine: Windows-10-10.0.19045-SP0
2023-06-05 00:12:22,491:INFO:PyCaret required dependencies:
2023-06-05 00:12:22,491:INFO:                 pip: 22.3.1
2023-06-05 00:12:22,491:INFO:          setuptools: 65.5.0
2023-06-05 00:12:22,491:INFO:             pycaret: 3.0.0
2023-06-05 00:12:22,491:INFO:             IPython: 8.12.0
2023-06-05 00:12:22,491:INFO:          ipywidgets: 8.0.6
2023-06-05 00:12:22,491:INFO:                tqdm: 4.65.0
2023-06-05 00:12:22,491:INFO:               numpy: 1.24.3
2023-06-05 00:12:22,491:INFO:              pandas: 1.5.3
2023-06-05 00:12:22,491:INFO:              jinja2: 3.1.2
2023-06-05 00:12:22,491:INFO:               scipy: 1.10.1
2023-06-05 00:12:22,491:INFO:              joblib: 1.2.0
2023-06-05 00:12:22,498:INFO:             sklearn: 1.2.2
2023-06-05 00:12:22,498:INFO:                pyod: 1.0.9
2023-06-05 00:12:22,498:INFO:            imblearn: 0.10.1
2023-06-05 00:12:22,498:INFO:   category_encoders: 2.6.0
2023-06-05 00:12:22,498:INFO:            lightgbm: 3.3.5
2023-06-05 00:12:22,498:INFO:               numba: 0.57.0
2023-06-05 00:12:22,498:INFO:            requests: 2.28.2
2023-06-05 00:12:22,499:INFO:          matplotlib: 3.7.1
2023-06-05 00:12:22,499:INFO:          scikitplot: 0.3.7
2023-06-05 00:12:22,499:INFO:         yellowbrick: 1.5
2023-06-05 00:12:22,499:INFO:              plotly: 5.14.1
2023-06-05 00:12:22,499:INFO:             kaleido: 0.2.1
2023-06-05 00:12:22,499:INFO:         statsmodels: 0.14.0
2023-06-05 00:12:22,499:INFO:              sktime: 0.18.0
2023-06-05 00:12:22,499:INFO:               tbats: 1.1.3
2023-06-05 00:12:22,500:INFO:            pmdarima: 2.0.3
2023-06-05 00:12:22,500:INFO:              psutil: 5.9.4
2023-06-05 00:12:22,500:INFO:PyCaret optional dependencies:
2023-06-05 00:12:22,500:INFO:                shap: Not installed
2023-06-05 00:12:22,500:INFO:           interpret: Not installed
2023-06-05 00:12:22,501:INFO:                umap: Not installed
2023-06-05 00:12:22,501:INFO:    pandas_profiling: Not installed
2023-06-05 00:12:22,501:INFO:  explainerdashboard: Not installed
2023-06-05 00:12:22,501:INFO:             autoviz: Not installed
2023-06-05 00:12:22,501:INFO:           fairlearn: Not installed
2023-06-05 00:12:22,501:INFO:             xgboost: Not installed
2023-06-05 00:12:22,501:INFO:            catboost: Not installed
2023-06-05 00:12:22,501:INFO:              kmodes: Not installed
2023-06-05 00:12:22,502:INFO:             mlxtend: Not installed
2023-06-05 00:12:22,502:INFO:       statsforecast: Not installed
2023-06-05 00:12:22,502:INFO:        tune_sklearn: Not installed
2023-06-05 00:12:22,502:INFO:                 ray: Not installed
2023-06-05 00:12:22,502:INFO:            hyperopt: Not installed
2023-06-05 00:12:22,502:INFO:              optuna: Not installed
2023-06-05 00:12:22,502:INFO:               skopt: Not installed
2023-06-05 00:12:22,502:INFO:              mlflow: Not installed
2023-06-05 00:12:22,502:INFO:              gradio: Not installed
2023-06-05 00:12:22,502:INFO:             fastapi: Not installed
2023-06-05 00:12:22,502:INFO:             uvicorn: Not installed
2023-06-05 00:12:22,502:INFO:              m2cgen: Not installed
2023-06-05 00:12:22,502:INFO:           evidently: Not installed
2023-06-05 00:12:22,502:INFO:               fugue: Not installed
2023-06-05 00:12:22,502:INFO:           streamlit: Not installed
2023-06-05 00:12:22,502:INFO:             prophet: 1.1.2
2023-06-05 00:12:22,502:INFO:None
2023-06-05 00:12:22,502:INFO:Set up data.
2023-06-05 00:12:22,558:INFO:Set up train/test split.
2023-06-05 00:12:22,643:INFO:Set up index.
2023-06-05 00:12:22,643:INFO:Set up folding strategy.
2023-06-05 00:12:22,643:INFO:Assigning column types.
2023-06-05 00:12:22,667:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-05 00:12:22,851:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 00:12:22,851:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:12:22,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:22,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:23,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 00:12:23,142:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:12:23,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:23,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:23,265:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-05 00:12:23,434:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:12:23,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:23,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:23,633:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:12:23,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:23,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:23,700:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-05 00:12:23,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:23,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:24,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:24,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:24,049:INFO:Preparing preprocessing pipeline...
2023-06-05 00:12:24,057:INFO:Set up simple imputation.
2023-06-05 00:12:24,083:INFO:Set up encoding of ordinal features.
2023-06-05 00:12:24,091:INFO:Set up encoding of categorical features.
2023-06-05 00:12:24,347:INFO:Finished creating preprocessing pipeline.
2023-06-05 00:12:24,383:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\shiva\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'hypertension',
                                             'heart_disease', 'smoking_history',
                                             'bmi', 'HbA1c_level',
                                             'blood_glucose_level'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['gender'],
                                    transformer=OrdinalEncoder(cols=['gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-06-05 00:12:24,383:INFO:Creating final display dataframe.
2023-06-05 00:12:24,613:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          diabetes
2                   Target type            Binary
3           Original data shape        (76885, 9)
4        Transformed data shape        (76885, 9)
5   Transformed train set shape        (57663, 9)
6    Transformed test set shape        (19222, 9)
7              Ordinal features                 1
8              Numeric features                 7
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              dbec
2023-06-05 00:12:24,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:24,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:25,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:25,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:12:25,004:INFO:setup() successfully completed in 3.36s...............
2023-06-05 00:12:25,004:INFO:Initializing compare_models()
2023-06-05 00:12:25,004:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-06-05 00:12:25,004:INFO:Checking exceptions
2023-06-05 00:12:25,031:INFO:Preparing display monitor
2023-06-05 00:12:25,032:INFO:Initializing Logistic Regression
2023-06-05 00:12:25,032:INFO:Total runtime is 0.0 minutes
2023-06-05 00:12:25,032:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:25,032:INFO:Initializing create_model()
2023-06-05 00:12:25,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:25,032:INFO:Checking exceptions
2023-06-05 00:12:25,040:INFO:Importing libraries
2023-06-05 00:12:25,040:INFO:Copying training dataset
2023-06-05 00:12:25,089:INFO:Defining folds
2023-06-05 00:12:25,089:INFO:Declaring metric variables
2023-06-05 00:12:25,089:INFO:Importing untrained model
2023-06-05 00:12:25,089:INFO:Logistic Regression Imported successfully
2023-06-05 00:12:25,089:INFO:Starting cross validation
2023-06-05 00:12:25,094:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:27,695:INFO:Calculating mean and std
2023-06-05 00:12:27,695:INFO:Creating metrics dataframe
2023-06-05 00:12:28,616:INFO:Uploading results into container
2023-06-05 00:12:28,616:INFO:Uploading model into container now
2023-06-05 00:12:28,622:INFO:_master_model_container: 1
2023-06-05 00:12:28,622:INFO:_display_container: 2
2023-06-05 00:12:28,624:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-05 00:12:28,625:INFO:create_model() successfully completed......................................
2023-06-05 00:12:28,884:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:28,884:INFO:Creating metrics dataframe
2023-06-05 00:12:28,892:INFO:Initializing K Neighbors Classifier
2023-06-05 00:12:28,892:INFO:Total runtime is 0.06434292395909627 minutes
2023-06-05 00:12:28,892:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:28,892:INFO:Initializing create_model()
2023-06-05 00:12:28,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:28,893:INFO:Checking exceptions
2023-06-05 00:12:28,893:INFO:Importing libraries
2023-06-05 00:12:28,893:INFO:Copying training dataset
2023-06-05 00:12:28,922:INFO:Defining folds
2023-06-05 00:12:28,922:INFO:Declaring metric variables
2023-06-05 00:12:28,922:INFO:Importing untrained model
2023-06-05 00:12:28,923:INFO:K Neighbors Classifier Imported successfully
2023-06-05 00:12:28,923:INFO:Starting cross validation
2023-06-05 00:12:28,924:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:30,896:INFO:Calculating mean and std
2023-06-05 00:12:30,897:INFO:Creating metrics dataframe
2023-06-05 00:12:31,199:INFO:Uploading results into container
2023-06-05 00:12:31,199:INFO:Uploading model into container now
2023-06-05 00:12:31,200:INFO:_master_model_container: 2
2023-06-05 00:12:31,200:INFO:_display_container: 2
2023-06-05 00:12:31,200:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-05 00:12:31,200:INFO:create_model() successfully completed......................................
2023-06-05 00:12:31,334:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:31,334:INFO:Creating metrics dataframe
2023-06-05 00:12:31,344:INFO:Initializing Naive Bayes
2023-06-05 00:12:31,344:INFO:Total runtime is 0.10520333846410115 minutes
2023-06-05 00:12:31,345:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:31,345:INFO:Initializing create_model()
2023-06-05 00:12:31,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:31,345:INFO:Checking exceptions
2023-06-05 00:12:31,345:INFO:Importing libraries
2023-06-05 00:12:31,346:INFO:Copying training dataset
2023-06-05 00:12:31,372:INFO:Defining folds
2023-06-05 00:12:31,372:INFO:Declaring metric variables
2023-06-05 00:12:31,375:INFO:Importing untrained model
2023-06-05 00:12:31,375:INFO:Naive Bayes Imported successfully
2023-06-05 00:12:31,375:INFO:Starting cross validation
2023-06-05 00:12:31,376:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:32,395:INFO:Calculating mean and std
2023-06-05 00:12:32,401:INFO:Creating metrics dataframe
2023-06-05 00:12:32,683:INFO:Uploading results into container
2023-06-05 00:12:32,684:INFO:Uploading model into container now
2023-06-05 00:12:32,685:INFO:_master_model_container: 3
2023-06-05 00:12:32,685:INFO:_display_container: 2
2023-06-05 00:12:32,685:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-05 00:12:32,685:INFO:create_model() successfully completed......................................
2023-06-05 00:12:32,818:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:32,818:INFO:Creating metrics dataframe
2023-06-05 00:12:32,828:INFO:Initializing Decision Tree Classifier
2023-06-05 00:12:32,828:INFO:Total runtime is 0.12994030714035035 minutes
2023-06-05 00:12:32,829:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:32,829:INFO:Initializing create_model()
2023-06-05 00:12:32,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:32,830:INFO:Checking exceptions
2023-06-05 00:12:32,831:INFO:Importing libraries
2023-06-05 00:12:32,831:INFO:Copying training dataset
2023-06-05 00:12:32,856:INFO:Defining folds
2023-06-05 00:12:32,857:INFO:Declaring metric variables
2023-06-05 00:12:32,857:INFO:Importing untrained model
2023-06-05 00:12:32,857:INFO:Decision Tree Classifier Imported successfully
2023-06-05 00:12:32,858:INFO:Starting cross validation
2023-06-05 00:12:32,859:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:33,825:INFO:Calculating mean and std
2023-06-05 00:12:33,829:INFO:Creating metrics dataframe
2023-06-05 00:12:34,104:INFO:Uploading results into container
2023-06-05 00:12:34,106:INFO:Uploading model into container now
2023-06-05 00:12:34,106:INFO:_master_model_container: 4
2023-06-05 00:12:34,107:INFO:_display_container: 2
2023-06-05 00:12:34,107:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-05 00:12:34,107:INFO:create_model() successfully completed......................................
2023-06-05 00:12:34,239:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:34,239:INFO:Creating metrics dataframe
2023-06-05 00:12:34,247:INFO:Initializing SVM - Linear Kernel
2023-06-05 00:12:34,247:INFO:Total runtime is 0.15359208583831788 minutes
2023-06-05 00:12:34,248:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:34,249:INFO:Initializing create_model()
2023-06-05 00:12:34,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:34,249:INFO:Checking exceptions
2023-06-05 00:12:34,249:INFO:Importing libraries
2023-06-05 00:12:34,249:INFO:Copying training dataset
2023-06-05 00:12:34,277:INFO:Defining folds
2023-06-05 00:12:34,277:INFO:Declaring metric variables
2023-06-05 00:12:34,277:INFO:Importing untrained model
2023-06-05 00:12:34,279:INFO:SVM - Linear Kernel Imported successfully
2023-06-05 00:12:34,279:INFO:Starting cross validation
2023-06-05 00:12:34,281:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:34,456:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:12:34,488:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:12:34,495:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:12:34,528:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:12:35,222:INFO:Calculating mean and std
2023-06-05 00:12:35,223:INFO:Creating metrics dataframe
2023-06-05 00:12:35,509:INFO:Uploading results into container
2023-06-05 00:12:35,510:INFO:Uploading model into container now
2023-06-05 00:12:35,510:INFO:_master_model_container: 5
2023-06-05 00:12:35,511:INFO:_display_container: 2
2023-06-05 00:12:35,511:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-05 00:12:35,511:INFO:create_model() successfully completed......................................
2023-06-05 00:12:35,653:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:35,653:INFO:Creating metrics dataframe
2023-06-05 00:12:35,664:INFO:Initializing Ridge Classifier
2023-06-05 00:12:35,664:INFO:Total runtime is 0.17720056772232057 minutes
2023-06-05 00:12:35,664:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:35,665:INFO:Initializing create_model()
2023-06-05 00:12:35,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:35,665:INFO:Checking exceptions
2023-06-05 00:12:35,665:INFO:Importing libraries
2023-06-05 00:12:35,665:INFO:Copying training dataset
2023-06-05 00:12:35,692:INFO:Defining folds
2023-06-05 00:12:35,693:INFO:Declaring metric variables
2023-06-05 00:12:35,693:INFO:Importing untrained model
2023-06-05 00:12:35,694:INFO:Ridge Classifier Imported successfully
2023-06-05 00:12:35,694:INFO:Starting cross validation
2023-06-05 00:12:35,698:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:35,930:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:12:35,949:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:12:36,016:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:12:36,038:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:12:36,873:INFO:Calculating mean and std
2023-06-05 00:12:36,873:INFO:Creating metrics dataframe
2023-06-05 00:12:37,204:INFO:Uploading results into container
2023-06-05 00:12:37,205:INFO:Uploading model into container now
2023-06-05 00:12:37,205:INFO:_master_model_container: 6
2023-06-05 00:12:37,205:INFO:_display_container: 2
2023-06-05 00:12:37,206:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-05 00:12:37,206:INFO:create_model() successfully completed......................................
2023-06-05 00:12:37,341:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:37,342:INFO:Creating metrics dataframe
2023-06-05 00:12:37,352:INFO:Initializing Random Forest Classifier
2023-06-05 00:12:37,353:INFO:Total runtime is 0.20535322427749636 minutes
2023-06-05 00:12:37,353:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:37,353:INFO:Initializing create_model()
2023-06-05 00:12:37,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:37,354:INFO:Checking exceptions
2023-06-05 00:12:37,354:INFO:Importing libraries
2023-06-05 00:12:37,354:INFO:Copying training dataset
2023-06-05 00:12:37,384:INFO:Defining folds
2023-06-05 00:12:37,384:INFO:Declaring metric variables
2023-06-05 00:12:37,385:INFO:Importing untrained model
2023-06-05 00:12:37,385:INFO:Random Forest Classifier Imported successfully
2023-06-05 00:12:37,386:INFO:Starting cross validation
2023-06-05 00:12:37,387:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:39,096:INFO:Calculating mean and std
2023-06-05 00:12:39,098:INFO:Creating metrics dataframe
2023-06-05 00:12:39,752:INFO:Uploading results into container
2023-06-05 00:12:39,758:INFO:Uploading model into container now
2023-06-05 00:12:39,759:INFO:_master_model_container: 7
2023-06-05 00:12:39,759:INFO:_display_container: 2
2023-06-05 00:12:39,760:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-05 00:12:39,761:INFO:create_model() successfully completed......................................
2023-06-05 00:12:39,901:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:39,901:INFO:Creating metrics dataframe
2023-06-05 00:12:39,916:INFO:Initializing Quadratic Discriminant Analysis
2023-06-05 00:12:39,916:INFO:Total runtime is 0.2480652451515198 minutes
2023-06-05 00:12:39,916:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:39,917:INFO:Initializing create_model()
2023-06-05 00:12:39,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:39,917:INFO:Checking exceptions
2023-06-05 00:12:39,917:INFO:Importing libraries
2023-06-05 00:12:39,917:INFO:Copying training dataset
2023-06-05 00:12:39,943:INFO:Defining folds
2023-06-05 00:12:39,949:INFO:Declaring metric variables
2023-06-05 00:12:39,949:INFO:Importing untrained model
2023-06-05 00:12:39,950:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-05 00:12:39,950:INFO:Starting cross validation
2023-06-05 00:12:39,952:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:41,080:INFO:Calculating mean and std
2023-06-05 00:12:41,080:INFO:Creating metrics dataframe
2023-06-05 00:12:41,383:INFO:Uploading results into container
2023-06-05 00:12:41,384:INFO:Uploading model into container now
2023-06-05 00:12:41,384:INFO:_master_model_container: 8
2023-06-05 00:12:41,385:INFO:_display_container: 2
2023-06-05 00:12:41,385:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-05 00:12:41,385:INFO:create_model() successfully completed......................................
2023-06-05 00:12:41,513:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:41,513:INFO:Creating metrics dataframe
2023-06-05 00:12:41,525:INFO:Initializing Ada Boost Classifier
2023-06-05 00:12:41,525:INFO:Total runtime is 0.2748896916707357 minutes
2023-06-05 00:12:41,526:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:41,526:INFO:Initializing create_model()
2023-06-05 00:12:41,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:41,527:INFO:Checking exceptions
2023-06-05 00:12:41,528:INFO:Importing libraries
2023-06-05 00:12:41,528:INFO:Copying training dataset
2023-06-05 00:12:41,561:INFO:Defining folds
2023-06-05 00:12:41,561:INFO:Declaring metric variables
2023-06-05 00:12:41,561:INFO:Importing untrained model
2023-06-05 00:12:41,561:INFO:Ada Boost Classifier Imported successfully
2023-06-05 00:12:41,562:INFO:Starting cross validation
2023-06-05 00:12:41,563:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:42,822:INFO:Calculating mean and std
2023-06-05 00:12:42,829:INFO:Creating metrics dataframe
2023-06-05 00:12:43,115:INFO:Uploading results into container
2023-06-05 00:12:43,116:INFO:Uploading model into container now
2023-06-05 00:12:43,116:INFO:_master_model_container: 9
2023-06-05 00:12:43,116:INFO:_display_container: 2
2023-06-05 00:12:43,117:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-05 00:12:43,117:INFO:create_model() successfully completed......................................
2023-06-05 00:12:43,250:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:43,251:INFO:Creating metrics dataframe
2023-06-05 00:12:43,261:INFO:Initializing Gradient Boosting Classifier
2023-06-05 00:12:43,262:INFO:Total runtime is 0.30383429924647015 minutes
2023-06-05 00:12:43,262:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:43,262:INFO:Initializing create_model()
2023-06-05 00:12:43,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:43,263:INFO:Checking exceptions
2023-06-05 00:12:43,264:INFO:Importing libraries
2023-06-05 00:12:43,264:INFO:Copying training dataset
2023-06-05 00:12:43,297:INFO:Defining folds
2023-06-05 00:12:43,297:INFO:Declaring metric variables
2023-06-05 00:12:43,298:INFO:Importing untrained model
2023-06-05 00:12:43,299:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:12:43,299:INFO:Starting cross validation
2023-06-05 00:12:43,301:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:44,353:INFO:Calculating mean and std
2023-06-05 00:12:44,358:INFO:Creating metrics dataframe
2023-06-05 00:12:44,624:INFO:Uploading results into container
2023-06-05 00:12:44,625:INFO:Uploading model into container now
2023-06-05 00:12:44,625:INFO:_master_model_container: 10
2023-06-05 00:12:44,625:INFO:_display_container: 2
2023-06-05 00:12:44,626:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:12:44,626:INFO:create_model() successfully completed......................................
2023-06-05 00:12:44,756:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:44,756:INFO:Creating metrics dataframe
2023-06-05 00:12:44,767:INFO:Initializing Linear Discriminant Analysis
2023-06-05 00:12:44,767:INFO:Total runtime is 0.3289177656173706 minutes
2023-06-05 00:12:44,767:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:44,768:INFO:Initializing create_model()
2023-06-05 00:12:44,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:44,768:INFO:Checking exceptions
2023-06-05 00:12:44,768:INFO:Importing libraries
2023-06-05 00:12:44,768:INFO:Copying training dataset
2023-06-05 00:12:44,798:INFO:Defining folds
2023-06-05 00:12:44,798:INFO:Declaring metric variables
2023-06-05 00:12:44,799:INFO:Importing untrained model
2023-06-05 00:12:44,799:INFO:Linear Discriminant Analysis Imported successfully
2023-06-05 00:12:44,800:INFO:Starting cross validation
2023-06-05 00:12:44,802:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:45,709:INFO:Calculating mean and std
2023-06-05 00:12:45,713:INFO:Creating metrics dataframe
2023-06-05 00:12:45,986:INFO:Uploading results into container
2023-06-05 00:12:45,987:INFO:Uploading model into container now
2023-06-05 00:12:45,988:INFO:_master_model_container: 11
2023-06-05 00:12:45,988:INFO:_display_container: 2
2023-06-05 00:12:45,988:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-05 00:12:45,988:INFO:create_model() successfully completed......................................
2023-06-05 00:12:46,122:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:46,122:INFO:Creating metrics dataframe
2023-06-05 00:12:46,129:INFO:Initializing Extra Trees Classifier
2023-06-05 00:12:46,131:INFO:Total runtime is 0.3516430695851644 minutes
2023-06-05 00:12:46,131:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:46,131:INFO:Initializing create_model()
2023-06-05 00:12:46,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:46,131:INFO:Checking exceptions
2023-06-05 00:12:46,132:INFO:Importing libraries
2023-06-05 00:12:46,132:INFO:Copying training dataset
2023-06-05 00:12:46,159:INFO:Defining folds
2023-06-05 00:12:46,159:INFO:Declaring metric variables
2023-06-05 00:12:46,159:INFO:Importing untrained model
2023-06-05 00:12:46,160:INFO:Extra Trees Classifier Imported successfully
2023-06-05 00:12:46,160:INFO:Starting cross validation
2023-06-05 00:12:46,162:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:48,247:INFO:Calculating mean and std
2023-06-05 00:12:48,254:INFO:Creating metrics dataframe
2023-06-05 00:12:48,898:INFO:Uploading results into container
2023-06-05 00:12:48,903:INFO:Uploading model into container now
2023-06-05 00:12:48,903:INFO:_master_model_container: 12
2023-06-05 00:12:48,904:INFO:_display_container: 2
2023-06-05 00:12:48,904:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-05 00:12:48,905:INFO:create_model() successfully completed......................................
2023-06-05 00:12:49,049:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:49,049:INFO:Creating metrics dataframe
2023-06-05 00:12:49,063:INFO:Initializing Light Gradient Boosting Machine
2023-06-05 00:12:49,063:INFO:Total runtime is 0.4005180319150289 minutes
2023-06-05 00:12:49,064:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:49,064:INFO:Initializing create_model()
2023-06-05 00:12:49,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:49,065:INFO:Checking exceptions
2023-06-05 00:12:49,065:INFO:Importing libraries
2023-06-05 00:12:49,065:INFO:Copying training dataset
2023-06-05 00:12:49,096:INFO:Defining folds
2023-06-05 00:12:49,096:INFO:Declaring metric variables
2023-06-05 00:12:49,096:INFO:Importing untrained model
2023-06-05 00:12:49,097:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-05 00:12:49,098:INFO:Starting cross validation
2023-06-05 00:12:49,099:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:50,369:INFO:Calculating mean and std
2023-06-05 00:12:50,372:INFO:Creating metrics dataframe
2023-06-05 00:12:50,637:INFO:Uploading results into container
2023-06-05 00:12:50,638:INFO:Uploading model into container now
2023-06-05 00:12:50,639:INFO:_master_model_container: 13
2023-06-05 00:12:50,639:INFO:_display_container: 2
2023-06-05 00:12:50,639:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-05 00:12:50,639:INFO:create_model() successfully completed......................................
2023-06-05 00:12:50,770:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:50,771:INFO:Creating metrics dataframe
2023-06-05 00:12:50,781:INFO:Initializing Dummy Classifier
2023-06-05 00:12:50,781:INFO:Total runtime is 0.4291465123494466 minutes
2023-06-05 00:12:50,782:INFO:SubProcess create_model() called ==================================
2023-06-05 00:12:50,782:INFO:Initializing create_model()
2023-06-05 00:12:50,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024748AD70D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:50,782:INFO:Checking exceptions
2023-06-05 00:12:50,782:INFO:Importing libraries
2023-06-05 00:12:50,783:INFO:Copying training dataset
2023-06-05 00:12:50,806:INFO:Defining folds
2023-06-05 00:12:50,807:INFO:Declaring metric variables
2023-06-05 00:12:50,807:INFO:Importing untrained model
2023-06-05 00:12:50,807:INFO:Dummy Classifier Imported successfully
2023-06-05 00:12:50,808:INFO:Starting cross validation
2023-06-05 00:12:50,817:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:12:51,002:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:12:51,048:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:12:51,085:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:12:51,103:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:12:51,758:INFO:Calculating mean and std
2023-06-05 00:12:51,759:INFO:Creating metrics dataframe
2023-06-05 00:12:52,019:INFO:Uploading results into container
2023-06-05 00:12:52,019:INFO:Uploading model into container now
2023-06-05 00:12:52,020:INFO:_master_model_container: 14
2023-06-05 00:12:52,020:INFO:_display_container: 2
2023-06-05 00:12:52,020:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-05 00:12:52,020:INFO:create_model() successfully completed......................................
2023-06-05 00:12:52,150:INFO:SubProcess create_model() end ==================================
2023-06-05 00:12:52,150:INFO:Creating metrics dataframe
2023-06-05 00:12:52,165:INFO:Initializing create_model()
2023-06-05 00:12:52,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:12:52,166:INFO:Checking exceptions
2023-06-05 00:12:52,168:INFO:Importing libraries
2023-06-05 00:12:52,168:INFO:Copying training dataset
2023-06-05 00:12:52,203:INFO:Defining folds
2023-06-05 00:12:52,203:INFO:Declaring metric variables
2023-06-05 00:12:52,203:INFO:Importing untrained model
2023-06-05 00:12:52,203:INFO:Declaring custom model
2023-06-05 00:12:52,204:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:12:52,206:INFO:Cross validation set to False
2023-06-05 00:12:52,206:INFO:Fitting Model
2023-06-05 00:12:52,582:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:12:52,582:INFO:create_model() successfully completed......................................
2023-06-05 00:12:52,748:INFO:_master_model_container: 14
2023-06-05 00:12:52,748:INFO:_display_container: 2
2023-06-05 00:12:52,749:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:12:52,749:INFO:compare_models() successfully completed......................................
2023-06-05 00:12:52,750:INFO:Initializing evaluate_model()
2023-06-05 00:12:52,751:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-05 00:12:52,767:INFO:Initializing plot_model()
2023-06-05 00:12:52,767:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, use_train_data=False, verbose=False, system=True, display=None, display_format=None)
2023-06-05 00:12:52,767:INFO:Checking exceptions
2023-06-05 00:12:52,780:INFO:Preloading libraries
2023-06-05 00:12:52,790:INFO:Copying training dataset
2023-06-05 00:12:52,790:INFO:Plot type: pipeline
2023-06-05 00:12:52,794:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:572: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  fig, ax = plt.subplots(

2023-06-05 00:12:52,978:INFO:Initializing tune_model()
2023-06-05 00:12:52,978:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2023-06-05 00:12:52,978:INFO:Checking exceptions
2023-06-05 00:12:52,993:INFO:Copying training dataset
2023-06-05 00:12:53,017:INFO:Checking base model
2023-06-05 00:12:53,017:INFO:Base model : Gradient Boosting Classifier
2023-06-05 00:12:53,022:INFO:Declaring metric variables
2023-06-05 00:12:53,024:INFO:Defining Hyperparameters
2023-06-05 00:12:53,157:INFO:Tuning with n_jobs=-1
2023-06-05 00:12:53,157:INFO:Initializing RandomizedSearchCV
2023-06-05 00:13:41,042:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-06-05 00:13:41,044:INFO:Hyperparameter search completed
2023-06-05 00:13:41,044:INFO:SubProcess create_model() called ==================================
2023-06-05 00:13:41,045:INFO:Initializing create_model()
2023-06-05 00:13:41,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024749AD78D0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-06-05 00:13:41,045:INFO:Checking exceptions
2023-06-05 00:13:41,045:INFO:Importing libraries
2023-06-05 00:13:41,046:INFO:Copying training dataset
2023-06-05 00:13:41,076:INFO:Defining folds
2023-06-05 00:13:41,076:INFO:Declaring metric variables
2023-06-05 00:13:41,076:INFO:Importing untrained model
2023-06-05 00:13:41,076:INFO:Declaring custom model
2023-06-05 00:13:41,076:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:13:41,076:INFO:Starting cross validation
2023-06-05 00:13:41,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:13:47,280:INFO:Calculating mean and std
2023-06-05 00:13:47,281:INFO:Creating metrics dataframe
2023-06-05 00:13:47,283:INFO:Finalizing model
2023-06-05 00:13:48,164:INFO:Uploading results into container
2023-06-05 00:13:48,165:INFO:Uploading model into container now
2023-06-05 00:13:48,166:INFO:_master_model_container: 15
2023-06-05 00:13:48,166:INFO:_display_container: 3
2023-06-05 00:13:48,167:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:13:48,167:INFO:create_model() successfully completed......................................
2023-06-05 00:13:48,344:INFO:SubProcess create_model() end ==================================
2023-06-05 00:13:48,344:INFO:choose_better activated
2023-06-05 00:13:48,345:INFO:SubProcess create_model() called ==================================
2023-06-05 00:13:48,346:INFO:Initializing create_model()
2023-06-05 00:13:48,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024747B63F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:13:48,347:INFO:Checking exceptions
2023-06-05 00:13:48,348:INFO:Importing libraries
2023-06-05 00:13:48,348:INFO:Copying training dataset
2023-06-05 00:13:48,382:INFO:Defining folds
2023-06-05 00:13:48,382:INFO:Declaring metric variables
2023-06-05 00:13:48,382:INFO:Importing untrained model
2023-06-05 00:13:48,383:INFO:Declaring custom model
2023-06-05 00:13:48,384:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:13:48,385:INFO:Starting cross validation
2023-06-05 00:13:48,386:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:13:52,638:INFO:Calculating mean and std
2023-06-05 00:13:52,642:INFO:Creating metrics dataframe
2023-06-05 00:13:52,645:INFO:Finalizing model
2023-06-05 00:13:53,537:INFO:Uploading results into container
2023-06-05 00:13:53,537:INFO:Uploading model into container now
2023-06-05 00:13:53,545:INFO:_master_model_container: 16
2023-06-05 00:13:53,545:INFO:_display_container: 4
2023-06-05 00:13:53,545:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:13:53,545:INFO:create_model() successfully completed......................................
2023-06-05 00:13:53,668:INFO:SubProcess create_model() end ==================================
2023-06-05 00:13:53,669:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-05 00:13:53,670:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-05 00:13:53,670:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-06-05 00:13:53,670:INFO:choose_better completed
2023-06-05 00:13:53,672:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-05 00:13:53,696:INFO:_master_model_container: 16
2023-06-05 00:13:53,697:INFO:_display_container: 3
2023-06-05 00:13:53,697:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:13:53,698:INFO:tune_model() successfully completed......................................
2023-06-05 00:14:55,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:14:55,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:14:55,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:14:55,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:14:56,939:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:15:06,759:INFO:PyCaret ClassificationExperiment
2023-06-05 00:15:06,759:INFO:Logging name: clf-default-name
2023-06-05 00:15:06,759:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-05 00:15:06,759:INFO:version 3.0.0
2023-06-05 00:15:06,759:INFO:Initializing setup()
2023-06-05 00:15:06,759:INFO:self.USI: d855
2023-06-05 00:15:06,759:INFO:self._variable_keys: {'X_train', 'memory', 'pipeline', 'y', 'fix_imbalance', 'n_jobs_param', 'fold_shuffle_param', 'USI', 'X', 'data', 'is_multiclass', 'X_test', 'gpu_n_jobs_param', '_ml_usecase', 'idx', 'html_param', 'seed', 'log_plots_param', '_available_plots', 'fold_generator', 'y_test', 'gpu_param', 'fold_groups_param', 'target_param', 'y_train', 'exp_id', 'logging_param', 'exp_name_log'}
2023-06-05 00:15:06,759:INFO:Checking environment
2023-06-05 00:15:06,760:INFO:python_version: 3.11.3
2023-06-05 00:15:06,760:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2023-06-05 00:15:06,760:INFO:machine: AMD64
2023-06-05 00:15:06,782:INFO:platform: Windows-10-10.0.19045-SP0
2023-06-05 00:15:06,783:INFO:Memory: svmem(total=8384401408, available=2435526656, percent=71.0, used=5948874752, free=2435526656)
2023-06-05 00:15:06,783:INFO:Physical Core: 4
2023-06-05 00:15:06,783:INFO:Logical Core: 8
2023-06-05 00:15:06,786:INFO:Checking libraries
2023-06-05 00:15:06,786:INFO:System:
2023-06-05 00:15:06,786:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2023-06-05 00:15:06,786:INFO:executable: C:\Program Files\Python311\python.exe
2023-06-05 00:15:06,786:INFO:   machine: Windows-10-10.0.19045-SP0
2023-06-05 00:15:06,786:INFO:PyCaret required dependencies:
2023-06-05 00:15:06,786:INFO:                 pip: 22.3.1
2023-06-05 00:15:06,786:INFO:          setuptools: 65.5.0
2023-06-05 00:15:06,786:INFO:             pycaret: 3.0.0
2023-06-05 00:15:06,787:INFO:             IPython: 8.12.0
2023-06-05 00:15:06,787:INFO:          ipywidgets: 8.0.6
2023-06-05 00:15:06,787:INFO:                tqdm: 4.65.0
2023-06-05 00:15:06,787:INFO:               numpy: 1.24.3
2023-06-05 00:15:06,787:INFO:              pandas: 1.5.3
2023-06-05 00:15:06,787:INFO:              jinja2: 3.1.2
2023-06-05 00:15:06,787:INFO:               scipy: 1.10.1
2023-06-05 00:15:06,787:INFO:              joblib: 1.2.0
2023-06-05 00:15:06,787:INFO:             sklearn: 1.2.2
2023-06-05 00:15:06,787:INFO:                pyod: 1.0.9
2023-06-05 00:15:06,787:INFO:            imblearn: 0.10.1
2023-06-05 00:15:06,787:INFO:   category_encoders: 2.6.0
2023-06-05 00:15:06,788:INFO:            lightgbm: 3.3.5
2023-06-05 00:15:06,788:INFO:               numba: 0.57.0
2023-06-05 00:15:06,788:INFO:            requests: 2.28.2
2023-06-05 00:15:06,788:INFO:          matplotlib: 3.7.1
2023-06-05 00:15:06,788:INFO:          scikitplot: 0.3.7
2023-06-05 00:15:06,788:INFO:         yellowbrick: 1.5
2023-06-05 00:15:06,788:INFO:              plotly: 5.14.1
2023-06-05 00:15:06,788:INFO:             kaleido: 0.2.1
2023-06-05 00:15:06,788:INFO:         statsmodels: 0.14.0
2023-06-05 00:15:06,788:INFO:              sktime: 0.18.0
2023-06-05 00:15:06,789:INFO:               tbats: 1.1.3
2023-06-05 00:15:06,789:INFO:            pmdarima: 2.0.3
2023-06-05 00:15:06,789:INFO:              psutil: 5.9.4
2023-06-05 00:15:06,789:INFO:PyCaret optional dependencies:
2023-06-05 00:15:06,823:INFO:                shap: Not installed
2023-06-05 00:15:06,823:INFO:           interpret: Not installed
2023-06-05 00:15:06,823:INFO:                umap: Not installed
2023-06-05 00:15:06,823:INFO:    pandas_profiling: Not installed
2023-06-05 00:15:06,823:INFO:  explainerdashboard: Not installed
2023-06-05 00:15:06,823:INFO:             autoviz: Not installed
2023-06-05 00:15:06,824:INFO:           fairlearn: Not installed
2023-06-05 00:15:06,824:INFO:             xgboost: Not installed
2023-06-05 00:15:06,824:INFO:            catboost: Not installed
2023-06-05 00:15:06,824:INFO:              kmodes: Not installed
2023-06-05 00:15:06,825:INFO:             mlxtend: Not installed
2023-06-05 00:15:06,825:INFO:       statsforecast: Not installed
2023-06-05 00:15:06,825:INFO:        tune_sklearn: Not installed
2023-06-05 00:15:06,825:INFO:                 ray: Not installed
2023-06-05 00:15:06,825:INFO:            hyperopt: Not installed
2023-06-05 00:15:06,825:INFO:              optuna: Not installed
2023-06-05 00:15:06,825:INFO:               skopt: Not installed
2023-06-05 00:15:06,825:INFO:              mlflow: Not installed
2023-06-05 00:15:06,825:INFO:              gradio: Not installed
2023-06-05 00:15:06,825:INFO:             fastapi: Not installed
2023-06-05 00:15:06,825:INFO:             uvicorn: Not installed
2023-06-05 00:15:06,826:INFO:              m2cgen: Not installed
2023-06-05 00:15:06,826:INFO:           evidently: Not installed
2023-06-05 00:15:06,826:INFO:               fugue: Not installed
2023-06-05 00:15:06,826:INFO:           streamlit: Not installed
2023-06-05 00:15:06,826:INFO:             prophet: 1.1.2
2023-06-05 00:15:06,826:INFO:None
2023-06-05 00:15:06,826:INFO:Set up data.
2023-06-05 00:15:06,866:INFO:Set up train/test split.
2023-06-05 00:15:06,917:INFO:Set up index.
2023-06-05 00:15:06,918:INFO:Set up folding strategy.
2023-06-05 00:15:06,918:INFO:Assigning column types.
2023-06-05 00:15:06,930:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-05 00:15:06,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 00:15:06,994:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:15:07,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,166:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 00:15:07,167:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:15:07,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,208:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-05 00:15:07,271:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:15:07,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,389:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:15:07,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,440:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-05 00:15:07,550:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:07,640:INFO:Preparing preprocessing pipeline...
2023-06-05 00:15:07,644:INFO:Set up simple imputation.
2023-06-05 00:15:07,679:INFO:Set up encoding of ordinal features.
2023-06-05 00:15:07,684:INFO:Set up encoding of categorical features.
2023-06-05 00:15:08,585:INFO:Finished creating preprocessing pipeline.
2023-06-05 00:15:08,615:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\shiva\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'hypertension',
                                             'heart_disease', 'smoking_history',
                                             'bmi', 'HbA1c_level',
                                             'blood_glucose_level'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['gender'],
                                    transformer=OrdinalEncoder(cols=['gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-06-05 00:15:08,615:INFO:Creating final display dataframe.
2023-06-05 00:15:08,751:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          diabetes
2                   Target type            Binary
3           Original data shape        (76885, 9)
4        Transformed data shape        (76885, 9)
5   Transformed train set shape        (57663, 9)
6    Transformed test set shape        (19222, 9)
7              Ordinal features                 1
8              Numeric features                 7
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              d855
2023-06-05 00:15:08,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:08,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:08,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:08,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:08,946:INFO:setup() successfully completed in 2.56s...............
2023-06-05 00:15:09,513:INFO:PyCaret ClassificationExperiment
2023-06-05 00:15:09,513:INFO:Logging name: clf-default-name
2023-06-05 00:15:09,513:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-05 00:15:09,513:INFO:version 3.0.0
2023-06-05 00:15:09,513:INFO:Initializing setup()
2023-06-05 00:15:09,513:INFO:self.USI: 4f00
2023-06-05 00:15:09,513:INFO:self._variable_keys: {'X_train', 'memory', 'pipeline', 'y', 'fix_imbalance', 'n_jobs_param', 'fold_shuffle_param', 'USI', 'X', 'data', 'is_multiclass', 'X_test', 'gpu_n_jobs_param', '_ml_usecase', 'idx', 'html_param', 'seed', 'log_plots_param', '_available_plots', 'fold_generator', 'y_test', 'gpu_param', 'fold_groups_param', 'target_param', 'y_train', 'exp_id', 'logging_param', 'exp_name_log'}
2023-06-05 00:15:09,513:INFO:Checking environment
2023-06-05 00:15:09,514:INFO:python_version: 3.11.3
2023-06-05 00:15:09,514:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2023-06-05 00:15:09,514:INFO:machine: AMD64
2023-06-05 00:15:09,514:INFO:platform: Windows-10-10.0.19045-SP0
2023-06-05 00:15:09,517:INFO:Memory: svmem(total=8384401408, available=2377478144, percent=71.6, used=6006923264, free=2377478144)
2023-06-05 00:15:09,517:INFO:Physical Core: 4
2023-06-05 00:15:09,517:INFO:Logical Core: 8
2023-06-05 00:15:09,518:INFO:Checking libraries
2023-06-05 00:15:09,518:INFO:System:
2023-06-05 00:15:09,518:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2023-06-05 00:15:09,518:INFO:executable: C:\Program Files\Python311\python.exe
2023-06-05 00:15:09,518:INFO:   machine: Windows-10-10.0.19045-SP0
2023-06-05 00:15:09,518:INFO:PyCaret required dependencies:
2023-06-05 00:15:09,518:INFO:                 pip: 22.3.1
2023-06-05 00:15:09,518:INFO:          setuptools: 65.5.0
2023-06-05 00:15:09,518:INFO:             pycaret: 3.0.0
2023-06-05 00:15:09,518:INFO:             IPython: 8.12.0
2023-06-05 00:15:09,519:INFO:          ipywidgets: 8.0.6
2023-06-05 00:15:09,519:INFO:                tqdm: 4.65.0
2023-06-05 00:15:09,519:INFO:               numpy: 1.24.3
2023-06-05 00:15:09,519:INFO:              pandas: 1.5.3
2023-06-05 00:15:09,519:INFO:              jinja2: 3.1.2
2023-06-05 00:15:09,519:INFO:               scipy: 1.10.1
2023-06-05 00:15:09,519:INFO:              joblib: 1.2.0
2023-06-05 00:15:09,519:INFO:             sklearn: 1.2.2
2023-06-05 00:15:09,519:INFO:                pyod: 1.0.9
2023-06-05 00:15:09,520:INFO:            imblearn: 0.10.1
2023-06-05 00:15:09,520:INFO:   category_encoders: 2.6.0
2023-06-05 00:15:09,520:INFO:            lightgbm: 3.3.5
2023-06-05 00:15:09,520:INFO:               numba: 0.57.0
2023-06-05 00:15:09,520:INFO:            requests: 2.28.2
2023-06-05 00:15:09,520:INFO:          matplotlib: 3.7.1
2023-06-05 00:15:09,520:INFO:          scikitplot: 0.3.7
2023-06-05 00:15:09,520:INFO:         yellowbrick: 1.5
2023-06-05 00:15:09,520:INFO:              plotly: 5.14.1
2023-06-05 00:15:09,521:INFO:             kaleido: 0.2.1
2023-06-05 00:15:09,521:INFO:         statsmodels: 0.14.0
2023-06-05 00:15:09,521:INFO:              sktime: 0.18.0
2023-06-05 00:15:09,521:INFO:               tbats: 1.1.3
2023-06-05 00:15:09,521:INFO:            pmdarima: 2.0.3
2023-06-05 00:15:09,521:INFO:              psutil: 5.9.4
2023-06-05 00:15:09,521:INFO:PyCaret optional dependencies:
2023-06-05 00:15:09,521:INFO:                shap: Not installed
2023-06-05 00:15:09,521:INFO:           interpret: Not installed
2023-06-05 00:15:09,522:INFO:                umap: Not installed
2023-06-05 00:15:09,522:INFO:    pandas_profiling: Not installed
2023-06-05 00:15:09,522:INFO:  explainerdashboard: Not installed
2023-06-05 00:15:09,522:INFO:             autoviz: Not installed
2023-06-05 00:15:09,522:INFO:           fairlearn: Not installed
2023-06-05 00:15:09,522:INFO:             xgboost: Not installed
2023-06-05 00:15:09,522:INFO:            catboost: Not installed
2023-06-05 00:15:09,522:INFO:              kmodes: Not installed
2023-06-05 00:15:09,522:INFO:             mlxtend: Not installed
2023-06-05 00:15:09,522:INFO:       statsforecast: Not installed
2023-06-05 00:15:09,522:INFO:        tune_sklearn: Not installed
2023-06-05 00:15:09,522:INFO:                 ray: Not installed
2023-06-05 00:15:09,522:INFO:            hyperopt: Not installed
2023-06-05 00:15:09,522:INFO:              optuna: Not installed
2023-06-05 00:15:09,523:INFO:               skopt: Not installed
2023-06-05 00:15:09,523:INFO:              mlflow: Not installed
2023-06-05 00:15:09,523:INFO:              gradio: Not installed
2023-06-05 00:15:09,523:INFO:             fastapi: Not installed
2023-06-05 00:15:09,523:INFO:             uvicorn: Not installed
2023-06-05 00:15:09,523:INFO:              m2cgen: Not installed
2023-06-05 00:15:09,523:INFO:           evidently: Not installed
2023-06-05 00:15:09,523:INFO:               fugue: Not installed
2023-06-05 00:15:09,523:INFO:           streamlit: Not installed
2023-06-05 00:15:09,524:INFO:             prophet: 1.1.2
2023-06-05 00:15:09,524:INFO:None
2023-06-05 00:15:09,524:INFO:Set up data.
2023-06-05 00:15:09,552:INFO:Set up train/test split.
2023-06-05 00:15:09,584:INFO:Set up index.
2023-06-05 00:15:09,584:INFO:Set up folding strategy.
2023-06-05 00:15:09,584:INFO:Assigning column types.
2023-06-05 00:15:09,594:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-05 00:15:09,639:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 00:15:09,639:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:15:09,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:09,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:09,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 00:15:09,717:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:15:09,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:09,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:09,748:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-05 00:15:09,805:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:15:09,840:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:09,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:09,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:15:09,922:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:09,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:09,924:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-05 00:15:10,051:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:10,051:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:10,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:10,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:10,168:INFO:Preparing preprocessing pipeline...
2023-06-05 00:15:10,170:INFO:Set up simple imputation.
2023-06-05 00:15:10,186:INFO:Set up encoding of ordinal features.
2023-06-05 00:15:10,191:INFO:Set up encoding of categorical features.
2023-06-05 00:15:10,348:INFO:Finished creating preprocessing pipeline.
2023-06-05 00:15:10,373:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\shiva\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'hypertension',
                                             'heart_disease', 'smoking_history',
                                             'bmi', 'HbA1c_level',
                                             'blood_glucose_level'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['gender'],
                                    transformer=OrdinalEncoder(cols=['gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-06-05 00:15:10,373:INFO:Creating final display dataframe.
2023-06-05 00:15:10,501:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          diabetes
2                   Target type            Binary
3           Original data shape        (76885, 9)
4        Transformed data shape        (76885, 9)
5   Transformed train set shape        (57663, 9)
6    Transformed test set shape        (19222, 9)
7              Ordinal features                 1
8              Numeric features                 7
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              4f00
2023-06-05 00:15:10,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:10,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:10,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:10,782:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:15:10,783:INFO:setup() successfully completed in 2.26s...............
2023-06-05 00:15:10,783:INFO:Initializing compare_models()
2023-06-05 00:15:10,784:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-06-05 00:15:10,784:INFO:Checking exceptions
2023-06-05 00:15:10,804:INFO:Preparing display monitor
2023-06-05 00:15:10,817:INFO:Initializing Logistic Regression
2023-06-05 00:15:10,818:INFO:Total runtime is 0.0 minutes
2023-06-05 00:15:10,818:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:10,819:INFO:Initializing create_model()
2023-06-05 00:15:10,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:10,819:INFO:Checking exceptions
2023-06-05 00:15:10,820:INFO:Importing libraries
2023-06-05 00:15:10,820:INFO:Copying training dataset
2023-06-05 00:15:10,856:INFO:Defining folds
2023-06-05 00:15:10,856:INFO:Declaring metric variables
2023-06-05 00:15:10,857:INFO:Importing untrained model
2023-06-05 00:15:10,858:INFO:Logistic Regression Imported successfully
2023-06-05 00:15:10,858:INFO:Starting cross validation
2023-06-05 00:15:10,860:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:18,090:INFO:Calculating mean and std
2023-06-05 00:15:18,096:INFO:Creating metrics dataframe
2023-06-05 00:15:18,843:INFO:Uploading results into container
2023-06-05 00:15:18,844:INFO:Uploading model into container now
2023-06-05 00:15:18,845:INFO:_master_model_container: 1
2023-06-05 00:15:18,846:INFO:_display_container: 2
2023-06-05 00:15:18,847:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-05 00:15:18,848:INFO:create_model() successfully completed......................................
2023-06-05 00:15:19,564:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:19,564:INFO:Creating metrics dataframe
2023-06-05 00:15:19,581:INFO:Initializing K Neighbors Classifier
2023-06-05 00:15:19,581:INFO:Total runtime is 0.14606730540593466 minutes
2023-06-05 00:15:19,581:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:19,581:INFO:Initializing create_model()
2023-06-05 00:15:19,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:19,581:INFO:Checking exceptions
2023-06-05 00:15:19,581:INFO:Importing libraries
2023-06-05 00:15:19,581:INFO:Copying training dataset
2023-06-05 00:15:19,621:INFO:Defining folds
2023-06-05 00:15:19,621:INFO:Declaring metric variables
2023-06-05 00:15:19,621:INFO:Importing untrained model
2023-06-05 00:15:19,622:INFO:K Neighbors Classifier Imported successfully
2023-06-05 00:15:19,623:INFO:Starting cross validation
2023-06-05 00:15:19,624:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:29,402:INFO:Calculating mean and std
2023-06-05 00:15:29,403:INFO:Creating metrics dataframe
2023-06-05 00:15:29,774:INFO:Uploading results into container
2023-06-05 00:15:29,774:INFO:Uploading model into container now
2023-06-05 00:15:29,774:INFO:_master_model_container: 2
2023-06-05 00:15:29,774:INFO:_display_container: 2
2023-06-05 00:15:29,774:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-05 00:15:29,774:INFO:create_model() successfully completed......................................
2023-06-05 00:15:29,892:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:29,892:INFO:Creating metrics dataframe
2023-06-05 00:15:29,902:INFO:Initializing Naive Bayes
2023-06-05 00:15:29,902:INFO:Total runtime is 0.31808395783106486 minutes
2023-06-05 00:15:29,902:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:29,902:INFO:Initializing create_model()
2023-06-05 00:15:29,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:29,902:INFO:Checking exceptions
2023-06-05 00:15:29,902:INFO:Importing libraries
2023-06-05 00:15:29,902:INFO:Copying training dataset
2023-06-05 00:15:29,926:INFO:Defining folds
2023-06-05 00:15:29,926:INFO:Declaring metric variables
2023-06-05 00:15:29,926:INFO:Importing untrained model
2023-06-05 00:15:29,927:INFO:Naive Bayes Imported successfully
2023-06-05 00:15:29,927:INFO:Starting cross validation
2023-06-05 00:15:29,927:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:31,335:INFO:Calculating mean and std
2023-06-05 00:15:31,335:INFO:Creating metrics dataframe
2023-06-05 00:15:32,195:INFO:Uploading results into container
2023-06-05 00:15:32,195:INFO:Uploading model into container now
2023-06-05 00:15:32,195:INFO:_master_model_container: 3
2023-06-05 00:15:32,195:INFO:_display_container: 2
2023-06-05 00:15:32,195:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-05 00:15:32,195:INFO:create_model() successfully completed......................................
2023-06-05 00:15:32,349:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:32,349:INFO:Creating metrics dataframe
2023-06-05 00:15:32,365:INFO:Initializing Decision Tree Classifier
2023-06-05 00:15:32,365:INFO:Total runtime is 0.3591323216756185 minutes
2023-06-05 00:15:32,365:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:32,365:INFO:Initializing create_model()
2023-06-05 00:15:32,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:32,365:INFO:Checking exceptions
2023-06-05 00:15:32,365:INFO:Importing libraries
2023-06-05 00:15:32,365:INFO:Copying training dataset
2023-06-05 00:15:32,400:INFO:Defining folds
2023-06-05 00:15:32,400:INFO:Declaring metric variables
2023-06-05 00:15:32,407:INFO:Importing untrained model
2023-06-05 00:15:32,407:INFO:Decision Tree Classifier Imported successfully
2023-06-05 00:15:32,407:INFO:Starting cross validation
2023-06-05 00:15:32,407:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:34,413:INFO:Calculating mean and std
2023-06-05 00:15:34,413:INFO:Creating metrics dataframe
2023-06-05 00:15:35,459:INFO:Uploading results into container
2023-06-05 00:15:35,461:INFO:Uploading model into container now
2023-06-05 00:15:35,462:INFO:_master_model_container: 4
2023-06-05 00:15:35,462:INFO:_display_container: 2
2023-06-05 00:15:35,462:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-05 00:15:35,462:INFO:create_model() successfully completed......................................
2023-06-05 00:15:35,629:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:35,629:INFO:Creating metrics dataframe
2023-06-05 00:15:35,645:INFO:Initializing SVM - Linear Kernel
2023-06-05 00:15:35,645:INFO:Total runtime is 0.41380433638890585 minutes
2023-06-05 00:15:35,645:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:35,645:INFO:Initializing create_model()
2023-06-05 00:15:35,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:35,645:INFO:Checking exceptions
2023-06-05 00:15:35,645:INFO:Importing libraries
2023-06-05 00:15:35,645:INFO:Copying training dataset
2023-06-05 00:15:35,701:INFO:Defining folds
2023-06-05 00:15:35,702:INFO:Declaring metric variables
2023-06-05 00:15:35,702:INFO:Importing untrained model
2023-06-05 00:15:35,703:INFO:SVM - Linear Kernel Imported successfully
2023-06-05 00:15:35,703:INFO:Starting cross validation
2023-06-05 00:15:35,708:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:35,982:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:15:36,059:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:15:36,059:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:15:36,090:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:15:38,166:INFO:Calculating mean and std
2023-06-05 00:15:38,166:INFO:Creating metrics dataframe
2023-06-05 00:15:39,027:INFO:Uploading results into container
2023-06-05 00:15:39,028:INFO:Uploading model into container now
2023-06-05 00:15:39,028:INFO:_master_model_container: 5
2023-06-05 00:15:39,028:INFO:_display_container: 2
2023-06-05 00:15:39,028:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-05 00:15:39,028:INFO:create_model() successfully completed......................................
2023-06-05 00:15:39,170:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:39,170:INFO:Creating metrics dataframe
2023-06-05 00:15:39,178:INFO:Initializing Ridge Classifier
2023-06-05 00:15:39,178:INFO:Total runtime is 0.47267531951268515 minutes
2023-06-05 00:15:39,178:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:39,178:INFO:Initializing create_model()
2023-06-05 00:15:39,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:39,178:INFO:Checking exceptions
2023-06-05 00:15:39,178:INFO:Importing libraries
2023-06-05 00:15:39,178:INFO:Copying training dataset
2023-06-05 00:15:39,228:INFO:Defining folds
2023-06-05 00:15:39,228:INFO:Declaring metric variables
2023-06-05 00:15:39,228:INFO:Importing untrained model
2023-06-05 00:15:39,228:INFO:Ridge Classifier Imported successfully
2023-06-05 00:15:39,228:INFO:Starting cross validation
2023-06-05 00:15:39,228:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:39,523:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:15:39,523:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:15:39,594:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:15:39,667:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:15:41,685:INFO:Calculating mean and std
2023-06-05 00:15:41,693:INFO:Creating metrics dataframe
2023-06-05 00:15:42,542:INFO:Uploading results into container
2023-06-05 00:15:42,549:INFO:Uploading model into container now
2023-06-05 00:15:42,550:INFO:_master_model_container: 6
2023-06-05 00:15:42,550:INFO:_display_container: 2
2023-06-05 00:15:42,550:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-05 00:15:42,550:INFO:create_model() successfully completed......................................
2023-06-05 00:15:42,708:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:42,708:INFO:Creating metrics dataframe
2023-06-05 00:15:42,724:INFO:Initializing Random Forest Classifier
2023-06-05 00:15:42,724:INFO:Total runtime is 0.531777004400889 minutes
2023-06-05 00:15:42,724:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:42,724:INFO:Initializing create_model()
2023-06-05 00:15:42,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:42,724:INFO:Checking exceptions
2023-06-05 00:15:42,724:INFO:Importing libraries
2023-06-05 00:15:42,724:INFO:Copying training dataset
2023-06-05 00:15:42,764:INFO:Defining folds
2023-06-05 00:15:42,764:INFO:Declaring metric variables
2023-06-05 00:15:42,764:INFO:Importing untrained model
2023-06-05 00:15:42,764:INFO:Random Forest Classifier Imported successfully
2023-06-05 00:15:42,772:INFO:Starting cross validation
2023-06-05 00:15:42,775:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:45,624:INFO:Calculating mean and std
2023-06-05 00:15:45,626:INFO:Creating metrics dataframe
2023-06-05 00:15:46,052:INFO:Uploading results into container
2023-06-05 00:15:46,053:INFO:Uploading model into container now
2023-06-05 00:15:46,053:INFO:_master_model_container: 7
2023-06-05 00:15:46,053:INFO:_display_container: 2
2023-06-05 00:15:46,053:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-05 00:15:46,053:INFO:create_model() successfully completed......................................
2023-06-05 00:15:46,209:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:46,209:INFO:Creating metrics dataframe
2023-06-05 00:15:46,217:INFO:Initializing Quadratic Discriminant Analysis
2023-06-05 00:15:46,217:INFO:Total runtime is 0.590000581741333 minutes
2023-06-05 00:15:46,217:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:46,217:INFO:Initializing create_model()
2023-06-05 00:15:46,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:46,217:INFO:Checking exceptions
2023-06-05 00:15:46,217:INFO:Importing libraries
2023-06-05 00:15:46,217:INFO:Copying training dataset
2023-06-05 00:15:46,259:INFO:Defining folds
2023-06-05 00:15:46,259:INFO:Declaring metric variables
2023-06-05 00:15:46,259:INFO:Importing untrained model
2023-06-05 00:15:46,260:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-05 00:15:46,260:INFO:Starting cross validation
2023-06-05 00:15:46,260:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:47,742:INFO:Calculating mean and std
2023-06-05 00:15:47,742:INFO:Creating metrics dataframe
2023-06-05 00:15:48,299:INFO:Uploading results into container
2023-06-05 00:15:48,300:INFO:Uploading model into container now
2023-06-05 00:15:48,300:INFO:_master_model_container: 8
2023-06-05 00:15:48,300:INFO:_display_container: 2
2023-06-05 00:15:48,300:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-05 00:15:48,300:INFO:create_model() successfully completed......................................
2023-06-05 00:15:48,424:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:48,424:INFO:Creating metrics dataframe
2023-06-05 00:15:48,432:INFO:Initializing Ada Boost Classifier
2023-06-05 00:15:48,438:INFO:Total runtime is 0.6270227591196695 minutes
2023-06-05 00:15:48,438:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:48,438:INFO:Initializing create_model()
2023-06-05 00:15:48,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:48,439:INFO:Checking exceptions
2023-06-05 00:15:48,439:INFO:Importing libraries
2023-06-05 00:15:48,439:INFO:Copying training dataset
2023-06-05 00:15:48,457:INFO:Defining folds
2023-06-05 00:15:48,457:INFO:Declaring metric variables
2023-06-05 00:15:48,457:INFO:Importing untrained model
2023-06-05 00:15:48,457:INFO:Ada Boost Classifier Imported successfully
2023-06-05 00:15:48,457:INFO:Starting cross validation
2023-06-05 00:15:48,465:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:50,020:INFO:Calculating mean and std
2023-06-05 00:15:50,020:INFO:Creating metrics dataframe
2023-06-05 00:15:50,375:INFO:Uploading results into container
2023-06-05 00:15:50,375:INFO:Uploading model into container now
2023-06-05 00:15:50,375:INFO:_master_model_container: 9
2023-06-05 00:15:50,375:INFO:_display_container: 2
2023-06-05 00:15:50,375:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-05 00:15:50,375:INFO:create_model() successfully completed......................................
2023-06-05 00:15:50,494:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:50,494:INFO:Creating metrics dataframe
2023-06-05 00:15:50,494:INFO:Initializing Gradient Boosting Classifier
2023-06-05 00:15:50,494:INFO:Total runtime is 0.6612875819206238 minutes
2023-06-05 00:15:50,494:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:50,502:INFO:Initializing create_model()
2023-06-05 00:15:50,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:50,502:INFO:Checking exceptions
2023-06-05 00:15:50,502:INFO:Importing libraries
2023-06-05 00:15:50,502:INFO:Copying training dataset
2023-06-05 00:15:50,518:INFO:Defining folds
2023-06-05 00:15:50,518:INFO:Declaring metric variables
2023-06-05 00:15:50,518:INFO:Importing untrained model
2023-06-05 00:15:50,518:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:15:50,518:INFO:Starting cross validation
2023-06-05 00:15:50,518:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:52,644:INFO:Calculating mean and std
2023-06-05 00:15:52,644:INFO:Creating metrics dataframe
2023-06-05 00:15:52,993:INFO:Uploading results into container
2023-06-05 00:15:52,993:INFO:Uploading model into container now
2023-06-05 00:15:52,993:INFO:_master_model_container: 10
2023-06-05 00:15:52,993:INFO:_display_container: 2
2023-06-05 00:15:52,993:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:15:52,993:INFO:create_model() successfully completed......................................
2023-06-05 00:15:53,122:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:53,122:INFO:Creating metrics dataframe
2023-06-05 00:15:53,128:INFO:Initializing Linear Discriminant Analysis
2023-06-05 00:15:53,128:INFO:Total runtime is 0.7051893591880798 minutes
2023-06-05 00:15:53,128:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:53,128:INFO:Initializing create_model()
2023-06-05 00:15:53,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:53,128:INFO:Checking exceptions
2023-06-05 00:15:53,128:INFO:Importing libraries
2023-06-05 00:15:53,128:INFO:Copying training dataset
2023-06-05 00:15:53,153:INFO:Defining folds
2023-06-05 00:15:53,153:INFO:Declaring metric variables
2023-06-05 00:15:53,153:INFO:Importing untrained model
2023-06-05 00:15:53,153:INFO:Linear Discriminant Analysis Imported successfully
2023-06-05 00:15:53,153:INFO:Starting cross validation
2023-06-05 00:15:53,153:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:54,684:INFO:Calculating mean and std
2023-06-05 00:15:54,686:INFO:Creating metrics dataframe
2023-06-05 00:15:55,563:INFO:Uploading results into container
2023-06-05 00:15:55,563:INFO:Uploading model into container now
2023-06-05 00:15:55,563:INFO:_master_model_container: 11
2023-06-05 00:15:55,563:INFO:_display_container: 2
2023-06-05 00:15:55,563:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-05 00:15:55,563:INFO:create_model() successfully completed......................................
2023-06-05 00:15:55,679:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:55,679:INFO:Creating metrics dataframe
2023-06-05 00:15:55,688:INFO:Initializing Extra Trees Classifier
2023-06-05 00:15:55,688:INFO:Total runtime is 0.7478545069694519 minutes
2023-06-05 00:15:55,688:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:55,688:INFO:Initializing create_model()
2023-06-05 00:15:55,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:55,688:INFO:Checking exceptions
2023-06-05 00:15:55,688:INFO:Importing libraries
2023-06-05 00:15:55,688:INFO:Copying training dataset
2023-06-05 00:15:55,712:INFO:Defining folds
2023-06-05 00:15:55,712:INFO:Declaring metric variables
2023-06-05 00:15:55,712:INFO:Importing untrained model
2023-06-05 00:15:55,712:INFO:Extra Trees Classifier Imported successfully
2023-06-05 00:15:55,712:INFO:Starting cross validation
2023-06-05 00:15:55,720:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:15:58,062:INFO:Calculating mean and std
2023-06-05 00:15:58,062:INFO:Creating metrics dataframe
2023-06-05 00:15:58,446:INFO:Uploading results into container
2023-06-05 00:15:58,452:INFO:Uploading model into container now
2023-06-05 00:15:58,453:INFO:_master_model_container: 12
2023-06-05 00:15:58,453:INFO:_display_container: 2
2023-06-05 00:15:58,454:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-05 00:15:58,454:INFO:create_model() successfully completed......................................
2023-06-05 00:15:58,569:INFO:SubProcess create_model() end ==================================
2023-06-05 00:15:58,569:INFO:Creating metrics dataframe
2023-06-05 00:15:58,577:INFO:Initializing Light Gradient Boosting Machine
2023-06-05 00:15:58,577:INFO:Total runtime is 0.7960056543350219 minutes
2023-06-05 00:15:58,577:INFO:SubProcess create_model() called ==================================
2023-06-05 00:15:58,577:INFO:Initializing create_model()
2023-06-05 00:15:58,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:15:58,577:INFO:Checking exceptions
2023-06-05 00:15:58,577:INFO:Importing libraries
2023-06-05 00:15:58,577:INFO:Copying training dataset
2023-06-05 00:15:58,628:INFO:Defining folds
2023-06-05 00:15:58,628:INFO:Declaring metric variables
2023-06-05 00:15:58,629:INFO:Importing untrained model
2023-06-05 00:15:58,629:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-05 00:15:58,629:INFO:Starting cross validation
2023-06-05 00:15:58,635:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:16:00,782:INFO:Calculating mean and std
2023-06-05 00:16:00,784:INFO:Creating metrics dataframe
2023-06-05 00:16:01,442:INFO:Uploading results into container
2023-06-05 00:16:01,442:INFO:Uploading model into container now
2023-06-05 00:16:01,443:INFO:_master_model_container: 13
2023-06-05 00:16:01,443:INFO:_display_container: 2
2023-06-05 00:16:01,443:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-05 00:16:01,443:INFO:create_model() successfully completed......................................
2023-06-05 00:16:01,567:INFO:SubProcess create_model() end ==================================
2023-06-05 00:16:01,567:INFO:Creating metrics dataframe
2023-06-05 00:16:01,573:INFO:Initializing Dummy Classifier
2023-06-05 00:16:01,573:INFO:Total runtime is 0.8459261020024617 minutes
2023-06-05 00:16:01,573:INFO:SubProcess create_model() called ==================================
2023-06-05 00:16:01,573:INFO:Initializing create_model()
2023-06-05 00:16:01,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD01A8BA50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:16:01,573:INFO:Checking exceptions
2023-06-05 00:16:01,573:INFO:Importing libraries
2023-06-05 00:16:01,573:INFO:Copying training dataset
2023-06-05 00:16:01,606:INFO:Defining folds
2023-06-05 00:16:01,606:INFO:Declaring metric variables
2023-06-05 00:16:01,606:INFO:Importing untrained model
2023-06-05 00:16:01,606:INFO:Dummy Classifier Imported successfully
2023-06-05 00:16:01,607:INFO:Starting cross validation
2023-06-05 00:16:01,608:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:16:01,824:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:16:01,838:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:16:01,897:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:16:01,925:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:16:03,042:INFO:Calculating mean and std
2023-06-05 00:16:03,049:INFO:Creating metrics dataframe
2023-06-05 00:16:03,362:INFO:Uploading results into container
2023-06-05 00:16:03,363:INFO:Uploading model into container now
2023-06-05 00:16:03,365:INFO:_master_model_container: 14
2023-06-05 00:16:03,365:INFO:_display_container: 2
2023-06-05 00:16:03,365:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-05 00:16:03,366:INFO:create_model() successfully completed......................................
2023-06-05 00:16:03,482:INFO:SubProcess create_model() end ==================================
2023-06-05 00:16:03,482:INFO:Creating metrics dataframe
2023-06-05 00:16:03,494:INFO:Initializing create_model()
2023-06-05 00:16:03,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:16:03,494:INFO:Checking exceptions
2023-06-05 00:16:03,497:INFO:Importing libraries
2023-06-05 00:16:03,497:INFO:Copying training dataset
2023-06-05 00:16:03,530:INFO:Defining folds
2023-06-05 00:16:03,530:INFO:Declaring metric variables
2023-06-05 00:16:03,531:INFO:Importing untrained model
2023-06-05 00:16:03,531:INFO:Declaring custom model
2023-06-05 00:16:03,531:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:16:03,533:INFO:Cross validation set to False
2023-06-05 00:16:03,534:INFO:Fitting Model
2023-06-05 00:16:04,128:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:16:04,128:INFO:create_model() successfully completed......................................
2023-06-05 00:16:04,374:INFO:_master_model_container: 14
2023-06-05 00:16:04,374:INFO:_display_container: 2
2023-06-05 00:16:04,376:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:16:04,376:INFO:compare_models() successfully completed......................................
2023-06-05 00:16:04,378:INFO:Initializing evaluate_model()
2023-06-05 00:16:04,378:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-05 00:16:04,608:INFO:Initializing plot_model()
2023-06-05 00:16:04,608:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, use_train_data=False, verbose=False, system=True, display=None, display_format=None)
2023-06-05 00:16:04,608:INFO:Checking exceptions
2023-06-05 00:16:04,623:INFO:Preloading libraries
2023-06-05 00:16:04,645:INFO:Copying training dataset
2023-06-05 00:16:04,645:INFO:Plot type: pipeline
2023-06-05 00:16:04,722:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:572: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  fig, ax = plt.subplots(

2023-06-05 00:16:04,883:INFO:Initializing tune_model()
2023-06-05 00:16:04,883:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2023-06-05 00:16:04,883:INFO:Checking exceptions
2023-06-05 00:16:04,899:INFO:Copying training dataset
2023-06-05 00:16:04,922:INFO:Checking base model
2023-06-05 00:16:04,923:INFO:Base model : Gradient Boosting Classifier
2023-06-05 00:16:04,925:INFO:Declaring metric variables
2023-06-05 00:16:04,926:INFO:Defining Hyperparameters
2023-06-05 00:16:05,059:INFO:Tuning with n_jobs=-1
2023-06-05 00:16:05,060:INFO:Initializing RandomizedSearchCV
2023-06-05 00:16:06,710:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-05 00:16:06,930:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-05 00:16:54,332:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-06-05 00:16:54,334:INFO:Hyperparameter search completed
2023-06-05 00:16:54,334:INFO:SubProcess create_model() called ==================================
2023-06-05 00:16:54,334:INFO:Initializing create_model()
2023-06-05 00:16:54,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD004781D0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-06-05 00:16:54,334:INFO:Checking exceptions
2023-06-05 00:16:54,335:INFO:Importing libraries
2023-06-05 00:16:54,335:INFO:Copying training dataset
2023-06-05 00:16:54,356:INFO:Defining folds
2023-06-05 00:16:54,356:INFO:Declaring metric variables
2023-06-05 00:16:54,356:INFO:Importing untrained model
2023-06-05 00:16:54,356:INFO:Declaring custom model
2023-06-05 00:16:54,356:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:16:54,356:INFO:Starting cross validation
2023-06-05 00:16:54,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:16:58,831:INFO:Calculating mean and std
2023-06-05 00:16:58,834:INFO:Creating metrics dataframe
2023-06-05 00:16:58,838:INFO:Finalizing model
2023-06-05 00:16:59,479:INFO:Uploading results into container
2023-06-05 00:16:59,484:INFO:Uploading model into container now
2023-06-05 00:16:59,487:INFO:_master_model_container: 15
2023-06-05 00:16:59,488:INFO:_display_container: 3
2023-06-05 00:16:59,493:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:16:59,494:INFO:create_model() successfully completed......................................
2023-06-05 00:16:59,861:INFO:SubProcess create_model() end ==================================
2023-06-05 00:16:59,862:INFO:choose_better activated
2023-06-05 00:16:59,862:INFO:SubProcess create_model() called ==================================
2023-06-05 00:16:59,864:INFO:Initializing create_model()
2023-06-05 00:16:59,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD78C73110>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:16:59,864:INFO:Checking exceptions
2023-06-05 00:16:59,865:INFO:Importing libraries
2023-06-05 00:16:59,865:INFO:Copying training dataset
2023-06-05 00:16:59,904:INFO:Defining folds
2023-06-05 00:16:59,904:INFO:Declaring metric variables
2023-06-05 00:16:59,905:INFO:Importing untrained model
2023-06-05 00:16:59,905:INFO:Declaring custom model
2023-06-05 00:16:59,906:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:16:59,907:INFO:Starting cross validation
2023-06-05 00:16:59,908:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:17:06,230:INFO:Calculating mean and std
2023-06-05 00:17:06,230:INFO:Creating metrics dataframe
2023-06-05 00:17:06,240:INFO:Finalizing model
2023-06-05 00:17:07,571:INFO:Uploading results into container
2023-06-05 00:17:07,576:INFO:Uploading model into container now
2023-06-05 00:17:07,577:INFO:_master_model_container: 16
2023-06-05 00:17:07,577:INFO:_display_container: 4
2023-06-05 00:17:07,577:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:17:07,577:INFO:create_model() successfully completed......................................
2023-06-05 00:17:07,771:INFO:SubProcess create_model() end ==================================
2023-06-05 00:17:07,771:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-05 00:17:07,775:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-05 00:17:07,776:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-06-05 00:17:07,777:INFO:choose_better completed
2023-06-05 00:17:07,779:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-05 00:17:07,815:INFO:_master_model_container: 16
2023-06-05 00:17:07,815:INFO:_display_container: 3
2023-06-05 00:17:07,824:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:17:07,824:INFO:tune_model() successfully completed......................................
2023-06-05 00:26:49,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:26:49,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:26:49,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:26:49,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:26:50,706:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:27:04,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:04,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:04,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:04,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:05,227:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:27:36,931:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:36,931:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:36,931:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:36,931:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:37,331:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:27:51,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:51,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:51,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:51,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:27:51,781:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:30:11,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:11,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:11,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:11,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:12,061:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:30:21,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:21,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:21,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:21,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:22,379:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:30:58,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:58,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:58,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:58,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:30:58,938:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:31:06,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:31:06,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:31:06,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:31:06,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:31:07,432:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:31:24,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:31:24,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:31:24,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:31:24,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:31:24,436:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:32:05,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:32:05,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:32:05,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:32:05,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:32:06,170:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:32:12,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:32:12,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:32:12,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:32:12,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 00:32:13,270:INFO:Soft dependency imported: prophet: 1.1.2
2023-06-05 00:32:33,928:INFO:PyCaret ClassificationExperiment
2023-06-05 00:32:33,928:INFO:Logging name: clf-default-name
2023-06-05 00:32:33,928:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-05 00:32:33,928:INFO:version 3.0.0
2023-06-05 00:32:33,928:INFO:Initializing setup()
2023-06-05 00:32:33,928:INFO:self.USI: af0d
2023-06-05 00:32:33,928:INFO:self._variable_keys: {'fold_groups_param', '_ml_usecase', 'fold_shuffle_param', 'fix_imbalance', 'data', 'is_multiclass', 'gpu_n_jobs_param', 'exp_name_log', 'seed', 'logging_param', 'X_test', 'USI', 'n_jobs_param', 'fold_generator', 'idx', 'log_plots_param', 'exp_id', 'html_param', 'X', 'X_train', 'y_train', 'gpu_param', '_available_plots', 'y', 'memory', 'pipeline', 'target_param', 'y_test'}
2023-06-05 00:32:33,928:INFO:Checking environment
2023-06-05 00:32:33,928:INFO:python_version: 3.11.3
2023-06-05 00:32:33,928:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2023-06-05 00:32:33,928:INFO:machine: AMD64
2023-06-05 00:32:33,956:INFO:platform: Windows-10-10.0.19045-SP0
2023-06-05 00:32:33,962:INFO:Memory: svmem(total=8384401408, available=1927622656, percent=77.0, used=6456778752, free=1927622656)
2023-06-05 00:32:33,962:INFO:Physical Core: 4
2023-06-05 00:32:33,962:INFO:Logical Core: 8
2023-06-05 00:32:33,962:INFO:Checking libraries
2023-06-05 00:32:33,962:INFO:System:
2023-06-05 00:32:33,962:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2023-06-05 00:32:33,962:INFO:executable: C:\Program Files\Python311\python.exe
2023-06-05 00:32:33,962:INFO:   machine: Windows-10-10.0.19045-SP0
2023-06-05 00:32:33,962:INFO:PyCaret required dependencies:
2023-06-05 00:32:33,962:INFO:                 pip: 22.3.1
2023-06-05 00:32:33,962:INFO:          setuptools: 65.5.0
2023-06-05 00:32:33,962:INFO:             pycaret: 3.0.0
2023-06-05 00:32:33,962:INFO:             IPython: 8.12.0
2023-06-05 00:32:33,962:INFO:          ipywidgets: 8.0.6
2023-06-05 00:32:33,962:INFO:                tqdm: 4.65.0
2023-06-05 00:32:33,962:INFO:               numpy: 1.24.3
2023-06-05 00:32:33,962:INFO:              pandas: 1.5.3
2023-06-05 00:32:33,962:INFO:              jinja2: 3.1.2
2023-06-05 00:32:33,962:INFO:               scipy: 1.10.1
2023-06-05 00:32:33,962:INFO:              joblib: 1.2.0
2023-06-05 00:32:33,962:INFO:             sklearn: 1.2.2
2023-06-05 00:32:33,962:INFO:                pyod: 1.0.9
2023-06-05 00:32:33,962:INFO:            imblearn: 0.10.1
2023-06-05 00:32:33,962:INFO:   category_encoders: 2.6.0
2023-06-05 00:32:33,962:INFO:            lightgbm: 3.3.5
2023-06-05 00:32:33,962:INFO:               numba: 0.57.0
2023-06-05 00:32:33,962:INFO:            requests: 2.28.2
2023-06-05 00:32:33,962:INFO:          matplotlib: 3.7.1
2023-06-05 00:32:33,962:INFO:          scikitplot: 0.3.7
2023-06-05 00:32:33,962:INFO:         yellowbrick: 1.5
2023-06-05 00:32:33,962:INFO:              plotly: 5.14.1
2023-06-05 00:32:33,962:INFO:             kaleido: 0.2.1
2023-06-05 00:32:33,962:INFO:         statsmodels: 0.14.0
2023-06-05 00:32:33,962:INFO:              sktime: 0.18.0
2023-06-05 00:32:33,962:INFO:               tbats: 1.1.3
2023-06-05 00:32:33,962:INFO:            pmdarima: 2.0.3
2023-06-05 00:32:33,962:INFO:              psutil: 5.9.4
2023-06-05 00:32:33,962:INFO:PyCaret optional dependencies:
2023-06-05 00:32:33,978:INFO:                shap: Not installed
2023-06-05 00:32:33,978:INFO:           interpret: Not installed
2023-06-05 00:32:33,978:INFO:                umap: Not installed
2023-06-05 00:32:33,978:INFO:    pandas_profiling: Not installed
2023-06-05 00:32:33,978:INFO:  explainerdashboard: Not installed
2023-06-05 00:32:33,978:INFO:             autoviz: Not installed
2023-06-05 00:32:33,978:INFO:           fairlearn: Not installed
2023-06-05 00:32:33,978:INFO:             xgboost: Not installed
2023-06-05 00:32:33,978:INFO:            catboost: Not installed
2023-06-05 00:32:33,978:INFO:              kmodes: Not installed
2023-06-05 00:32:33,978:INFO:             mlxtend: Not installed
2023-06-05 00:32:33,978:INFO:       statsforecast: Not installed
2023-06-05 00:32:33,978:INFO:        tune_sklearn: Not installed
2023-06-05 00:32:33,978:INFO:                 ray: Not installed
2023-06-05 00:32:33,978:INFO:            hyperopt: Not installed
2023-06-05 00:32:33,978:INFO:              optuna: Not installed
2023-06-05 00:32:33,978:INFO:               skopt: Not installed
2023-06-05 00:32:33,978:INFO:              mlflow: Not installed
2023-06-05 00:32:33,978:INFO:              gradio: Not installed
2023-06-05 00:32:33,978:INFO:             fastapi: Not installed
2023-06-05 00:32:33,978:INFO:             uvicorn: Not installed
2023-06-05 00:32:33,978:INFO:              m2cgen: Not installed
2023-06-05 00:32:33,978:INFO:           evidently: Not installed
2023-06-05 00:32:33,978:INFO:               fugue: Not installed
2023-06-05 00:32:33,978:INFO:           streamlit: Not installed
2023-06-05 00:32:33,978:INFO:             prophet: 1.1.2
2023-06-05 00:32:33,978:INFO:None
2023-06-05 00:32:33,978:INFO:Set up data.
2023-06-05 00:32:34,008:INFO:Set up train/test split.
2023-06-05 00:32:34,030:INFO:Set up index.
2023-06-05 00:32:34,030:INFO:Set up folding strategy.
2023-06-05 00:32:34,030:INFO:Assigning column types.
2023-06-05 00:32:34,049:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-05 00:32:34,100:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 00:32:34,116:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:32:34,167:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 00:32:34,350:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:32:34,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,392:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-05 00:32:34,443:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:32:34,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,511:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-05 00:32:34,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,536:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-05 00:32:34,604:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:34,670:INFO:Preparing preprocessing pipeline...
2023-06-05 00:32:34,673:INFO:Set up simple imputation.
2023-06-05 00:32:34,682:INFO:Set up encoding of ordinal features.
2023-06-05 00:32:34,685:INFO:Set up encoding of categorical features.
2023-06-05 00:32:34,803:INFO:Finished creating preprocessing pipeline.
2023-06-05 00:32:34,824:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\shiva\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'hypertension',
                                             'heart_disease', 'smoking_history',
                                             'bmi', 'HbA1c_level',
                                             'blood_glucose_level'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('ordinal_encoding',
                 TransformerWrapper(exclude=None, include=['gender'],
                                    transformer=OrdinalEncoder(cols=['gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0)))],
         verbose=False)
2023-06-05 00:32:34,824:INFO:Creating final display dataframe.
2023-06-05 00:32:34,918:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          diabetes
2                   Target type            Binary
3           Original data shape        (76885, 9)
4        Transformed data shape        (76885, 9)
5   Transformed train set shape        (57663, 9)
6    Transformed test set shape        (19222, 9)
7              Ordinal features                 1
8              Numeric features                 7
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              af0d
2023-06-05 00:32:35,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:35,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:35,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:35,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 00:32:35,091:INFO:setup() successfully completed in 2.11s...............
2023-06-05 00:32:35,091:INFO:Initializing compare_models()
2023-06-05 00:32:35,091:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-06-05 00:32:35,091:INFO:Checking exceptions
2023-06-05 00:32:35,120:INFO:Preparing display monitor
2023-06-05 00:32:35,128:INFO:Initializing Logistic Regression
2023-06-05 00:32:35,128:INFO:Total runtime is 0.0 minutes
2023-06-05 00:32:35,129:INFO:SubProcess create_model() called ==================================
2023-06-05 00:32:35,130:INFO:Initializing create_model()
2023-06-05 00:32:35,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:32:35,130:INFO:Checking exceptions
2023-06-05 00:32:35,130:INFO:Importing libraries
2023-06-05 00:32:35,131:INFO:Copying training dataset
2023-06-05 00:32:35,163:INFO:Defining folds
2023-06-05 00:32:35,164:INFO:Declaring metric variables
2023-06-05 00:32:35,164:INFO:Importing untrained model
2023-06-05 00:32:35,164:INFO:Logistic Regression Imported successfully
2023-06-05 00:32:35,164:INFO:Starting cross validation
2023-06-05 00:32:35,165:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:32:41,582:INFO:Calculating mean and std
2023-06-05 00:32:41,583:INFO:Creating metrics dataframe
2023-06-05 00:32:41,927:INFO:Uploading results into container
2023-06-05 00:32:41,927:INFO:Uploading model into container now
2023-06-05 00:32:41,928:INFO:_master_model_container: 1
2023-06-05 00:32:41,928:INFO:_display_container: 2
2023-06-05 00:32:41,928:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-05 00:32:41,928:INFO:create_model() successfully completed......................................
2023-06-05 00:32:42,088:INFO:SubProcess create_model() end ==================================
2023-06-05 00:32:42,088:INFO:Creating metrics dataframe
2023-06-05 00:32:42,099:INFO:Initializing K Neighbors Classifier
2023-06-05 00:32:42,099:INFO:Total runtime is 0.11619231303532919 minutes
2023-06-05 00:32:42,100:INFO:SubProcess create_model() called ==================================
2023-06-05 00:32:42,100:INFO:Initializing create_model()
2023-06-05 00:32:42,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:32:42,100:INFO:Checking exceptions
2023-06-05 00:32:42,102:INFO:Importing libraries
2023-06-05 00:32:42,102:INFO:Copying training dataset
2023-06-05 00:32:42,130:INFO:Defining folds
2023-06-05 00:32:42,130:INFO:Declaring metric variables
2023-06-05 00:32:42,134:INFO:Importing untrained model
2023-06-05 00:32:42,134:INFO:K Neighbors Classifier Imported successfully
2023-06-05 00:32:42,134:INFO:Starting cross validation
2023-06-05 00:32:42,136:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:32:46,980:INFO:Calculating mean and std
2023-06-05 00:32:46,981:INFO:Creating metrics dataframe
2023-06-05 00:32:47,240:INFO:Uploading results into container
2023-06-05 00:32:47,245:INFO:Uploading model into container now
2023-06-05 00:32:47,245:INFO:_master_model_container: 2
2023-06-05 00:32:47,246:INFO:_display_container: 2
2023-06-05 00:32:47,246:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-05 00:32:47,246:INFO:create_model() successfully completed......................................
2023-06-05 00:32:47,366:INFO:SubProcess create_model() end ==================================
2023-06-05 00:32:47,366:INFO:Creating metrics dataframe
2023-06-05 00:32:47,375:INFO:Initializing Naive Bayes
2023-06-05 00:32:47,375:INFO:Total runtime is 0.20412292480468752 minutes
2023-06-05 00:32:47,375:INFO:SubProcess create_model() called ==================================
2023-06-05 00:32:47,375:INFO:Initializing create_model()
2023-06-05 00:32:47,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:32:47,375:INFO:Checking exceptions
2023-06-05 00:32:47,375:INFO:Importing libraries
2023-06-05 00:32:47,375:INFO:Copying training dataset
2023-06-05 00:32:47,399:INFO:Defining folds
2023-06-05 00:32:47,399:INFO:Declaring metric variables
2023-06-05 00:32:47,399:INFO:Importing untrained model
2023-06-05 00:32:47,399:INFO:Naive Bayes Imported successfully
2023-06-05 00:32:47,400:INFO:Starting cross validation
2023-06-05 00:32:47,401:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:32:49,552:INFO:Calculating mean and std
2023-06-05 00:32:49,554:INFO:Creating metrics dataframe
2023-06-05 00:32:50,316:INFO:Uploading results into container
2023-06-05 00:32:50,317:INFO:Uploading model into container now
2023-06-05 00:32:50,318:INFO:_master_model_container: 3
2023-06-05 00:32:50,318:INFO:_display_container: 2
2023-06-05 00:32:50,318:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-05 00:32:50,318:INFO:create_model() successfully completed......................................
2023-06-05 00:32:50,454:INFO:SubProcess create_model() end ==================================
2023-06-05 00:32:50,454:INFO:Creating metrics dataframe
2023-06-05 00:32:50,461:INFO:Initializing Decision Tree Classifier
2023-06-05 00:32:50,461:INFO:Total runtime is 0.25556151866912846 minutes
2023-06-05 00:32:50,461:INFO:SubProcess create_model() called ==================================
2023-06-05 00:32:50,461:INFO:Initializing create_model()
2023-06-05 00:32:50,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:32:50,461:INFO:Checking exceptions
2023-06-05 00:32:50,461:INFO:Importing libraries
2023-06-05 00:32:50,469:INFO:Copying training dataset
2023-06-05 00:32:50,496:INFO:Defining folds
2023-06-05 00:32:50,503:INFO:Declaring metric variables
2023-06-05 00:32:50,503:INFO:Importing untrained model
2023-06-05 00:32:50,505:INFO:Decision Tree Classifier Imported successfully
2023-06-05 00:32:50,505:INFO:Starting cross validation
2023-06-05 00:32:50,507:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:32:52,657:INFO:Calculating mean and std
2023-06-05 00:32:52,659:INFO:Creating metrics dataframe
2023-06-05 00:32:53,468:INFO:Uploading results into container
2023-06-05 00:32:53,469:INFO:Uploading model into container now
2023-06-05 00:32:53,470:INFO:_master_model_container: 4
2023-06-05 00:32:53,470:INFO:_display_container: 2
2023-06-05 00:32:53,471:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-05 00:32:53,471:INFO:create_model() successfully completed......................................
2023-06-05 00:32:53,614:INFO:SubProcess create_model() end ==================================
2023-06-05 00:32:53,614:INFO:Creating metrics dataframe
2023-06-05 00:32:53,624:INFO:Initializing SVM - Linear Kernel
2023-06-05 00:32:53,624:INFO:Total runtime is 0.3082619945208232 minutes
2023-06-05 00:32:53,624:INFO:SubProcess create_model() called ==================================
2023-06-05 00:32:53,632:INFO:Initializing create_model()
2023-06-05 00:32:53,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:32:53,632:INFO:Checking exceptions
2023-06-05 00:32:53,632:INFO:Importing libraries
2023-06-05 00:32:53,632:INFO:Copying training dataset
2023-06-05 00:32:53,672:INFO:Defining folds
2023-06-05 00:32:53,672:INFO:Declaring metric variables
2023-06-05 00:32:53,672:INFO:Importing untrained model
2023-06-05 00:32:53,673:INFO:SVM - Linear Kernel Imported successfully
2023-06-05 00:32:53,674:INFO:Starting cross validation
2023-06-05 00:32:53,676:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:32:53,913:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:32:53,965:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:32:53,985:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:32:54,030:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-05 00:32:56,121:INFO:Calculating mean and std
2023-06-05 00:32:56,124:INFO:Creating metrics dataframe
2023-06-05 00:32:56,912:INFO:Uploading results into container
2023-06-05 00:32:56,917:INFO:Uploading model into container now
2023-06-05 00:32:56,917:INFO:_master_model_container: 5
2023-06-05 00:32:56,918:INFO:_display_container: 2
2023-06-05 00:32:56,918:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-05 00:32:56,919:INFO:create_model() successfully completed......................................
2023-06-05 00:32:57,060:INFO:SubProcess create_model() end ==================================
2023-06-05 00:32:57,060:INFO:Creating metrics dataframe
2023-06-05 00:32:57,068:INFO:Initializing Ridge Classifier
2023-06-05 00:32:57,068:INFO:Total runtime is 0.36567720572153734 minutes
2023-06-05 00:32:57,068:INFO:SubProcess create_model() called ==================================
2023-06-05 00:32:57,068:INFO:Initializing create_model()
2023-06-05 00:32:57,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:32:57,068:INFO:Checking exceptions
2023-06-05 00:32:57,068:INFO:Importing libraries
2023-06-05 00:32:57,068:INFO:Copying training dataset
2023-06-05 00:32:57,096:INFO:Defining folds
2023-06-05 00:32:57,104:INFO:Declaring metric variables
2023-06-05 00:32:57,104:INFO:Importing untrained model
2023-06-05 00:32:57,105:INFO:Ridge Classifier Imported successfully
2023-06-05 00:32:57,105:INFO:Starting cross validation
2023-06-05 00:32:57,107:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:32:57,395:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:32:57,404:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:32:57,452:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:32:57,509:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-05 00:32:59,479:INFO:Calculating mean and std
2023-06-05 00:32:59,481:INFO:Creating metrics dataframe
2023-06-05 00:32:59,976:INFO:Uploading results into container
2023-06-05 00:32:59,982:INFO:Uploading model into container now
2023-06-05 00:32:59,983:INFO:_master_model_container: 6
2023-06-05 00:32:59,983:INFO:_display_container: 2
2023-06-05 00:32:59,983:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-05 00:32:59,983:INFO:create_model() successfully completed......................................
2023-06-05 00:33:00,122:INFO:SubProcess create_model() end ==================================
2023-06-05 00:33:00,122:INFO:Creating metrics dataframe
2023-06-05 00:33:00,132:INFO:Initializing Random Forest Classifier
2023-06-05 00:33:00,132:INFO:Total runtime is 0.4167329072952271 minutes
2023-06-05 00:33:00,132:INFO:SubProcess create_model() called ==================================
2023-06-05 00:33:00,136:INFO:Initializing create_model()
2023-06-05 00:33:00,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:33:00,136:INFO:Checking exceptions
2023-06-05 00:33:00,136:INFO:Importing libraries
2023-06-05 00:33:00,136:INFO:Copying training dataset
2023-06-05 00:33:00,166:INFO:Defining folds
2023-06-05 00:33:00,169:INFO:Declaring metric variables
2023-06-05 00:33:00,169:INFO:Importing untrained model
2023-06-05 00:33:00,170:INFO:Random Forest Classifier Imported successfully
2023-06-05 00:33:00,171:INFO:Starting cross validation
2023-06-05 00:33:00,174:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:33:02,345:INFO:Calculating mean and std
2023-06-05 00:33:02,348:INFO:Creating metrics dataframe
2023-06-05 00:33:02,858:INFO:Uploading results into container
2023-06-05 00:33:02,859:INFO:Uploading model into container now
2023-06-05 00:33:02,860:INFO:_master_model_container: 7
2023-06-05 00:33:02,860:INFO:_display_container: 2
2023-06-05 00:33:02,861:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-05 00:33:02,861:INFO:create_model() successfully completed......................................
2023-06-05 00:33:03,022:INFO:SubProcess create_model() end ==================================
2023-06-05 00:33:03,023:INFO:Creating metrics dataframe
2023-06-05 00:33:03,033:INFO:Initializing Quadratic Discriminant Analysis
2023-06-05 00:33:03,033:INFO:Total runtime is 0.46509057283401495 minutes
2023-06-05 00:33:03,033:INFO:SubProcess create_model() called ==================================
2023-06-05 00:33:03,034:INFO:Initializing create_model()
2023-06-05 00:33:03,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:33:03,035:INFO:Checking exceptions
2023-06-05 00:33:03,035:INFO:Importing libraries
2023-06-05 00:33:03,035:INFO:Copying training dataset
2023-06-05 00:33:03,079:INFO:Defining folds
2023-06-05 00:33:03,079:INFO:Declaring metric variables
2023-06-05 00:33:03,080:INFO:Importing untrained model
2023-06-05 00:33:03,081:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-05 00:33:03,082:INFO:Starting cross validation
2023-06-05 00:33:03,085:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:33:04,999:INFO:Calculating mean and std
2023-06-05 00:33:04,999:INFO:Creating metrics dataframe
2023-06-05 00:33:05,936:INFO:Uploading results into container
2023-06-05 00:33:05,936:INFO:Uploading model into container now
2023-06-05 00:33:05,942:INFO:_master_model_container: 8
2023-06-05 00:33:05,942:INFO:_display_container: 2
2023-06-05 00:33:05,943:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-05 00:33:05,944:INFO:create_model() successfully completed......................................
2023-06-05 00:33:06,143:INFO:SubProcess create_model() end ==================================
2023-06-05 00:33:06,143:INFO:Creating metrics dataframe
2023-06-05 00:33:06,157:INFO:Initializing Ada Boost Classifier
2023-06-05 00:33:06,157:INFO:Total runtime is 0.5171600898106894 minutes
2023-06-05 00:33:06,158:INFO:SubProcess create_model() called ==================================
2023-06-05 00:33:06,159:INFO:Initializing create_model()
2023-06-05 00:33:06,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:33:06,160:INFO:Checking exceptions
2023-06-05 00:33:06,161:INFO:Importing libraries
2023-06-05 00:33:06,161:INFO:Copying training dataset
2023-06-05 00:33:06,205:INFO:Defining folds
2023-06-05 00:33:06,205:INFO:Declaring metric variables
2023-06-05 00:33:06,207:INFO:Importing untrained model
2023-06-05 00:33:06,208:INFO:Ada Boost Classifier Imported successfully
2023-06-05 00:33:06,208:INFO:Starting cross validation
2023-06-05 00:33:06,210:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:33:09,518:INFO:Calculating mean and std
2023-06-05 00:33:09,519:INFO:Creating metrics dataframe
2023-06-05 00:33:10,396:INFO:Uploading results into container
2023-06-05 00:33:10,396:INFO:Uploading model into container now
2023-06-05 00:33:10,400:INFO:_master_model_container: 9
2023-06-05 00:33:10,400:INFO:_display_container: 2
2023-06-05 00:33:10,400:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-05 00:33:10,401:INFO:create_model() successfully completed......................................
2023-06-05 00:33:10,615:INFO:SubProcess create_model() end ==================================
2023-06-05 00:33:10,616:INFO:Creating metrics dataframe
2023-06-05 00:33:10,632:INFO:Initializing Gradient Boosting Classifier
2023-06-05 00:33:10,633:INFO:Total runtime is 0.5917528231938681 minutes
2023-06-05 00:33:10,633:INFO:SubProcess create_model() called ==================================
2023-06-05 00:33:10,633:INFO:Initializing create_model()
2023-06-05 00:33:10,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:33:10,634:INFO:Checking exceptions
2023-06-05 00:33:10,634:INFO:Importing libraries
2023-06-05 00:33:10,634:INFO:Copying training dataset
2023-06-05 00:33:10,686:INFO:Defining folds
2023-06-05 00:33:10,686:INFO:Declaring metric variables
2023-06-05 00:33:10,686:INFO:Importing untrained model
2023-06-05 00:33:10,686:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:33:10,689:INFO:Starting cross validation
2023-06-05 00:33:10,692:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:33:13,817:INFO:Calculating mean and std
2023-06-05 00:33:13,818:INFO:Creating metrics dataframe
2023-06-05 00:33:14,185:INFO:Uploading results into container
2023-06-05 00:33:14,186:INFO:Uploading model into container now
2023-06-05 00:33:14,186:INFO:_master_model_container: 10
2023-06-05 00:33:14,186:INFO:_display_container: 2
2023-06-05 00:33:14,187:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:33:14,187:INFO:create_model() successfully completed......................................
2023-06-05 00:33:14,301:INFO:SubProcess create_model() end ==================================
2023-06-05 00:33:14,302:INFO:Creating metrics dataframe
2023-06-05 00:33:14,303:INFO:Initializing Linear Discriminant Analysis
2023-06-05 00:33:14,303:INFO:Total runtime is 0.6529147346814475 minutes
2023-06-05 00:33:14,303:INFO:SubProcess create_model() called ==================================
2023-06-05 00:33:14,303:INFO:Initializing create_model()
2023-06-05 00:33:14,303:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:33:14,303:INFO:Checking exceptions
2023-06-05 00:33:14,303:INFO:Importing libraries
2023-06-05 00:33:14,303:INFO:Copying training dataset
2023-06-05 00:33:14,336:INFO:Defining folds
2023-06-05 00:33:14,337:INFO:Declaring metric variables
2023-06-05 00:33:14,337:INFO:Importing untrained model
2023-06-05 00:33:14,337:INFO:Linear Discriminant Analysis Imported successfully
2023-06-05 00:33:14,337:INFO:Starting cross validation
2023-06-05 00:33:14,339:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:33:15,557:INFO:Calculating mean and std
2023-06-05 00:33:15,558:INFO:Creating metrics dataframe
2023-06-05 00:33:16,154:INFO:Uploading results into container
2023-06-05 00:33:16,154:INFO:Uploading model into container now
2023-06-05 00:33:16,155:INFO:_master_model_container: 11
2023-06-05 00:33:16,155:INFO:_display_container: 2
2023-06-05 00:33:16,156:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-05 00:33:16,156:INFO:create_model() successfully completed......................................
2023-06-05 00:33:16,278:INFO:SubProcess create_model() end ==================================
2023-06-05 00:33:16,278:INFO:Creating metrics dataframe
2023-06-05 00:33:16,286:INFO:Initializing Extra Trees Classifier
2023-06-05 00:33:16,286:INFO:Total runtime is 0.6859630147616069 minutes
2023-06-05 00:33:16,286:INFO:SubProcess create_model() called ==================================
2023-06-05 00:33:16,287:INFO:Initializing create_model()
2023-06-05 00:33:16,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:33:16,287:INFO:Checking exceptions
2023-06-05 00:33:16,287:INFO:Importing libraries
2023-06-05 00:33:16,287:INFO:Copying training dataset
2023-06-05 00:33:16,314:INFO:Defining folds
2023-06-05 00:33:16,314:INFO:Declaring metric variables
2023-06-05 00:33:16,314:INFO:Importing untrained model
2023-06-05 00:33:16,315:INFO:Extra Trees Classifier Imported successfully
2023-06-05 00:33:16,316:INFO:Starting cross validation
2023-06-05 00:33:16,317:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:33:18,464:INFO:Calculating mean and std
2023-06-05 00:33:18,466:INFO:Creating metrics dataframe
2023-06-05 00:33:19,234:INFO:Uploading results into container
2023-06-05 00:33:19,235:INFO:Uploading model into container now
2023-06-05 00:33:19,236:INFO:_master_model_container: 12
2023-06-05 00:33:19,236:INFO:_display_container: 2
2023-06-05 00:33:19,237:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-05 00:33:19,237:INFO:create_model() successfully completed......................................
2023-06-05 00:33:19,389:INFO:SubProcess create_model() end ==================================
2023-06-05 00:33:19,389:INFO:Creating metrics dataframe
2023-06-05 00:33:19,399:INFO:Initializing Light Gradient Boosting Machine
2023-06-05 00:33:19,400:INFO:Total runtime is 0.7378488977750143 minutes
2023-06-05 00:33:19,400:INFO:SubProcess create_model() called ==================================
2023-06-05 00:33:19,400:INFO:Initializing create_model()
2023-06-05 00:33:19,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:33:19,401:INFO:Checking exceptions
2023-06-05 00:33:19,401:INFO:Importing libraries
2023-06-05 00:33:19,401:INFO:Copying training dataset
2023-06-05 00:33:19,436:INFO:Defining folds
2023-06-05 00:33:19,436:INFO:Declaring metric variables
2023-06-05 00:33:19,437:INFO:Importing untrained model
2023-06-05 00:33:19,438:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-05 00:33:19,439:INFO:Starting cross validation
2023-06-05 00:33:19,441:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:33:20,834:INFO:Calculating mean and std
2023-06-05 00:33:20,834:INFO:Creating metrics dataframe
2023-06-05 00:33:21,166:INFO:Uploading results into container
2023-06-05 00:33:21,167:INFO:Uploading model into container now
2023-06-05 00:33:21,167:INFO:_master_model_container: 13
2023-06-05 00:33:21,168:INFO:_display_container: 2
2023-06-05 00:33:21,168:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-05 00:33:21,168:INFO:create_model() successfully completed......................................
2023-06-05 00:33:21,336:INFO:SubProcess create_model() end ==================================
2023-06-05 00:33:21,337:INFO:Creating metrics dataframe
2023-06-05 00:33:21,349:INFO:Initializing Dummy Classifier
2023-06-05 00:33:21,350:INFO:Total runtime is 0.7703689455986024 minutes
2023-06-05 00:33:21,350:INFO:SubProcess create_model() called ==================================
2023-06-05 00:33:21,350:INFO:Initializing create_model()
2023-06-05 00:33:21,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025673A36D10>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:33:21,352:INFO:Checking exceptions
2023-06-05 00:33:21,352:INFO:Importing libraries
2023-06-05 00:33:21,352:INFO:Copying training dataset
2023-06-05 00:33:21,400:INFO:Defining folds
2023-06-05 00:33:21,401:INFO:Declaring metric variables
2023-06-05 00:33:21,401:INFO:Importing untrained model
2023-06-05 00:33:21,402:INFO:Dummy Classifier Imported successfully
2023-06-05 00:33:21,403:INFO:Starting cross validation
2023-06-05 00:33:21,404:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:33:21,652:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:33:21,672:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:33:21,734:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:33:21,782:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-05 00:33:22,483:INFO:Calculating mean and std
2023-06-05 00:33:22,484:INFO:Creating metrics dataframe
2023-06-05 00:33:22,857:INFO:Uploading results into container
2023-06-05 00:33:22,858:INFO:Uploading model into container now
2023-06-05 00:33:22,859:INFO:_master_model_container: 14
2023-06-05 00:33:22,859:INFO:_display_container: 2
2023-06-05 00:33:22,859:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-05 00:33:22,859:INFO:create_model() successfully completed......................................
2023-06-05 00:33:22,982:INFO:SubProcess create_model() end ==================================
2023-06-05 00:33:22,982:INFO:Creating metrics dataframe
2023-06-05 00:33:22,996:INFO:Initializing create_model()
2023-06-05 00:33:22,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:33:22,997:INFO:Checking exceptions
2023-06-05 00:33:22,999:INFO:Importing libraries
2023-06-05 00:33:22,999:INFO:Copying training dataset
2023-06-05 00:33:23,039:INFO:Defining folds
2023-06-05 00:33:23,039:INFO:Declaring metric variables
2023-06-05 00:33:23,039:INFO:Importing untrained model
2023-06-05 00:33:23,039:INFO:Declaring custom model
2023-06-05 00:33:23,039:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:33:23,039:INFO:Cross validation set to False
2023-06-05 00:33:23,039:INFO:Fitting Model
2023-06-05 00:33:23,389:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:33:23,389:INFO:create_model() successfully completed......................................
2023-06-05 00:33:23,547:INFO:_master_model_container: 14
2023-06-05 00:33:23,548:INFO:_display_container: 2
2023-06-05 00:33:23,548:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:33:23,548:INFO:compare_models() successfully completed......................................
2023-06-05 00:33:23,549:INFO:Initializing evaluate_model()
2023-06-05 00:33:23,549:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-05 00:33:23,783:INFO:Initializing plot_model()
2023-06-05 00:33:23,783:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, use_train_data=False, verbose=False, system=True, display=None, display_format=None)
2023-06-05 00:33:23,784:INFO:Checking exceptions
2023-06-05 00:33:23,795:INFO:Preloading libraries
2023-06-05 00:33:23,808:INFO:Copying training dataset
2023-06-05 00:33:23,808:INFO:Plot type: pipeline
2023-06-05 00:33:23,859:WARNING:C:\Users\shiva\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:572: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  fig, ax = plt.subplots(

2023-06-05 00:33:24,115:INFO:Initializing tune_model()
2023-06-05 00:33:24,115:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2023-06-05 00:33:24,115:INFO:Checking exceptions
2023-06-05 00:33:24,133:INFO:Copying training dataset
2023-06-05 00:33:24,168:INFO:Checking base model
2023-06-05 00:33:24,168:INFO:Base model : Gradient Boosting Classifier
2023-06-05 00:33:24,169:INFO:Declaring metric variables
2023-06-05 00:33:24,170:INFO:Defining Hyperparameters
2023-06-05 00:33:24,310:INFO:Tuning with n_jobs=-1
2023-06-05 00:33:24,311:INFO:Initializing RandomizedSearchCV
2023-06-05 00:34:06,718:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-06-05 00:34:06,718:INFO:Hyperparameter search completed
2023-06-05 00:34:06,718:INFO:SubProcess create_model() called ==================================
2023-06-05 00:34:06,726:INFO:Initializing create_model()
2023-06-05 00:34:06,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025674BE8D10>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-06-05 00:34:06,726:INFO:Checking exceptions
2023-06-05 00:34:06,726:INFO:Importing libraries
2023-06-05 00:34:06,726:INFO:Copying training dataset
2023-06-05 00:34:06,749:INFO:Defining folds
2023-06-05 00:34:06,749:INFO:Declaring metric variables
2023-06-05 00:34:06,749:INFO:Importing untrained model
2023-06-05 00:34:06,749:INFO:Declaring custom model
2023-06-05 00:34:06,749:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:34:06,749:INFO:Starting cross validation
2023-06-05 00:34:06,749:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:34:10,572:INFO:Calculating mean and std
2023-06-05 00:34:10,572:INFO:Creating metrics dataframe
2023-06-05 00:34:10,574:INFO:Finalizing model
2023-06-05 00:34:10,971:INFO:Uploading results into container
2023-06-05 00:34:10,972:INFO:Uploading model into container now
2023-06-05 00:34:10,973:INFO:_master_model_container: 15
2023-06-05 00:34:10,973:INFO:_display_container: 3
2023-06-05 00:34:10,974:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:34:10,974:INFO:create_model() successfully completed......................................
2023-06-05 00:34:11,108:INFO:SubProcess create_model() end ==================================
2023-06-05 00:34:11,108:INFO:choose_better activated
2023-06-05 00:34:11,108:INFO:SubProcess create_model() called ==================================
2023-06-05 00:34:11,116:INFO:Initializing create_model()
2023-06-05 00:34:11,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025670E71890>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 00:34:11,116:INFO:Checking exceptions
2023-06-05 00:34:11,116:INFO:Importing libraries
2023-06-05 00:34:11,116:INFO:Copying training dataset
2023-06-05 00:34:11,147:INFO:Defining folds
2023-06-05 00:34:11,147:INFO:Declaring metric variables
2023-06-05 00:34:11,147:INFO:Importing untrained model
2023-06-05 00:34:11,147:INFO:Declaring custom model
2023-06-05 00:34:11,147:INFO:Gradient Boosting Classifier Imported successfully
2023-06-05 00:34:11,147:INFO:Starting cross validation
2023-06-05 00:34:11,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 00:34:14,791:INFO:Calculating mean and std
2023-06-05 00:34:14,791:INFO:Creating metrics dataframe
2023-06-05 00:34:14,792:INFO:Finalizing model
2023-06-05 00:34:15,142:INFO:Uploading results into container
2023-06-05 00:34:15,142:INFO:Uploading model into container now
2023-06-05 00:34:15,142:INFO:_master_model_container: 16
2023-06-05 00:34:15,142:INFO:_display_container: 4
2023-06-05 00:34:15,142:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:34:15,142:INFO:create_model() successfully completed......................................
2023-06-05 00:34:15,260:INFO:SubProcess create_model() end ==================================
2023-06-05 00:34:15,261:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-05 00:34:15,261:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9792
2023-06-05 00:34:15,261:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-06-05 00:34:15,261:INFO:choose_better completed
2023-06-05 00:34:15,263:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-05 00:34:15,280:INFO:_master_model_container: 16
2023-06-05 00:34:15,281:INFO:_display_container: 3
2023-06-05 00:34:15,282:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-05 00:34:15,282:INFO:tune_model() successfully completed......................................
